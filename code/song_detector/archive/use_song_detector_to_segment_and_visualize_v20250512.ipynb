{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b688551a",
   "metadata": {},
   "source": [
    "# This code uses a .json file with file names and detected song intervals, then assembles either: 1) recording segments that contain song or 2) entire files that contain song.\n",
    "\n",
    "## Both data outputs are saved in the original folder_path.\n",
    "- folder_path is a path to a folder that contains all of the .wav file recordings.\n",
    "- json_path is a path to a .json file output by a song detector code, which contains each .wav file name from folder_path and, if there was detected song, the time segments with detected song in them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64cd353",
   "metadata": {},
   "source": [
    "## Option 1: only generate spectrograms of time setgments with detected song. \n",
    "### This code uses the time segments inside of the .json file to combine songs into 1 minute .wav files containing song, then saves those .wav files and generates .pngs of their spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5855eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Saved detected_song_minute_1_partial.wav  (49.82 s)\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import json\n",
    "# import numpy as np\n",
    "# from pathlib import Path\n",
    "# from scipy.io import wavfile\n",
    "\n",
    "# # ════════════════════════════════════════════════════════════════════════\n",
    "# # CONFIG ── change these two paths only\n",
    "# # ════════════════════════════════════════════════════════════════════════\n",
    "# folder_path = (\n",
    "#     \"/Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5288_testing_pipeline\"\n",
    "# )\n",
    "# json_path = (\n",
    "#     \"/Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5288_testing_pipeline_amplitude_only_detected_song_intervals.json\"\n",
    "# )\n",
    "\n",
    "# # ════════════════════════════════════════════════════════════════════════\n",
    "# # OPTIONAL RUNTIME SETTINGS\n",
    "# # ════════════════════════════════════════════════════════════════════════\n",
    "# chunk_duration_sec       = 60      # target length of each output clip\n",
    "# save_partial_final_chunk = True    # save the trailing < 60‑s chunk?\n",
    "# pad_partial_with_zeros   = False   # …and pad it up to 60 s?\n",
    "\n",
    "# # ════════════════════════════════════════════════════════════════════════\n",
    "# # SET‑UP ── output folder\n",
    "# # ════════════════════════════════════════════════════════════════════════\n",
    "# output_folder = os.path.join(folder_path, \"detected_song_minutes\")\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# # ════════════════════════════════════════════════════════════════════════\n",
    "# # STEP 1 ── load JSON with [start, end] times in seconds\n",
    "# # ════════════════════════════════════════════════════════════════════════\n",
    "# with open(json_path, \"r\") as f:\n",
    "#     detected_intervals = json.load(f)\n",
    "\n",
    "# # ════════════════════════════════════════════════════════════════════════\n",
    "# # STEP 2 ── slice out every detected interval and collect in RAM\n",
    "# # ════════════════════════════════════════════════════════════════════════\n",
    "# detected_segments      = []\n",
    "# sample_rate_reference  = None\n",
    "\n",
    "# for file_name, intervals in detected_intervals.items():\n",
    "#     wav_path = os.path.join(folder_path, file_name)\n",
    "#     if not os.path.exists(wav_path):\n",
    "#         print(f\"⚠️  Missing file: {file_name}\")\n",
    "#         continue\n",
    "\n",
    "#     try:\n",
    "#         samplerate, data = wavfile.read(wav_path)\n",
    "\n",
    "#         # keep the first file’s sample‑rate as the reference\n",
    "#         if sample_rate_reference is None:\n",
    "#             sample_rate_reference = samplerate\n",
    "#         elif samplerate != sample_rate_reference:\n",
    "#             raise ValueError(f\"Sample‑rate mismatch in {file_name}\")\n",
    "\n",
    "#         # stereo → mono\n",
    "#         if data.ndim > 1:\n",
    "#             data = data.mean(axis=1)\n",
    "\n",
    "#         # extract all (start, end) snippets\n",
    "#         for start_time, end_time in intervals:\n",
    "#             start = int(start_time * samplerate)\n",
    "#             end   = int(end_time   * samplerate)\n",
    "#             detected_segments.append(data[start:end])\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"⚠️  Error reading {file_name}: {e}\")\n",
    "\n",
    "# if not detected_segments:\n",
    "#     raise RuntimeError(\"No detected song segments were found in the JSON file.\")\n",
    "\n",
    "# # ════════════════════════════════════════════════════════════════════════\n",
    "# # STEP 3 ── concatenate and split into ≤60‑s chunks\n",
    "# # ════════════════════════════════════════════════════════════════════════\n",
    "# concatenated   = np.concatenate(detected_segments)\n",
    "# target_samples = chunk_duration_sec * sample_rate_reference\n",
    "\n",
    "# minute_segments = []\n",
    "\n",
    "# for i in range(0, len(concatenated), target_samples):\n",
    "#     chunk = concatenated[i : i + target_samples]\n",
    "\n",
    "#     if len(chunk) == target_samples:\n",
    "#         # full‑length minute\n",
    "#         minute_segments.append(chunk)\n",
    "\n",
    "#     elif save_partial_final_chunk and len(chunk) > 0:\n",
    "#         # trailing < 60‑s chunk\n",
    "#         if pad_partial_with_zeros:\n",
    "#             pad_len = target_samples - len(chunk)\n",
    "#             chunk   = np.pad(chunk, (0, pad_len), mode=\"constant\")\n",
    "#         minute_segments.append(chunk)\n",
    "\n",
    "# # ════════════════════════════════════════════════════════════════════════\n",
    "# # STEP 4 ── write each chunk to disk\n",
    "# # ════════════════════════════════════════════════════════════════════════\n",
    "# for idx, segment in enumerate(minute_segments, start=1):\n",
    "#     duration_sec = len(segment) / sample_rate_reference\n",
    "#     suffix       = \"_partial\" if duration_sec < chunk_duration_sec else \"\"\n",
    "#     fname        = f\"detected_song_minute_{idx}{suffix}.wav\"\n",
    "#     fpath        = os.path.join(output_folder, fname)\n",
    "\n",
    "#     wavfile.write(fpath, sample_rate_reference, segment.astype(np.int16))\n",
    "#     print(f\"✅  Saved {fname}  ({duration_sec:.2f} s)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0648f83d",
   "metadata": {},
   "source": [
    "### Adjusted to include the animal_id and recording_date in the .wav file name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a959ff6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Saved USA5207_2025-07-19_detected_song_segment_1.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_2.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_3.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_4.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_5.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_6.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_7.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_8.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_9.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_10.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_11.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_12.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_13.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_14.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_15.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_16.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_17.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_18.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_19.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_20.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_21.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_22.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_23.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_24.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_25.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_26.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_27.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_28.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_29.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_30.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_31.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_32.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_33.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_34.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_35.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_36.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_37.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_38.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_39.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_40.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_41.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_42.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_43_partial.wav  (2.67 s)\n",
      "\n",
      "Done!  Segments are in: /Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33/detected_song_segments\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf‑8 -*-\n",
    "\"\"\"\n",
    "Slice detected song intervals out of a folder of .wav files, concatenate them,\n",
    "split into ≤ chunk_duration_sec chunks, and save the chunks with filenames that\n",
    "embed `animal_id` and `recording_date`, e.g.\n",
    "\n",
    "    USA5288_2025-04-08_detected_song_segment_3.wav\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Optional, List\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# USER‑EDITABLE METADATA\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "animal_id      = \"USA5207\"     # shown in the output filenames\n",
    "recording_date = \"2025-07-19\"  # YYYY‑MM‑DD              ↑\n",
    "\n",
    "# absolute **or** relative path to the folder that holds the .wav files\n",
    "folder_path = Path(\n",
    "    \"/Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33\"\n",
    ")\n",
    "\n",
    "# absolute **or** relative path to the JSON file with detected intervals\n",
    "json_path = Path(\n",
    "    \"/Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33_periodicity_only_detected_song_intervals_combined_segments.json\"\n",
    ")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# RUNTIME SETTINGS\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "chunk_duration_sec       = 60      # target length of each output clip\n",
    "save_partial_final_chunk = True    # keep a trailing < 60‑s chunk?\n",
    "pad_partial_with_zeros   = False   # …and pad it out to full length?\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# QUICK VALIDATION OF THE TWO CRITICAL PATHS\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "if not folder_path.exists():\n",
    "    raise FileNotFoundError(f\"Audio folder not found:\\n  {folder_path.resolve()}\")\n",
    "\n",
    "if not json_path.is_file():\n",
    "    raise FileNotFoundError(f\"JSON file not found:\\n  {json_path.resolve()}\")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# OUTPUT FOLDER\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "output_folder = folder_path / \"detected_song_segments\"\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# STEP 1 – load JSON with [start, end] pairs (seconds)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "with open(json_path, \"r\", encoding=\"utf‑8\") as f:\n",
    "    detected_intervals: dict[str, List[List[float]]] = json.load(f)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# STEP 2 – extract every detected interval from every file\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "detected_segments: List[np.ndarray] = []\n",
    "sample_rate_reference: Optional[int] = None\n",
    "missing_files: list[str] = []\n",
    "\n",
    "for file_name, intervals in detected_intervals.items():\n",
    "    wav_path = folder_path / file_name\n",
    "    if not wav_path.exists():\n",
    "        missing_files.append(file_name)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        samplerate, data = wavfile.read(wav_path)\n",
    "\n",
    "        # use the first file as the reference sample‑rate\n",
    "        if sample_rate_reference is None:\n",
    "            sample_rate_reference = samplerate\n",
    "        elif samplerate != sample_rate_reference:\n",
    "            raise ValueError(f\"Sample‑rate mismatch in {file_name}\")\n",
    "\n",
    "        # stereo → mono\n",
    "        if data.ndim > 1:\n",
    "            data = data.mean(axis=1)\n",
    "\n",
    "        # pull every [start, end] snippet\n",
    "        for start_time, end_time in intervals:\n",
    "            start = int(start_time * samplerate)\n",
    "            end   = int(end_time   * samplerate)\n",
    "            detected_segments.append(data[start:end])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Error reading {file_name}: {e}\")\n",
    "\n",
    "# Report any listed but missing files\n",
    "if missing_files:\n",
    "    print(\"\\n⚠️  The following files were listed in the JSON but not found in\"\n",
    "          f\" {folder_path}:\\n  • \" + \"\\n  • \".join(missing_files))\n",
    "\n",
    "if not detected_segments:\n",
    "    raise RuntimeError(\"No detected song segments were found for the paths \"\n",
    "                       \"you provided. Double‑check the folder/JSON pairing.\")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# STEP 3 – concatenate & split into ≤ chunk_duration_sec chunks\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "concatenated   = np.concatenate(detected_segments)\n",
    "target_samples = chunk_duration_sec * sample_rate_reference\n",
    "song_segments  = []\n",
    "\n",
    "for i in range(0, len(concatenated), target_samples):\n",
    "    chunk = concatenated[i : i + target_samples]\n",
    "\n",
    "    if len(chunk) == target_samples:\n",
    "        # full‑length chunk\n",
    "        song_segments.append(chunk)\n",
    "\n",
    "    elif save_partial_final_chunk and len(chunk) > 0:\n",
    "        # trailing short chunk\n",
    "        if pad_partial_with_zeros:\n",
    "            pad_len = target_samples - len(chunk)\n",
    "            chunk   = np.pad(chunk, (0, pad_len), mode=\"constant\")\n",
    "        song_segments.append(chunk)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# STEP 4 – write each chunk to disk with descriptive filename\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "for idx, segment in enumerate(song_segments, start=1):\n",
    "    duration_sec = len(segment) / sample_rate_reference\n",
    "    suffix       = \"_partial\" if duration_sec < chunk_duration_sec else \"\"\n",
    "    fname = f\"{animal_id}_{recording_date}_detected_song_segment_{idx}{suffix}.wav\"\n",
    "\n",
    "    wavfile.write(output_folder / fname,\n",
    "                  sample_rate_reference,\n",
    "                  segment.astype(np.int16))\n",
    "\n",
    "    print(f\"✅  Saved {fname}  ({duration_sec:.2f} s)\")\n",
    "\n",
    "print(\"\\nDone!  Segments are in:\", output_folder.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6689e7",
   "metadata": {},
   "source": [
    "## Generate the spectrograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f02c90fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "# from scipy.io import wavfile\n",
    "# from scipy.signal import spectrogram, windows, ellip, filtfilt\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tkinter as tk\n",
    "# import json\n",
    "\n",
    "# def get_screen_resolution():\n",
    "#     root = tk.Tk()\n",
    "#     root.withdraw()\n",
    "#     screen_width = root.winfo_screenwidth()\n",
    "#     screen_height = root.winfo_screenheight()\n",
    "#     root.destroy()\n",
    "#     return screen_width / 100, screen_height / 100  # inches\n",
    "\n",
    "# width_inches, height_inches = get_screen_resolution()\n",
    "\n",
    "# # === Load JSON file once\n",
    "# with open(json_path, 'r') as f:\n",
    "#     file_lists = json.load(f)\n",
    "\n",
    "# def process_wav_file(file_path, spectrogram_folder, segment_duration=10, low_cut=500, high_cut=8000):\n",
    "#     try:\n",
    "#         base_name = Path(file_path).stem\n",
    "#         samplerate, data = wavfile.read(file_path)\n",
    "#         if data.ndim > 1:\n",
    "#             data = data.mean(axis=1)\n",
    "\n",
    "#         nyquist = samplerate / 2\n",
    "#         wp = [low_cut / nyquist, high_cut / nyquist]\n",
    "#         b, a = ellip(5, 0.2, 40, wp, btype='band')\n",
    "#         data = filtfilt(b, a, data)\n",
    "\n",
    "#         duration_seconds = data.shape[0] / samplerate\n",
    "#         segment_length_samples = int(segment_duration * samplerate)\n",
    "#         num_segments = min(6, int(np.ceil(duration_seconds / segment_duration)))\n",
    "\n",
    "#         spectrogram_fig_path = os.path.join(spectrogram_folder, f\"{base_name}_spectrogram.png\")\n",
    "\n",
    "#         fig, axs = plt.subplots(num_segments, 1, figsize=(width_inches, height_inches), sharex=True, gridspec_kw={'hspace': 0.0})\n",
    "#         if num_segments == 1:\n",
    "#             axs = [axs]\n",
    "\n",
    "#         red_lines_sec = []\n",
    "#         if f\"{base_name}.wav\" in file_lists:\n",
    "#             red_lines_sec = [entry[\"start_sample\"] / samplerate for entry in file_lists[f\"{base_name}.wav\"]]\n",
    "\n",
    "#         for i in range(num_segments):\n",
    "#             start_sample = i * segment_length_samples\n",
    "#             end_sample = start_sample + segment_length_samples\n",
    "#             segment_data = np.zeros(segment_length_samples, dtype=data.dtype)\n",
    "#             if start_sample < data.shape[0]:\n",
    "#                 segment_data[:max(0, min(segment_length_samples, data.shape[0] - start_sample))] = data[start_sample:end_sample]\n",
    "\n",
    "#             f, t, Sxx = spectrogram(\n",
    "#                 segment_data,\n",
    "#                 fs=samplerate,\n",
    "#                 window=windows.gaussian(2048, std=2048/8),\n",
    "#                 nperseg=2048,\n",
    "#                 noverlap=(2048 - 119)\n",
    "#             )\n",
    "\n",
    "#             Sxx_log = 10 * np.log10(Sxx + np.finfo(float).eps)\n",
    "#             Sxx_log_clipped = np.clip(Sxx_log, a_min=3, a_max=None)\n",
    "#             Sxx_log_normalized = (Sxx_log_clipped - np.min(Sxx_log_clipped)) / (np.max(Sxx_log_clipped) - np.min(Sxx_log_clipped))\n",
    "#             Sxx_log_normalized = np.power(Sxx_log_normalized, 0.7)\n",
    "\n",
    "#             axs[i].imshow(Sxx_log_normalized, aspect='auto', origin='lower',\n",
    "#                           extent=[0, segment_duration, f.min(), f.max()], cmap='binary')\n",
    "#             axs[i].set_ylim(0,11000)\n",
    "\n",
    "#             for x in red_lines_sec:\n",
    "#                 if start_sample / samplerate <= x < end_sample / samplerate:\n",
    "#                     axs[i].axvline(x - (start_sample / samplerate), color='red', linestyle='-', linewidth=1)\n",
    "\n",
    "#             axs[i].set_ylabel('Freq [Hz]')\n",
    "#             if i == num_segments - 1:\n",
    "#                 axs[i].set_xlabel('Time [sec]')\n",
    "#                 axs[i].set_xticks(np.linspace(0, segment_duration, 5))\n",
    "\n",
    "#         fig.suptitle(f'{base_name} – Spectrogram (Filtered {low_cut}-{high_cut} Hz)', fontsize=14)\n",
    "#         fig.tight_layout()\n",
    "#         fig.savefig(spectrogram_fig_path, dpi=300)\n",
    "#         plt.close(fig)\n",
    "#         print(f\"✅ Saved: {spectrogram_fig_path}\\n\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ Error processing {file_path}: {e}\")\n",
    "\n",
    "# def batch_process_folder(folder_path, segment_duration=10):\n",
    "#     output_folder = os.path.join(folder_path)\n",
    "#     spectrogram_folder = os.path.join(output_folder, \"spectrograms\")\n",
    "#     os.makedirs(spectrogram_folder, exist_ok=True)\n",
    "\n",
    "#     wav_files = [f for f in Path(folder_path).glob(\"*.wav\")]\n",
    "#     if not wav_files:\n",
    "#         print(\"No .wav files found in the selected folder.\")\n",
    "#         return\n",
    "\n",
    "#     print(f\"\\n📂 Processing {len(wav_files)} files in: {folder_path}\\n\")\n",
    "#     for wav_file in wav_files:\n",
    "#         process_wav_file(wav_file, spectrogram_folder, segment_duration=segment_duration)\n",
    "\n",
    "# # === USER INPUT ===\n",
    "# #folder_path = '/Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_unsegmented_songs/55/detected_song_minutes'\n",
    "# save_minutes_folder_path = folder_path + '/detected_song_segments'\n",
    "# batch_process_folder(\n",
    "#     save_minutes_folder_path,\n",
    "#     segment_duration=10  # Each panel = 10s; total of 6 panels = 60s\n",
    "#     #animal_id = 'USA5288'\n",
    "#     #recording_date = '2024-04-08'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f148ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Rendering 1 files …\n",
      "\n",
      "✅ USA5288_2025-04-08_detected_song_segment_1_partial_spectrogram.png\n",
      "\n",
      "Done!  PNGs live in: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5288_testing_pipeline/detected_song_segments/spectrograms\n"
     ]
    }
   ],
   "source": [
    "# #!/usr/bin/env python\n",
    "# # -*- coding: utf-8 -*-\n",
    "# \"\"\"\n",
    "# Render filtered spectrogram panels for every *.wav produced by the\n",
    "# “detected_song_segment” exporter.  Each .png is saved next to the audio\n",
    "# inside   <parent>/detected_song_segments/spectrograms/.\n",
    "# \"\"\"\n",
    "\n",
    "# from pathlib import Path\n",
    "# from typing import Tuple\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.io import wavfile\n",
    "# from scipy.signal import spectrogram, windows, ellip, filtfilt\n",
    "# import tkinter as tk\n",
    "\n",
    "# # ────────────────────────────────────────────────────────────────\n",
    "# # USER CONFIG\n",
    "# # ────────────────────────────────────────────────────────────────\n",
    "# # Point this at the SAME parent folder you fed to the exporter script.\n",
    "# parent_folder = Path(\n",
    "#     \"/Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5288_testing_pipeline\"\n",
    "# )\n",
    "\n",
    "# # Filter + plotting\n",
    "# segment_duration    = 10          # seconds per panel\n",
    "# panels_per_fig      = 6           # => 60‑s figure for each audio file\n",
    "# low_cut, high_cut   = 500, 8000   # Hz band‑pass before spectrogram\n",
    "# cmap_choice         = \"binary\"    # colormap for log‑scaled spectrogram\n",
    "\n",
    "# # ────────────────────────────────────────────────────────────────\n",
    "# # HELPER – screen size in inches (fallback to 12×8 if headless)\n",
    "# # ────────────────────────────────────────────────────────────────\n",
    "# def get_screen_inches() -> Tuple[float, float]:\n",
    "#     try:\n",
    "#         root = tk.Tk(); root.withdraw()\n",
    "#         w, h = root.winfo_screenwidth(), root.winfo_screenheight()\n",
    "#         root.destroy()\n",
    "#         return w / 100, h / 100\n",
    "#     except Exception:\n",
    "#         return 12, 8\n",
    "\n",
    "# width_inches, height_inches = get_screen_inches()\n",
    "\n",
    "# # ────────────────────────────────────────────────────────────────\n",
    "# # CORE – process ONE .wav\n",
    "# # ────────────────────────────────────────────────────────────────\n",
    "# def process_wav_file(wav_path: Path, out_folder: Path):\n",
    "#     base_name = wav_path.stem\n",
    "#     try:\n",
    "#         sr, data = wavfile.read(wav_path)\n",
    "#         if data.ndim > 1:\n",
    "#             data = data.mean(axis=1)\n",
    "#         if np.issubdtype(data.dtype, np.integer):\n",
    "#             data = data.astype(np.float32)  # work in float\n",
    "\n",
    "#         # Band‑pass\n",
    "#         nyq  = sr / 2\n",
    "#         b, a = ellip(5, 0.2, 40, [low_cut / nyq, high_cut / nyq], btype=\"band\")\n",
    "#         data = filtfilt(b, a, data)\n",
    "\n",
    "#         total_secs     = data.size / sr\n",
    "#         samples_per_se = int(segment_duration * sr)\n",
    "#         n_panels       = min(panels_per_fig, int(np.ceil(total_secs / segment_duration)))\n",
    "\n",
    "#         out_png = out_folder / f\"{base_name}_spectrogram.png\"\n",
    "#         fig, axs = plt.subplots(n_panels, 1,\n",
    "#                                 figsize=(width_inches, height_inches),\n",
    "#                                 sharex=True,\n",
    "#                                 gridspec_kw={\"hspace\": 0.0})\n",
    "#         axs = [axs] if n_panels == 1 else axs\n",
    "\n",
    "#         for i in range(n_panels):\n",
    "#             start_samp = i * samples_per_se\n",
    "#             seg = data[start_samp : start_samp + samples_per_se]\n",
    "\n",
    "#             # zero‑pad last seg if shorter\n",
    "#             if seg.size < samples_per_se:\n",
    "#                 seg = np.pad(seg, (0, samples_per_se - seg.size))\n",
    "\n",
    "#             f, t, Sxx = spectrogram(\n",
    "#                 seg, fs=sr,\n",
    "#                 window=windows.gaussian(2048, std=2048/8),\n",
    "#                 nperseg=2048, noverlap=2048-119\n",
    "#             )\n",
    "#             S_log = 10 * np.log10(Sxx + np.finfo(float).eps)\n",
    "#             S_log = np.clip(S_log, a_min=3, a_max=None)\n",
    "#             S_norm = (S_log - S_log.min()) / (S_log.ptp() or 1.0)\n",
    "#             S_norm **= 0.7  # mild gamma\n",
    "\n",
    "#             axs[i].imshow(S_norm,\n",
    "#                           aspect='auto', origin='lower',\n",
    "#                           extent=[0, segment_duration, f.min(), f.max()],\n",
    "#                           cmap=cmap_choice)\n",
    "#             axs[i].set_ylim(0, 11000)\n",
    "#             axs[i].set_ylabel(\"Freq [Hz]\")\n",
    "#             if i == n_panels - 1:\n",
    "#                 axs[i].set_xlabel(\"Time [s]\")\n",
    "#                 axs[i].set_xticks(np.linspace(0, segment_duration, 5))\n",
    "\n",
    "#         fig.suptitle(f\"{base_name}  –  Spectrogram ({low_cut}-{high_cut} Hz)\",\n",
    "#                      fontsize=14)\n",
    "#         fig.tight_layout()\n",
    "#         fig.savefig(out_png, dpi=300)\n",
    "#         plt.close(fig)\n",
    "#         print(\"✅\", out_png.name)\n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ {wav_path.name}: {e}\")\n",
    "\n",
    "# # ────────────────────────────────────────────────────────────────\n",
    "# # BATCH\n",
    "# # ────────────────────────────────────────────────────────────────\n",
    "# segments_folder = parent_folder / \"detected_song_segments\"\n",
    "# if not segments_folder.is_dir():\n",
    "#     raise FileNotFoundError(f\"Folder not found:\\n  {segments_folder}\")\n",
    "\n",
    "# png_folder = segments_folder / \"spectrograms\"\n",
    "# png_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# wav_files = list(segments_folder.glob(\"*.wav\"))\n",
    "# if not wav_files:\n",
    "#     print(\"No .wav files found in\", segments_folder)\n",
    "# else:\n",
    "#     print(f\"📂 Rendering {len(wav_files)} files …\\n\")\n",
    "#     for w in wav_files:\n",
    "#         process_wav_file(w, png_folder)\n",
    "\n",
    "# print(\"\\nDone!  PNGs live in:\", png_folder.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fa8039b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Rendering spectrograms for 43 files …\n",
      "\n",
      "✅ USA5207_2025-07-19_detected_song_segment_1_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_10_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_11_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_12_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_13_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_14_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_15_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_16_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_17_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_18_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_19_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_2_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_20_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_21_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_22_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_23_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_24_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_25_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_26_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_27_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_28_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_29_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_3_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_30_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_31_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_32_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_33_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_34_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_35_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_36_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_37_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_38_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_39_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_4_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_40_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_41_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_42_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_43_partial_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_5_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_6_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_7_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_8_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_9_spectrogram.png\n",
      "\n",
      "Done!  PNGs are in: /Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33/detected_song_segments/spectrograms\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Render filtered spectrogram panels for every\n",
    "<parent>/detected_song_segments/*.wav **and** draw red dashed lines wherever\n",
    "the concatenated audio switches from one original .wav file to the next.\n",
    "\n",
    "Required inputs\n",
    "---------------\n",
    "parent_folder : Path to the folder that also contains\n",
    "                ├─ detected_song_segments/\n",
    "                └─ <something>.json          (# same JSON you fed the exporter)\n",
    "\n",
    "The JSON must have the form::\n",
    "    {\n",
    "        \"original_a.wav\": [[s0,e0], [s1,e1], ...],\n",
    "        \"original_b.wav\": [[s2,e2], ...],\n",
    "        ...\n",
    "    }\n",
    "\n",
    "The script re‑creates the exporter’s concatenation logic to know where one\n",
    "file stops and the next one starts inside each 60‑s segment.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram, windows, ellip, filtfilt\n",
    "import json\n",
    "import tkinter as tk\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# USER CONFIG  (edit these three paths / constants)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "parent_folder = Path(\n",
    "    \"/Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33\"\n",
    ")\n",
    "json_path = \"/Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33_periodicity_only_detected_song_intervals_combined_segments.json\"\n",
    "\n",
    "segment_duration    = 10          # seconds per spectrogram panel\n",
    "panels_per_fig      = 6           # ⇒ 60 s max per detected segment\n",
    "low_cut, high_cut   = 500, 8000   # Hz filter before spectrogram\n",
    "cmap_choice         = \"binary\"\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "# DERIVED PATHS\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "segments_folder = parent_folder / \"detected_song_segments\"\n",
    "png_folder      = segments_folder / \"spectrograms\"\n",
    "png_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "# UTILS\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "def get_screen_inches() -> Tuple[float, float]:\n",
    "    try:\n",
    "        root = tk.Tk(); root.withdraw()\n",
    "        w, h = root.winfo_screenwidth(), root.winfo_screenheight()\n",
    "        root.destroy()\n",
    "        return w / 100, h / 100\n",
    "    except Exception:\n",
    "        return 12, 8\n",
    "\n",
    "width_inches, height_inches = get_screen_inches()\n",
    "\n",
    "segment_idx_re = re.compile(r\"_segment_(\\d+)\")\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "# STEP 1 – rebuild boundary map  {segment_number: [times (s), …]}\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    detected_intervals: Dict[str, List[List[float]]] = json.load(f)\n",
    "\n",
    "# We need the sample‑rate that the exporter used.  Grab it from any segment.\n",
    "any_seg = next((p for p in segments_folder.glob(\"*.wav\")), None)\n",
    "if any_seg is None:\n",
    "    raise FileNotFoundError(\"No *.wav in detected_song_segments/\")\n",
    "sample_rate_reference, _ = wavfile.read(any_seg)\n",
    "\n",
    "target_samples = panels_per_fig * segment_duration * sample_rate_reference  # 60 s\n",
    "\n",
    "# Build a list of (src_file, slice_len_samples) in the *exact* order\n",
    "slice_list: List[Tuple[str, int]] = []\n",
    "for src_name, intervals in detected_intervals.items():\n",
    "    for start_t, end_t in intervals:\n",
    "        slice_len = int(round((end_t - start_t) * sample_rate_reference))\n",
    "        slice_list.append((src_name, slice_len))\n",
    "\n",
    "boundary_map: Dict[int, List[float]] = {}          # {segment_idx: [t1, t2, …]}\n",
    "current_seg_idx  = 1\n",
    "current_pos_in_seg = 0     # samples\n",
    "current_src_file: str | None = None\n",
    "boundaries_in_seg: List[float] = []\n",
    "\n",
    "for src_file, slice_len in slice_list:\n",
    "    remaining = slice_len\n",
    "    while remaining > 0:\n",
    "        space_left = target_samples - current_pos_in_seg\n",
    "        take = min(remaining, space_left)\n",
    "\n",
    "        # If we’re switching files *and* we’re not at the very start of segment\n",
    "        if src_file != current_src_file and current_pos_in_seg != 0:\n",
    "            boundaries_in_seg.append(current_pos_in_seg / sample_rate_reference)\n",
    "        current_src_file = src_file\n",
    "\n",
    "        current_pos_in_seg += take\n",
    "        remaining         -= take\n",
    "\n",
    "        # Segment filled → commit boundaries & start new one\n",
    "        if current_pos_in_seg == target_samples:\n",
    "            boundary_map[current_seg_idx] = boundaries_in_seg\n",
    "            current_seg_idx      += 1\n",
    "            current_pos_in_seg    = 0\n",
    "            boundaries_in_seg     = []\n",
    "            current_src_file      = None\n",
    "\n",
    "# leftover (partial) segment\n",
    "boundary_map[current_seg_idx] = boundaries_in_seg\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "# STEP 2 – process ONE .wav\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "def process_wav_file(wav_path: Path, boundaries: List[float]):\n",
    "    base_name = wav_path.stem\n",
    "    sr, data  = wavfile.read(wav_path)\n",
    "    if data.ndim > 1:\n",
    "        data = data.mean(axis=1)\n",
    "    if np.issubdtype(data.dtype, np.integer):\n",
    "        data = data.astype(np.float32)\n",
    "\n",
    "    nyq = sr / 2\n",
    "    b, a = ellip(5, 0.2, 40, [low_cut / nyq, high_cut / nyq], btype=\"band\")\n",
    "    data = filtfilt(b, a, data)\n",
    "\n",
    "    total_secs   = data.size / sr\n",
    "    samples_per_panel = int(segment_duration * sr)\n",
    "    n_panels     = min(panels_per_fig, int(np.ceil(total_secs / segment_duration)))\n",
    "\n",
    "    fig, axs = plt.subplots(n_panels, 1,\n",
    "                            figsize=(width_inches, height_inches),\n",
    "                            sharex=True, gridspec_kw={'hspace': 0.0})\n",
    "    axs = [axs] if n_panels == 1 else axs\n",
    "\n",
    "    for i in range(n_panels):\n",
    "        start_samp = i * samples_per_panel\n",
    "        seg = data[start_samp : start_samp + samples_per_panel]\n",
    "        if seg.size < samples_per_panel:\n",
    "            seg = np.pad(seg, (0, samples_per_panel - seg.size))\n",
    "\n",
    "        f, t, Sxx = spectrogram(\n",
    "            seg, fs=sr,\n",
    "            window=windows.gaussian(2048, std=2048/8),\n",
    "            nperseg=2048, noverlap=2048 - 119\n",
    "        )\n",
    "        S_log  = 10 * np.log10(Sxx + np.finfo(float).eps)\n",
    "        S_log  = np.clip(S_log, a_min=3, a_max=None)\n",
    "        S_norm = (S_log - S_log.min()) / (S_log.ptp() or 1.0)\n",
    "        S_norm **= 0.7\n",
    "\n",
    "        axs[i].imshow(S_norm, aspect='auto', origin='lower',\n",
    "                      extent=[0, segment_duration, f.min(), f.max()],\n",
    "                      cmap=cmap_choice)\n",
    "        axs[i].set_ylim(0, 11000)\n",
    "        axs[i].set_ylabel(\"Freq [Hz]\")\n",
    "\n",
    "        # Draw the red dashed boundaries that fall inside this 10‑s panel\n",
    "        panel_t0 = i * segment_duration\n",
    "        panel_t1 = panel_t0 + segment_duration\n",
    "        for b_t in boundaries:\n",
    "            if panel_t0 < b_t < panel_t1:\n",
    "                axs[i].axvline(b_t - panel_t0, color='red',\n",
    "                               linestyle='--', linewidth=1)\n",
    "\n",
    "        if i == n_panels - 1:\n",
    "            axs[i].set_xlabel(\"Time [s]\")\n",
    "            axs[i].set_xticks(np.linspace(0, segment_duration, 5))\n",
    "\n",
    "    fig.suptitle(f\"{base_name}  –  Spectrogram ({low_cut}-{high_cut} Hz)\",\n",
    "                 fontsize=14)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    out_png = png_folder / f\"{base_name}_spectrogram.png\"\n",
    "    fig.savefig(out_png, dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(\"✅\", out_png.name)\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "# STEP 3 – batch over segments\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "wav_files = sorted(segments_folder.glob(\"*.wav\"))\n",
    "if not wav_files:\n",
    "    raise FileNotFoundError(\"No .wav files found in detected_song_segments/\")\n",
    "\n",
    "print(f\"📂 Rendering spectrograms for {len(wav_files)} files …\\n\")\n",
    "\n",
    "for wav_file in wav_files:\n",
    "    m = segment_idx_re.search(wav_file.stem)\n",
    "    if not m:\n",
    "        print(\"⚠️  Could not parse segment index from\", wav_file.name)\n",
    "        continue\n",
    "    seg_idx = int(m.group(1))\n",
    "    boundaries = boundary_map.get(seg_idx, [])\n",
    "    process_wav_file(wav_file, boundaries)\n",
    "\n",
    "print(\"\\nDone!  PNGs are in:\", png_folder.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970d3783",
   "metadata": {},
   "source": [
    "# Option 2: This portion combines all .wav files containing songs into 1-minute recordings, then  generates spectrograms of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0934973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Saved detected_song_minute_1.wav\n",
      "✅  Saved detected_song_minute_2.wav\n",
      "✅  Saved detected_song_minute_3.wav\n",
      "✅  Saved detected_song_minute_4.wav\n",
      "✅  Saved detected_song_minute_5.wav\n",
      "✅  Saved detected_song_minute_6.wav\n",
      "✅  Saved detected_song_minute_7.wav\n",
      "✅  Saved detected_song_minute_8.wav\n",
      "✅  Saved detected_song_minute_9.wav\n",
      "✅  Saved detected_song_minute_10.wav\n",
      "✅  Saved detected_song_minute_11.wav\n",
      "✅  Saved detected_song_minute_12.wav\n",
      "✅  Saved detected_song_minute_13.wav\n",
      "✅  Saved detected_song_minute_14.wav\n",
      "✅  Saved detected_song_minute_15.wav\n",
      "✅  Saved detected_song_minute_16.wav\n",
      "✅  Saved detected_song_minute_17.wav\n",
      "✅  Saved detected_song_minute_18.wav\n",
      "✅  Saved detected_song_minute_19.wav\n",
      "✅  Saved detected_song_minute_20.wav\n",
      "✅  Saved detected_song_minute_21.wav\n",
      "✅  Saved detected_song_minute_22.wav\n",
      "✅  Saved detected_song_minute_23.wav\n",
      "✅  Saved detected_song_minute_24.wav\n",
      "✅  Saved detected_song_minute_25.wav\n",
      "✅  Saved detected_song_minute_26.wav\n",
      "✅  Saved detected_song_minute_27.wav\n",
      "✅  Saved detected_song_minute_28.wav\n",
      "✅  Saved detected_song_minute_29.wav\n",
      "✅  Saved detected_song_minute_30.wav\n",
      "✅  Saved detected_song_minute_31.wav\n",
      "✅  Saved detected_song_minute_32.wav\n",
      "✅  Saved detected_song_minute_33.wav\n",
      "✅  Saved detected_song_minute_34.wav\n",
      "✅  Saved detected_song_minute_35.wav\n",
      "✅  Saved detected_song_minute_36.wav\n",
      "✅  Saved detected_song_minute_37.wav\n",
      "✅  Saved detected_song_minute_38.wav\n",
      "✅  Saved detected_song_minute_39.wav\n",
      "✅  Saved detected_song_minute_40.wav\n",
      "✅  Saved detected_song_minute_41.wav\n",
      "✅  Saved detected_song_minute_42.wav\n",
      "✅  Saved detected_song_minute_43.wav\n",
      "✅  Saved detected_song_minute_44.wav\n",
      "✅  Saved detected_song_minute_45.wav\n",
      "✅  Saved detected_song_minute_46.wav\n",
      "✅  Saved detected_song_minute_47.wav\n",
      "✅  Saved detected_song_minute_48.wav\n",
      "✅  Saved detected_song_minute_49.wav\n",
      "✅  Saved detected_song_minute_50.wav\n",
      "✅  Saved detected_song_minute_51.wav\n",
      "✅  Saved detected_song_minute_52.wav\n",
      "✅  Saved detected_song_minute_53.wav\n",
      "✅  Saved detected_song_minute_54.wav\n",
      "✅  Saved detected_song_minute_55.wav\n",
      "✅  Saved detected_song_minute_56.wav\n",
      "✅  Saved detected_song_minute_57.wav\n",
      "✅  Saved detected_song_minute_58.wav\n",
      "✅  Saved detected_song_minute_59.wav\n",
      "✅  Saved detected_song_minute_60.wav\n",
      "📄  Metadata saved to: /Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33/detected_song_files_full_recordings/segment_metadata.json\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from pathlib import Path   # (unused but often handy)\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# CONFIG ── update these two paths only\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "# folder_path = '/your/recordings/folder'\n",
    "# json_path   = '/your/detector_output.json'\n",
    "\n",
    "# ── derived paths ──────────────────────────────────────────────────────\n",
    "output_folder       = os.path.join(folder_path, 'detected_song_files_full_recordings')\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "metadata_output_path = os.path.join(output_folder, 'segment_metadata.json')\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# LOAD detector JSON  →  {wav_file : [[start,end], …]}\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "with open(json_path) as f:\n",
    "    detected_intervals = json.load(f)\n",
    "\n",
    "# process files in deterministic order\n",
    "file_names = sorted(detected_intervals.keys())\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# READ all wavs into memory (could be streamed if very large files)\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "audio_queue            = []            # [(file_name, data)]\n",
    "sample_rate_reference  = None\n",
    "\n",
    "for fn in file_names:\n",
    "    wav_path = os.path.join(folder_path, fn)\n",
    "    if not os.path.exists(wav_path):\n",
    "        print(f\"⚠️  Missing file: {fn}\")\n",
    "        continue\n",
    "    try:\n",
    "        sr, data = wavfile.read(wav_path)\n",
    "        if sample_rate_reference is None:\n",
    "            sample_rate_reference = sr\n",
    "        elif sr != sample_rate_reference:\n",
    "            raise ValueError(f\"Sample‑rate mismatch in {fn} ({sr} vs {sample_rate_reference})\")\n",
    "        if data.ndim > 1:                       # stereo → mono\n",
    "            data = data.mean(axis=1)\n",
    "        audio_queue.append((fn, data.astype(np.float32)))\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Error reading {fn}: {e}\")\n",
    "\n",
    "if not audio_queue:\n",
    "    raise RuntimeError(\"No audio files were loaded successfully.\")\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# CHUNKING variables & helpers\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "minute_samples      = 60 * sample_rate_reference\n",
    "leftover            = np.array([], dtype=np.float32)\n",
    "leftover_provenance = []      # list of dicts: {\"source_file\", \"range_start\", \"range_end\"}\n",
    "segment_metadata    = {}\n",
    "chunk_count         = 0\n",
    "\n",
    "def get_song_segments_within_range(source_file, range_start, range_end):\n",
    "    \"\"\"Return detector intervals (sec) that overlap [range_start, range_end) in sample coords,\n",
    "       expressed relative to the *start of that range*.\"\"\"\n",
    "    out = []\n",
    "    for t_start, t_end in detected_intervals.get(source_file, []):\n",
    "        s_start = int(t_start * sample_rate_reference)\n",
    "        s_end   = int(t_end   * sample_rate_reference)\n",
    "        ov_start = max(s_start, range_start)\n",
    "        ov_end   = min(s_end,   range_end)\n",
    "        if ov_start < ov_end:\n",
    "            out.append([\n",
    "                round((ov_start - range_start) / sample_rate_reference, 3),\n",
    "                round((ov_end   - range_start) / sample_rate_reference, 3)\n",
    "            ])\n",
    "    return out\n",
    "\n",
    "def finalize_chunk(chunk_data, provenance, song_segments, idx):\n",
    "    fname = f'detected_song_minute_{idx+1}.wav'\n",
    "    fpath = os.path.join(output_folder, fname)\n",
    "    wavfile.write(fpath, sample_rate_reference, chunk_data.astype(np.int16))\n",
    "    segment_metadata[fname] = {\n",
    "        \"source_files\": provenance,\n",
    "        \"song_segments_in_chunk\": song_segments\n",
    "    }\n",
    "    print(f\"✅  Saved {fname}\")\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# MAIN loop – stitch files, slice 60‑s chunks, preserve provenance\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "for file_name, data in audio_queue:\n",
    "\n",
    "    # 1) build new \"combined\" buffer = leftover + current file\n",
    "    combined         = np.concatenate([leftover, data])\n",
    "    combined_ranges  = []          # [{\"source_file\", \"range_start\", \"range_end\"}]\n",
    "    offset           = 0\n",
    "\n",
    "    # carry forward *all* leftover provenance\n",
    "    for prov in leftover_provenance:\n",
    "        dur = prov[\"range_end\"] - prov[\"range_start\"]\n",
    "        combined_ranges.append({\n",
    "            \"source_file\": prov[\"source_file\"],\n",
    "            \"range_start\": offset,\n",
    "            \"range_end\":   offset + dur\n",
    "        })\n",
    "        offset += dur\n",
    "\n",
    "    # append current file’s span\n",
    "    combined_ranges.append({\n",
    "        \"source_file\": file_name,\n",
    "        \"range_start\": offset,\n",
    "        \"range_end\":   offset + len(data)\n",
    "    })\n",
    "\n",
    "    # 2) slice full‑minute chunks\n",
    "    cursor = 0\n",
    "    while cursor + minute_samples <= len(combined):\n",
    "        chunk               = combined[cursor:cursor + minute_samples]\n",
    "        chunk_provenance    = []\n",
    "        chunk_song_segments = []\n",
    "\n",
    "        chunk_start = cursor\n",
    "        chunk_end   = cursor + minute_samples\n",
    "\n",
    "        for rng in combined_ranges:\n",
    "            src_start, src_end = rng[\"range_start\"], rng[\"range_end\"]\n",
    "            ov_start = max(chunk_start, src_start)\n",
    "            ov_end   = min(chunk_end,   src_end)\n",
    "            if ov_start < ov_end:   # overlap exists\n",
    "                # provenance entry\n",
    "                rel_start_sec = (ov_start - chunk_start) / sample_rate_reference\n",
    "                rel_end_sec   = (ov_end   - chunk_start) / sample_rate_reference\n",
    "                chunk_provenance.append({\n",
    "                    \"source_file\": rng[\"source_file\"],\n",
    "                    \"time_range_in_chunk_seconds\": [round(rel_start_sec,3),\n",
    "                                                   round(rel_end_sec,3)]\n",
    "                })\n",
    "                # song segments from this slice\n",
    "                slice_rel_start = ov_start - src_start\n",
    "                slice_rel_end   = ov_end   - src_start\n",
    "                for seg in get_song_segments_within_range(\n",
    "                        rng[\"source_file\"], slice_rel_start, slice_rel_end):\n",
    "                    chunk_song_segments.append([\n",
    "                        round(seg[0] + rel_start_sec, 3),\n",
    "                        round(seg[1] + rel_start_sec, 3)\n",
    "                    ])\n",
    "\n",
    "        finalize_chunk(chunk, chunk_provenance, chunk_song_segments, chunk_count)\n",
    "        chunk_count += 1\n",
    "        cursor      += minute_samples\n",
    "\n",
    "    # 3) whatever is left < 60 s → carry to next iteration\n",
    "    leftover = combined[cursor:]\n",
    "    leftover_provenance = []\n",
    "    if len(leftover) > 0:\n",
    "        for rng in combined_ranges:\n",
    "            if rng[\"range_end\"] > cursor:                      # part survives\n",
    "                leftover_provenance.append({\n",
    "                    \"source_file\": rng[\"source_file\"],\n",
    "                    \"range_start\": max(0,   rng[\"range_start\"] - cursor),\n",
    "                    \"range_end\":   rng[\"range_end\"] - cursor\n",
    "                })\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# FINAL (possibly padded) chunk made from leftover audio\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "if len(leftover) > 0:\n",
    "    padded = np.pad(leftover, (0, minute_samples - len(leftover)), mode=\"constant\")\n",
    "    final_prov  = []\n",
    "    final_segs  = []\n",
    "    for rng in leftover_provenance:\n",
    "        p_start_sec = rng[\"range_start\"] / sample_rate_reference\n",
    "        p_end_sec   = rng[\"range_end\"]   / sample_rate_reference\n",
    "        final_prov.append({\n",
    "            \"source_file\": rng[\"source_file\"],\n",
    "            \"time_range_in_chunk_seconds\": [round(p_start_sec,3), round(p_end_sec,3)]\n",
    "        })\n",
    "        for seg in get_song_segments_within_range(\n",
    "                rng[\"source_file\"], 0, rng[\"range_end\"] - rng[\"range_start\"]):\n",
    "            final_segs.append([\n",
    "                round(seg[0] + p_start_sec, 3),\n",
    "                round(seg[1] + p_start_sec, 3)\n",
    "            ])\n",
    "    finalize_chunk(padded, final_prov, final_segs, chunk_count)\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# WRITE master metadata file\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "with open(metadata_output_path, \"w\") as f:\n",
    "    json.dump(segment_metadata, f, indent=2)\n",
    "\n",
    "print(f\"📄  Metadata saved to: {metadata_output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a84cd4",
   "metadata": {},
   "source": [
    "## Generate the spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf898c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Saved USA5288_2025-04-08_detected_song_minute_1.wav\n",
      "✅  Saved USA5288_2025-04-08_detected_song_minute_2.wav\n",
      "\n",
      "📄  Metadata saved to: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5288_testing_pipeline/detected_song_files_full_recordings/segment_metadata.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Batch‑render spectrograms for detected‑song minute clips and (re)name the\n",
    "clips themselves with a clearer convention:\n",
    "\n",
    "    <animal_id>_<recording_date>_detected_song_file_minute_<n>.wav\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram, windows, ellip, filtfilt\n",
    "import tkinter as tk\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# REQUIRED: identify the bird and the recording\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "animal_id       = \"USA5207\"      # ← EDIT\n",
    "recording_date  = \"2025-07-19\"   # ← EDIT  (YYYY‑MM‑DD)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# PATHS  (point base_folder at the directory that HOLDS the .wav clips)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "base_folder     = Path(\n",
    "    \"/path/to/detected_song_files_full_recordings\"\n",
    ").expanduser().resolve()\n",
    "\n",
    "spectrogram_out = base_folder / \"spectrograms\"           # PNGs here\n",
    "spectrogram_out.mkdir(exist_ok=True)\n",
    "\n",
    "# Optional: if you have metadata, load it; otherwise use empty dict\n",
    "metadata_json   = base_folder / \"segment_metadata.json\"\n",
    "if metadata_json.is_file():\n",
    "    with metadata_json.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        segment_metadata = json.load(f)\n",
    "else:\n",
    "    segment_metadata = {}\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# Figure dimensions helper\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def get_screen_inches() -> Tuple[float, float]:\n",
    "    try:\n",
    "        root = tk.Tk(); root.withdraw()\n",
    "        w, h = root.winfo_screenwidth(), root.winfo_screenheight()\n",
    "        root.destroy()\n",
    "        return w / 100, h / 100\n",
    "    except Exception:\n",
    "        return 12, 8\n",
    "\n",
    "width_inches, height_inches = get_screen_inches()\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# Spectrogram rendering for one clip\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def render_clip(wav_path: Path,\n",
    "                segment_duration: int = 10,\n",
    "                panels_per_fig: int = 6,\n",
    "                low_cut: int = 500,\n",
    "                high_cut: int = 8000) -> None:\n",
    "\n",
    "    base_name = wav_path.stem\n",
    "    sr, data = wavfile.read(wav_path)\n",
    "    if data.ndim > 1:\n",
    "        data = data.mean(axis=1)\n",
    "    if np.issubdtype(data.dtype, np.integer):\n",
    "        data = data.astype(np.float32)\n",
    "\n",
    "    # band‑pass\n",
    "    nyq = sr / 2\n",
    "    b, a = ellip(5, 0.2, 40, [low_cut / nyq, high_cut / nyq], btype='band')\n",
    "    data = filtfilt(b, a, data)\n",
    "\n",
    "    total_secs        = data.size / sr\n",
    "    samples_per_panel = int(segment_duration * sr)\n",
    "    n_panels          = min(panels_per_fig, int(np.ceil(total_secs / segment_duration)))\n",
    "\n",
    "    # annotations\n",
    "    meta_key       = f\"{wav_path.name}\"\n",
    "    song_intervals = segment_metadata.get(meta_key, {}).get(\"song_segments_in_chunk\", [])\n",
    "    boundary_lines = [src[\"time_range_in_chunk_seconds\"][1]\n",
    "                      for src in segment_metadata.get(meta_key, {}).get(\"source_files\", [])\n",
    "                      if \"time_range_in_chunk_seconds\" in src]\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        n_panels, 1, figsize=(width_inches, height_inches),\n",
    "        sharex=True, gridspec_kw={\"hspace\": 0.0}\n",
    "    )\n",
    "    axs = [axs] if n_panels == 1 else axs\n",
    "\n",
    "    for idx in range(n_panels):\n",
    "        start_sample = idx * samples_per_panel\n",
    "        panel = data[start_sample:start_sample + samples_per_panel]\n",
    "        if panel.size < samples_per_panel:                       # zero‑pad last panel\n",
    "            panel = np.pad(panel, (0, samples_per_panel - panel.size))\n",
    "\n",
    "        f, t, Sxx = spectrogram(\n",
    "            panel, fs=sr,\n",
    "            window=windows.gaussian(2048, std=2048/8),\n",
    "            nperseg=2048, noverlap=2048 - 119\n",
    "        )\n",
    "        S_log  = 10 * np.log10(Sxx + np.finfo(float).eps)\n",
    "        S_log  = np.clip(S_log, a_min=3, a_max=None)\n",
    "        S_norm = (S_log - S_log.min()) / (S_log.ptp() or 1)\n",
    "        S_norm **= 0.7\n",
    "\n",
    "        axs[idx].imshow(\n",
    "            S_norm, aspect='auto', origin='lower',\n",
    "            extent=[0, segment_duration, f.min(), f.max()],\n",
    "            cmap='binary'\n",
    "        )\n",
    "        axs[idx].set_ylim(0, 11_000)\n",
    "        axs[idx].set_ylabel(\"Freq [Hz]\")\n",
    "\n",
    "        # yellow song spans\n",
    "        p0, p1 = idx * segment_duration, (idx + 1) * segment_duration\n",
    "        for s0, s1 in song_intervals:\n",
    "            if s0 < p1 and s1 > p0:\n",
    "                x0, x1 = max(0, s0 - p0), min(segment_duration, s1 - p0)\n",
    "                axs[idx].axvspan(x0, x1, color='yellow', alpha=0.1)\n",
    "\n",
    "        # red dashed boundaries\n",
    "        for b in boundary_lines:\n",
    "            if p0 < b < p1:\n",
    "                axs[idx].axvline(b - p0, color='red', linestyle='--', linewidth=1.2)\n",
    "\n",
    "        if idx == n_panels - 1:\n",
    "            axs[idx].set_xlabel(\"Time [s]\")\n",
    "            axs[idx].set_xticks(np.linspace(0, segment_duration, 5))\n",
    "\n",
    "    fig.suptitle(f\"{base_name} – Spectrogram ({low_cut}-{high_cut} Hz)\", fontsize=14)\n",
    "    fig.tight_layout()\n",
    "    out_png = spectrogram_out / f\"{base_name}_spectrogram.png\"\n",
    "    fig.savefig(out_png, dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(f\"✅ spectrogram → {out_png.name}\")\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# Batch rename clips, update metadata map, and render\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "wav_files: List[Path] = sorted(base_folder.glob(\"*.wav\"))\n",
    "if not wav_files:\n",
    "    raise FileNotFoundError(f\"No .wav clips found in {base_folder}\")\n",
    "\n",
    "print(f\"\\n📂 Found {len(wav_files)} clips – renaming & rendering …\\n\")\n",
    "\n",
    "for idx, old_path in enumerate(wav_files, start=1):\n",
    "    new_name = f\"{animal_id}_{recording_date}_detected_song_file_minute_{idx}.wav\"\n",
    "    new_path = old_path.with_name(new_name)\n",
    "\n",
    "    # rename on disk (skip if already correct)\n",
    "    if old_path.name != new_name:\n",
    "        old_path.rename(new_path)\n",
    "\n",
    "    # make metadata accessible under new filename (in‑memory only)\n",
    "    if old_path.name in segment_metadata and new_name not in segment_metadata:\n",
    "        segment_metadata[new_name] = segment_metadata[old_path.name]\n",
    "\n",
    "    # render spectrogram\n",
    "    render_clip(new_path)\n",
    "\n",
    "print(\"\\nDone!  Spectrograms in:\", spectrogram_out.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a131047",
   "metadata": {},
   "source": [
    "### generate the spectrogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63a67a07",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33/detected_song_files_full_recordings/spectrograms'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 35\u001b[0m\n\u001b[1;32m     30\u001b[0m base_folder     \u001b[38;5;241m=\u001b[39m Path(\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33/detected_song_files_full_recordings\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     32\u001b[0m )\u001b[38;5;241m.\u001b[39mexpanduser()\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[1;32m     34\u001b[0m spectrogram_out \u001b[38;5;241m=\u001b[39m base_folder \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspectrograms\u001b[39m\u001b[38;5;124m\"\u001b[39m           \u001b[38;5;66;03m# PNGs here\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[43mspectrogram_out\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Optional: if you have metadata, load it; otherwise use empty dict\u001b[39;00m\n\u001b[1;32m     38\u001b[0m metadata_json   \u001b[38;5;241m=\u001b[39m base_folder \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegment_metadata.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/BYOD_class/lib/python3.9/pathlib.py:1323\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;124;03mCreate a new directory at this given path.\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1323\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33/detected_song_files_full_recordings/spectrograms'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Batch‑render spectrograms for detected‑song minute clips and (re)name the\n",
    "clips themselves with a clearer convention:\n",
    "\n",
    "    <animal_id>_<recording_date>_detected_song_file_minute_<n>.wav\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram, windows, ellip, filtfilt\n",
    "import tkinter as tk\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# REQUIRED: identify the bird and the recording\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "animal_id       = \"USA5207\"      # ← EDIT\n",
    "recording_date  = \"2025-07-19\"   # ← EDIT  (YYYY‑MM‑DD)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# PATHS  (point base_folder at the directory that HOLDS the .wav clips)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "base_folder     = Path(\n",
    "    \"/Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33/detected_song_files_full_recordings\"\n",
    ").expanduser().resolve()\n",
    "\n",
    "spectrogram_out = base_folder / \"spectrograms\"           # PNGs here\n",
    "spectrogram_out.mkdir(exist_ok=True)\n",
    "\n",
    "# Optional: if you have metadata, load it; otherwise use empty dict\n",
    "metadata_json   = base_folder / \"segment_metadata.json\"\n",
    "if metadata_json.is_file():\n",
    "    with metadata_json.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        segment_metadata = json.load(f)\n",
    "else:\n",
    "    segment_metadata = {}\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# Figure dimensions helper\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def get_screen_inches() -> Tuple[float, float]:\n",
    "    try:\n",
    "        root = tk.Tk(); root.withdraw()\n",
    "        w, h = root.winfo_screenwidth(), root.winfo_screenheight()\n",
    "        root.destroy()\n",
    "        return w / 100, h / 100\n",
    "    except Exception:\n",
    "        return 12, 8\n",
    "\n",
    "width_inches, height_inches = get_screen_inches()\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# Spectrogram rendering for one clip\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def render_clip(wav_path: Path,\n",
    "                segment_duration: int = 10,\n",
    "                panels_per_fig: int = 6,\n",
    "                low_cut: int = 500,\n",
    "                high_cut: int = 8000) -> None:\n",
    "\n",
    "    base_name = wav_path.stem\n",
    "    sr, data = wavfile.read(wav_path)\n",
    "    if data.ndim > 1:\n",
    "        data = data.mean(axis=1)\n",
    "    if np.issubdtype(data.dtype, np.integer):\n",
    "        data = data.astype(np.float32)\n",
    "\n",
    "    # band‑pass\n",
    "    nyq = sr / 2\n",
    "    b, a = ellip(5, 0.2, 40, [low_cut / nyq, high_cut / nyq], btype='band')\n",
    "    data = filtfilt(b, a, data)\n",
    "\n",
    "    total_secs        = data.size / sr\n",
    "    samples_per_panel = int(segment_duration * sr)\n",
    "    n_panels          = min(panels_per_fig, int(np.ceil(total_secs / segment_duration)))\n",
    "\n",
    "    # annotations\n",
    "    meta_key       = f\"{wav_path.name}\"\n",
    "    song_intervals = segment_metadata.get(meta_key, {}).get(\"song_segments_in_chunk\", [])\n",
    "    boundary_lines = [src[\"time_range_in_chunk_seconds\"][1]\n",
    "                      for src in segment_metadata.get(meta_key, {}).get(\"source_files\", [])\n",
    "                      if \"time_range_in_chunk_seconds\" in src]\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        n_panels, 1, figsize=(width_inches, height_inches),\n",
    "        sharex=True, gridspec_kw={\"hspace\": 0.0}\n",
    "    )\n",
    "    axs = [axs] if n_panels == 1 else axs\n",
    "\n",
    "    for idx in range(n_panels):\n",
    "        start_sample = idx * samples_per_panel\n",
    "        panel = data[start_sample:start_sample + samples_per_panel]\n",
    "        if panel.size < samples_per_panel:                       # zero‑pad last panel\n",
    "            panel = np.pad(panel, (0, samples_per_panel - panel.size))\n",
    "\n",
    "        f, t, Sxx = spectrogram(\n",
    "            panel, fs=sr,\n",
    "            window=windows.gaussian(2048, std=2048/8),\n",
    "            nperseg=2048, noverlap=2048 - 119\n",
    "        )\n",
    "        S_log  = 10 * np.log10(Sxx + np.finfo(float).eps)\n",
    "        S_log  = np.clip(S_log, a_min=3, a_max=None)\n",
    "        S_norm = (S_log - S_log.min()) / (S_log.ptp() or 1)\n",
    "        S_norm **= 0.7\n",
    "\n",
    "        axs[idx].imshow(\n",
    "            S_norm, aspect='auto', origin='lower',\n",
    "            extent=[0, segment_duration, f.min(), f.max()],\n",
    "            cmap='binary'\n",
    "        )\n",
    "        axs[idx].set_ylim(0, 11_000)\n",
    "        axs[idx].set_ylabel(\"Freq [Hz]\")\n",
    "\n",
    "        # yellow song spans\n",
    "        p0, p1 = idx * segment_duration, (idx + 1) * segment_duration\n",
    "        for s0, s1 in song_intervals:\n",
    "            if s0 < p1 and s1 > p0:\n",
    "                x0, x1 = max(0, s0 - p0), min(segment_duration, s1 - p0)\n",
    "                axs[idx].axvspan(x0, x1, color='yellow', alpha=0.1)\n",
    "\n",
    "        # red dashed boundaries\n",
    "        for b in boundary_lines:\n",
    "            if p0 < b < p1:\n",
    "                axs[idx].axvline(b - p0, color='red', linestyle='--', linewidth=1.2)\n",
    "\n",
    "        if idx == n_panels - 1:\n",
    "            axs[idx].set_xlabel(\"Time [s]\")\n",
    "            axs[idx].set_xticks(np.linspace(0, segment_duration, 5))\n",
    "\n",
    "    fig.suptitle(f\"{base_name} – Spectrogram ({low_cut}-{high_cut} Hz)\", fontsize=14)\n",
    "    fig.tight_layout()\n",
    "    out_png = spectrogram_out / f\"{base_name}_spectrogram.png\"\n",
    "    fig.savefig(out_png, dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(f\"✅ spectrogram → {out_png.name}\")\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# Batch rename clips, update metadata map, and render\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "wav_files: List[Path] = sorted(base_folder.glob(\"*.wav\"))\n",
    "if not wav_files:\n",
    "    raise FileNotFoundError(f\"No .wav clips found in {base_folder}\")\n",
    "\n",
    "print(f\"\\n📂 Found {len(wav_files)} clips – renaming & rendering …\\n\")\n",
    "\n",
    "for idx, old_path in enumerate(wav_files, start=1):\n",
    "    new_name = f\"{animal_id}_{recording_date}_detected_song_file_minute_{idx}.wav\"\n",
    "    new_path = old_path.with_name(new_name)\n",
    "\n",
    "    # rename on disk (skip if already correct)\n",
    "    if old_path.name != new_name:\n",
    "        old_path.rename(new_path)\n",
    "\n",
    "    # make metadata accessible under new filename (in‑memory only)\n",
    "    if old_path.name in segment_metadata and new_name not in segment_metadata:\n",
    "        segment_metadata[new_name] = segment_metadata[old_path.name]\n",
    "\n",
    "    # render spectrogram\n",
    "    render_clip(new_path)\n",
    "\n",
    "print(\"\\nDone!  Spectrograms in:\", spectrogram_out.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25e9d1a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Cannot find /Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33/segment_metadata.json",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 55\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# ────────────────────────────────────────────────────────────────\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# LOAD metadata  ➜  {filename.wav: {...}}\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# ────────────────────────────────────────────────────────────────\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m metadata_path\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetadata_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m metadata_path\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     58\u001b[0m     segment_metadata: Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find /Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33/segment_metadata.json"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Render spectrograms for every *_detected_song_minute_*.wav created by the\n",
    "“full‑recordings” segmenter, using the provenance stored in segment_metadata.json\n",
    "to annotate:\n",
    "  • yellow spans  = song intervals\n",
    "  • red dashed line = boundary between concatenated source files\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram, windows, ellip, filtfilt\n",
    "import tkinter as tk\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# USER – point this at *the same* output folder the segmenter wrote\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "output_folder = Path(\n",
    "    \"/Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33\"\n",
    ")\n",
    "\n",
    "metadata_path = output_folder / \"segment_metadata.json\"\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# CONSTANTS\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "segment_duration   = 10        # seconds per panel\n",
    "panels_per_fig     = 6         # => 60 s total per PNG\n",
    "low_cut, high_cut  = 500, 8000 # Hz band‑pass before spectrogram\n",
    "cmap_choice        = \"binary\"  # greyscale‑ish\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# HELPER – figure size in inches (fallback if headless)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def get_screen_inches() -> Tuple[float, float]:\n",
    "    try:\n",
    "        root = tk.Tk(); root.withdraw()\n",
    "        w, h = root.winfo_screenwidth(), root.winfo_screenheight()\n",
    "        root.destroy()\n",
    "        return w / 100, h / 100\n",
    "    except Exception:\n",
    "        return 12, 8                  # safe default for headless servers\n",
    "\n",
    "width_inches, height_inches = get_screen_inches()\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# LOAD metadata  ➜  {filename.wav: {...}}\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "if not metadata_path.is_file():\n",
    "    raise FileNotFoundError(f\"Cannot find {metadata_path}\")\n",
    "\n",
    "with metadata_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    segment_metadata: Dict[str, dict] = json.load(f)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# PREP output PNG folder\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "png_folder = output_folder / \"spectrograms\"\n",
    "png_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# CORE – process ONE detected‑song clip\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def process_wav_file(wav_path: Path):\n",
    "    base_name = wav_path.stem                         # no .wav\n",
    "    meta_key  = wav_path.name                         # with .wav\n",
    "\n",
    "    # ---- load audio ------------------------------------------------------\n",
    "    sr, data = wavfile.read(wav_path)\n",
    "    if data.ndim > 1:\n",
    "        data = data.mean(axis=1)\n",
    "    if np.issubdtype(data.dtype, np.integer):\n",
    "        data = data.astype(np.float32)\n",
    "\n",
    "    # ---- band‑pass filter ------------------------------------------------\n",
    "    nyq = sr / 2\n",
    "    b, a = ellip(5, 0.2, 40, [low_cut / nyq, high_cut / nyq], btype=\"band\")\n",
    "    data = filtfilt(b, a, data)\n",
    "\n",
    "    total_secs        = data.size / sr\n",
    "    samples_per_panel = int(segment_duration * sr)\n",
    "    n_panels          = min(panels_per_fig, int(np.ceil(total_secs / segment_duration)))\n",
    "\n",
    "    # ---- song intervals & boundary lines ---------------------------------\n",
    "    song_intervals: List[List[float]] = []\n",
    "    boundary_lines: List[float]       = []\n",
    "\n",
    "    meta = segment_metadata.get(meta_key, {})\n",
    "    song_intervals = meta.get(\"song_segments_in_chunk\", [])\n",
    "    for src in meta.get(\"source_files\", []):\n",
    "        boundary_lines.append(src[\"time_range_in_chunk_seconds\"][1])\n",
    "    # drop the final boundary at 60 s (just the end of the clip)\n",
    "    boundary_lines = [b for b in boundary_lines if b < panels_per_fig * segment_duration]\n",
    "\n",
    "    # ---- plotting --------------------------------------------------------\n",
    "    fig, axs = plt.subplots(\n",
    "        n_panels, 1,\n",
    "        figsize=(width_inches, height_inches),\n",
    "        sharex=True, gridspec_kw={\"hspace\": 0.0}\n",
    "    )\n",
    "    axs = [axs] if n_panels == 1 else axs\n",
    "\n",
    "    for i in range(n_panels):\n",
    "        start_samp = i * samples_per_panel\n",
    "        seg = data[start_samp : start_samp + samples_per_panel]\n",
    "        if seg.size < samples_per_panel:\n",
    "            seg = np.pad(seg, (0, samples_per_panel - seg.size))\n",
    "\n",
    "        f, t, Sxx = spectrogram(\n",
    "            seg, fs=sr,\n",
    "            window=windows.gaussian(2048, std=2048/8),\n",
    "            nperseg=2048, noverlap=2048 - 119\n",
    "        )\n",
    "        S_log  = 10 * np.log10(Sxx + np.finfo(float).eps)\n",
    "        S_log  = np.clip(S_log, a_min=3, a_max=None)\n",
    "        S_norm = (S_log - S_log.min()) / (S_log.ptp() or 1.0)\n",
    "        S_norm **= 0.7\n",
    "\n",
    "        axs[i].imshow(\n",
    "            S_norm, aspect=\"auto\", origin=\"lower\",\n",
    "            extent=[0, segment_duration, f.min(), f.max()],\n",
    "            cmap=cmap_choice\n",
    "        )\n",
    "        axs[i].set_ylim(0, 11000)\n",
    "        axs[i].set_ylabel(\"Freq [Hz]\")\n",
    "\n",
    "        # ---- yellow song highlights -------------------------------------\n",
    "        panel_t0 = i * segment_duration\n",
    "        panel_t1 = panel_t0 + segment_duration\n",
    "        for s0, s1 in song_intervals:\n",
    "            if s0 < panel_t1 and s1 > panel_t0:\n",
    "                axs[i].axvspan(max(0, s0-panel_t0),\n",
    "                               min(segment_duration, s1-panel_t0),\n",
    "                               color=\"yellow\", alpha=0.10)\n",
    "\n",
    "        # ---- red dashed boundaries --------------------------------------\n",
    "        for b_t in boundary_lines:\n",
    "            if panel_t0 < b_t < panel_t1:\n",
    "                axs[i].axvline(b_t - panel_t0, color=\"red\",\n",
    "                               linestyle=\"--\", linewidth=1.2)\n",
    "\n",
    "        if i == n_panels - 1:\n",
    "            axs[i].set_xlabel(\"Time [s]\")\n",
    "            axs[i].set_xticks(np.linspace(0, segment_duration, 5))\n",
    "\n",
    "    fig.suptitle(f\"{base_name}  –  Spectrogram ({low_cut}-{high_cut} Hz)\", fontsize=14)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    out_png = png_folder / f\"{base_name}_spectrogram.png\"\n",
    "    fig.savefig(out_png, dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(\"✅\", out_png.name)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# BATCH over every *_detected_song_minute_*.wav\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "wav_files = sorted(output_folder.glob(\"*_detected_song_minute_*.wav\"))\n",
    "if not wav_files:\n",
    "    raise FileNotFoundError(\"No *_detected_song_minute_*.wav files found in\\n\"\n",
    "                            f\"  {output_folder}\")\n",
    "\n",
    "print(f\"\\n📂 Rendering {len(wav_files)} spectrograms …\\n\")\n",
    "for w in wav_files:\n",
    "    process_wav_file(w)\n",
    "\n",
    "print(\"\\nDone!  PNGs saved to:\", png_folder.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f445dfe",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No *_detected_song_minute_*.wav files found in\n  /Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33/detected_song_files_full_recordings",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 186\u001b[0m\n\u001b[1;32m    184\u001b[0m wav_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(detected_folder\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*_detected_song_minute_*.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m wav_files:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo *_detected_song_minute_*.wav files found in\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdetected_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m     )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m📂 Rendering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(wav_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m spectrograms …\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m wav_files:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No *_detected_song_minute_*.wav files found in\n  /Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33/detected_song_files_full_recordings"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Render spectrograms for every *_detected_song_minute_*.wav created by the\n",
    "“full‑recordings” segmenter.\n",
    "\n",
    "SETUP\n",
    "-----\n",
    "1.  Set `base_folder` to the directory that contains the sub‑folder\n",
    "    “detected_song_files_full_recordings”.\n",
    "2.  That sub‑folder must hold *both* the *_detected_song_minute_*.wav clips\n",
    "    and the file **segment_metadata.json**.\n",
    "\n",
    "The script draws:\n",
    "  • yellow spans        = song intervals  \n",
    "  • red dashed lines    = boundaries between concatenated source files\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram, windows, ellip, filtfilt\n",
    "import tkinter as tk\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# USER – set this to the experiment folder\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "base_folder = Path(\n",
    "    \"/Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33\"\n",
    ").expanduser().resolve()\n",
    "\n",
    "# All detected clips + metadata live down here ⬇︎\n",
    "detected_folder = base_folder / \"detected_song_files_full_recordings\"\n",
    "metadata_path   = detected_folder / \"segment_metadata.json\"\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# CONSTANTS\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "segment_duration   = 10        # seconds per panel\n",
    "panels_per_fig     = 6         # => 60 s total per PNG\n",
    "low_cut, high_cut  = 500, 8000 # Hz band‑pass before spectrogram\n",
    "cmap_choice        = \"binary\"  # greyscale‑ish\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# HELPER – figure size in inches (fallback if headless)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def get_screen_inches() -> Tuple[float, float]:\n",
    "    try:\n",
    "        root = tk.Tk(); root.withdraw()\n",
    "        w, h = root.winfo_screenwidth(), root.winfo_screenheight()\n",
    "        root.destroy()\n",
    "        return w / 100, h / 100\n",
    "    except Exception:\n",
    "        return 12, 8                  # safe default for headless servers\n",
    "\n",
    "width_inches, height_inches = get_screen_inches()\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# LOAD metadata  ➜  {filename.wav: {...}}\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "if not metadata_path.is_file():\n",
    "    raise FileNotFoundError(\n",
    "        f\"\\n❌  Cannot find metadata file:\\n    {metadata_path}\\n\\n\"\n",
    "        \"Expected directory layout:\\n\"\n",
    "        \"  base_folder/\\n\"\n",
    "        \"    └── detected_song_files_full_recordings/\\n\"\n",
    "        \"          ├── *_detected_song_minute_*.wav\\n\"\n",
    "        \"          └── segment_metadata.json\"\n",
    "    )\n",
    "\n",
    "with metadata_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    segment_metadata: Dict[str, dict] = json.load(f)\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# PREP output PNG folder\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "png_folder = detected_folder / \"spectrograms\"\n",
    "png_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# CORE – process ONE detected‑song clip\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def process_wav_file(wav_path: Path):\n",
    "    base_name = wav_path.stem\n",
    "    meta_key  = wav_path.name\n",
    "\n",
    "    # ---- load audio ------------------------------------------------------\n",
    "    sr, data = wavfile.read(wav_path)\n",
    "    if data.ndim > 1:\n",
    "        data = data.mean(axis=1)\n",
    "    if np.issubdtype(data.dtype, np.integer):\n",
    "        data = data.astype(np.float32)\n",
    "\n",
    "    # ---- band‑pass filter ------------------------------------------------\n",
    "    nyq = sr / 2\n",
    "    b, a = ellip(5, 0.2, 40, [low_cut / nyq, high_cut / nyq], btype=\"band\")\n",
    "    data = filtfilt(b, a, data)\n",
    "\n",
    "    total_secs        = data.size / sr\n",
    "    samples_per_panel = int(segment_duration * sr)\n",
    "    n_panels          = min(panels_per_fig, int(np.ceil(total_secs / segment_duration)))\n",
    "\n",
    "    # ---- song intervals & boundary lines ---------------------------------\n",
    "    song_intervals: List[List[float]] = []\n",
    "    boundary_lines: List[float]       = []\n",
    "\n",
    "    meta = segment_metadata.get(meta_key, {})\n",
    "    song_intervals = meta.get(\"song_segments_in_chunk\", [])\n",
    "    for src in meta.get(\"source_files\", []):\n",
    "        boundary_lines.append(src[\"time_range_in_chunk_seconds\"][1])\n",
    "    boundary_lines = [b for b in boundary_lines if b < panels_per_fig * segment_duration]\n",
    "\n",
    "    # ---- plotting --------------------------------------------------------\n",
    "    fig, axs = plt.subplots(\n",
    "        n_panels, 1,\n",
    "        figsize=(width_inches, height_inches),\n",
    "        sharex=True, gridspec_kw={\"hspace\": 0.0}\n",
    "    )\n",
    "    axs = [axs] if n_panels == 1 else axs\n",
    "\n",
    "    for i in range(n_panels):\n",
    "        start_samp = i * samples_per_panel\n",
    "        seg = data[start_samp : start_samp + samples_per_panel]\n",
    "        if seg.size < samples_per_panel:\n",
    "            seg = np.pad(seg, (0, samples_per_panel - seg.size))\n",
    "\n",
    "        f, t, Sxx = spectrogram(\n",
    "            seg, fs=sr,\n",
    "            window=windows.gaussian(2048, std=2048/8),\n",
    "            nperseg=2048, noverlap=2048 - 119\n",
    "        )\n",
    "        S_log  = 10 * np.log10(Sxx + np.finfo(float).eps)\n",
    "        S_log  = np.clip(S_log, a_min=3, a_max=None)\n",
    "        S_norm = (S_log - S_log.min()) / (S_log.ptp() or 1.0)\n",
    "        S_norm **= 0.7\n",
    "\n",
    "        axs[i].imshow(\n",
    "            S_norm, aspect=\"auto\", origin=\"lower\",\n",
    "            extent=[0, segment_duration, f.min(), f.max()],\n",
    "            cmap=cmap_choice\n",
    "        )\n",
    "        axs[i].set_ylim(0, 11000)\n",
    "        axs[i].set_ylabel(\"Freq [Hz]\")\n",
    "\n",
    "        # ---- yellow song highlights -------------------------------------\n",
    "        panel_t0 = i * segment_duration\n",
    "        panel_t1 = panel_t0 + segment_duration\n",
    "        for s0, s1 in song_intervals:\n",
    "            if s0 < panel_t1 and s1 > panel_t0:\n",
    "                axs[i].axvspan(max(0, s0-panel_t0),\n",
    "                               min(segment_duration, s1-panel_t0),\n",
    "                               color=\"yellow\", alpha=0.10)\n",
    "\n",
    "        # ---- red dashed boundaries --------------------------------------\n",
    "        for b_t in boundary_lines:\n",
    "            if panel_t0 < b_t < panel_t1:\n",
    "                axs[i].axvline(b_t - panel_t0, color=\"red\",\n",
    "                               linestyle=\"--\", linewidth=1.2)\n",
    "\n",
    "        if i == n_panels - 1:\n",
    "            axs[i].set_xlabel(\"Time [s]\")\n",
    "            axs[i].set_xticks(np.linspace(0, segment_duration, 5))\n",
    "\n",
    "    fig.suptitle(f\"{base_name}  –  Spectrogram ({low_cut}-{high_cut} Hz)\", fontsize=14)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    out_png = png_folder / f\"{base_name}_spectrogram.png\"\n",
    "    fig.savefig(out_png, dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(\"✅\", out_png.name)\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# BATCH over every *_detected_song_minute_*.wav\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "wav_files = sorted(detected_folder.glob(\"*_detected_song_minute_*.wav\"))\n",
    "if not wav_files:\n",
    "    raise FileNotFoundError(\n",
    "        \"No *_detected_song_minute_*.wav files found in\\n\"\n",
    "        f\"  {detected_folder}\"\n",
    "    )\n",
    "\n",
    "print(f\"\\n📂 Rendering {len(wav_files)} spectrograms …\\n\")\n",
    "for w in wav_files:\n",
    "    process_wav_file(w)\n",
    "\n",
    "print(\"\\nDone!  PNGs saved to:\", png_folder.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1228e1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4149d396",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ffdded0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50401d3c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5c2157b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70bf6745",
   "metadata": {},
   "source": [
    "### Trying out different color scales for better song visibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323fc851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 Processing 2 files in /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5288_testing_pipeline/detected_song_files_full_recordings\n",
      "\n",
      "✅ Saved: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5288_testing_pipeline/detected_song_files_full_recordings/spectrograms/detected_song_minute_2_spectrogram.png\n",
      "✅ Saved: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5288_testing_pipeline/detected_song_files_full_recordings/spectrograms/detected_song_minute_1_spectrogram.png\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "# from scipy.io import wavfile\n",
    "# from scipy.signal import spectrogram, windows, ellip, filtfilt\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tkinter as tk\n",
    "# import json\n",
    "\n",
    "# # ── Utility: approximate screen size in inches (assumes 100 dpi) ─────────────\n",
    "# def get_screen_resolution():\n",
    "#     root = tk.Tk(); root.withdraw()\n",
    "#     w_px, h_px = root.winfo_screenwidth(), root.winfo_screenheight()\n",
    "#     root.destroy()\n",
    "#     return w_px / 100, h_px / 100\n",
    "\n",
    "# width_inches, height_inches = get_screen_resolution()\n",
    "\n",
    "# # ── Load your segment metadata (if you have one) ─────────────────────────────\n",
    "# # For example:\n",
    "# # with open(\"path/to/segment_metadata.json\") as f:\n",
    "# #     segment_metadata = json.load(f)\n",
    "# segment_metadata = {}  # replace with your actual metadata dict\n",
    "\n",
    "# def process_wav_file(file_path, spectrogram_folder,\n",
    "#                      segment_duration=10,\n",
    "#                      low_cut=500, high_cut=8000):\n",
    "#     try:\n",
    "#         base_name = Path(file_path).stem\n",
    "#         sr, data = wavfile.read(file_path)\n",
    "#         if data.ndim > 1:\n",
    "#             data = data.mean(axis=1)\n",
    "\n",
    "#         # === Band‑pass filter ===\n",
    "#         nyq = sr / 2\n",
    "#         b, a = ellip(5, 0.2, 40,\n",
    "#                      [low_cut/nyq, high_cut/nyq],\n",
    "#                      btype='band')\n",
    "#         data = filtfilt(b, a, data)\n",
    "\n",
    "#         # === Setup segments ===\n",
    "#         total_secs = data.size / sr\n",
    "#         seg_samps = int(segment_duration * sr)\n",
    "#         nseg = min(6, int(np.ceil(total_secs / segment_duration)))\n",
    "#         out_path = Path(spectrogram_folder) / f\"{base_name}_spectrogram.png\"\n",
    "\n",
    "#         fig, axs = plt.subplots(nseg, 1,\n",
    "#                                 figsize=(width_inches, height_inches),\n",
    "#                                 sharex=True,\n",
    "#                                 gridspec_kw={'hspace': 0})\n",
    "#         if nseg == 1:\n",
    "#             axs = [axs]\n",
    "\n",
    "#         # retrieve any song intervals / boundaries\n",
    "#         key = f\"{base_name}.wav\"\n",
    "#         song_intervals = segment_metadata.get(key, {}).get(\"song_segments_in_chunk\", [])\n",
    "#         boundaries = [src[\"time_range_in_chunk_seconds\"][1]\n",
    "#                       for src in segment_metadata.get(key, {}).get(\"source_files\", [])\n",
    "#                       if \"time_range_in_chunk_seconds\" in src]\n",
    "\n",
    "#         for i in range(nseg):\n",
    "#             start = i * seg_samps\n",
    "#             end = start + seg_samps\n",
    "#             chunk = np.zeros(seg_samps, dtype=data.dtype)\n",
    "#             if start < data.size:\n",
    "#                 chunk[:max(0, min(seg_samps, data.size - start))] = data[start:end]\n",
    "\n",
    "#             # ── compute spectrogram ──────────────────────────────────────────\n",
    "#             f, t, Sxx = spectrogram(\n",
    "#                 chunk,\n",
    "#                 fs=sr,\n",
    "#                 window=windows.gaussian(2048, std=2048/8),\n",
    "#                 nperseg=2048,\n",
    "#                 noverlap=2048 - 119\n",
    "#             )\n",
    "\n",
    "#             # ── convert to dB and clamp dynamic range ────────────────────────\n",
    "#             Sxx_dB = 10 * np.log10(Sxx + np.finfo(float).eps)\n",
    "#             vmax = Sxx_dB.max()\n",
    "#             vmin = vmax - 60   # adjust dynamic range (e.g. top 60 dB)\n",
    "#             axs[i].imshow(\n",
    "#                 Sxx_dB,\n",
    "#                 aspect='auto',\n",
    "#                 origin='lower',\n",
    "#                 extent=[0, segment_duration, f.min(), f.max()],\n",
    "#                 cmap='gray_r',\n",
    "#                 vmin=vmin,\n",
    "#                 vmax=vmax\n",
    "#             )\n",
    "#             axs[i].set_ylim(0, 11000)\n",
    "\n",
    "#             # ── yellow highlights ───────────────────────────────────────────\n",
    "#             panel_off = i * segment_duration\n",
    "#             for s0, s1 in song_intervals:\n",
    "#                 if s0 < panel_off + segment_duration and s1 > panel_off:\n",
    "#                     x0 = max(0, s0 - panel_off)\n",
    "#                     x1 = min(segment_duration, s1 - panel_off)\n",
    "#                     axs[i].axvspan(x0, x1, color='yellow', alpha=0.1)\n",
    "\n",
    "#             # ── red boundaries ───────────────────────────────────────────────\n",
    "#             for btime in boundaries:\n",
    "#                 if panel_off < btime < panel_off + segment_duration:\n",
    "#                     axs[i].axvline(btime - panel_off,\n",
    "#                                    color='red',\n",
    "#                                    linestyle='--',\n",
    "#                                    linewidth=1.2)\n",
    "\n",
    "#             axs[i].set_ylabel('Freq [Hz]')\n",
    "#             if i == nseg - 1:\n",
    "#                 axs[i].set_xlabel('Time [sec]')\n",
    "#                 axs[i].set_xticks(np.linspace(0, segment_duration, 5))\n",
    "\n",
    "#         fig.suptitle(f'{base_name} – Spectrogram (Filtered {low_cut}-{high_cut} Hz)', fontsize=14)\n",
    "#         fig.tight_layout()\n",
    "#         fig.savefig(out_path, dpi=300)\n",
    "#         plt.close(fig)\n",
    "#         print(f\"✅ Saved: {out_path}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ Error processing {file_path} – {e}\")\n",
    "\n",
    "# def batch_process_folder(folder_path, segment_duration=10):\n",
    "#     spectrogram_folder = Path(folder_path) / \"spectrograms\"\n",
    "#     spectrogram_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     wavs = list(Path(folder_path).glob(\"*.wav\"))\n",
    "#     if not wavs:\n",
    "#         print(\"No .wav files found.\")\n",
    "#         return\n",
    "\n",
    "#     print(f\"\\n📂 Processing {len(wavs)} files in {folder_path}\\n\")\n",
    "#     for wf in wavs:\n",
    "#         process_wav_file(str(wf), str(spectrogram_folder),\n",
    "#                          segment_duration=segment_duration)\n",
    "\n",
    "# # === USER CONFIGURE & RUN ===\n",
    "# if __name__ == \"__main__\":\n",
    "#     # point this to your folder of .wav files\n",
    "#     #folder = \"/path/to/your/wav_folder\"\n",
    "#     batch_process_folder(spectrogram_output_folder, segment_duration=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98f3053",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BYOD_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
