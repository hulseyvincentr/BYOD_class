{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b688551a",
   "metadata": {},
   "source": [
    "# This code uses a .json file with file names and detected song intervals, then assembles either: 1) recording segments that contain song or 2) entire files that contain song.\n",
    "\n",
    "## Both data outputs are saved in the original folder_path.\n",
    "- folder_path is a path to a folder that contains all of the .wav file recordings.\n",
    "- json_path is a path to a .json file output by a song detector code, which contains each .wav file name from folder_path and, if there was detected song, the time segments with detected song in them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64cd353",
   "metadata": {},
   "source": [
    "## Option 1: only generate spectrograms of time setgments with detected song. \n",
    "### This code uses the time segments inside of the .json file to combine songs into 1 minute .wav files containing song, then saves those .wav files and generates .pngs of their spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b698a077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "animal_id      = \"USA5207\"     # shown in the output filenames\n",
    "recording_date = \"2025-07-19\"  # YYYY‑MM‑DD              ↑\n",
    "\n",
    "# absolute **or** relative path to the folder that holds the .wav files\n",
    "folder_path = Path(\n",
    "    \"/Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33\"\n",
    ")\n",
    "\n",
    "# absolute **or** relative path to the JSON file with detected intervals\n",
    "json_path = Path(\n",
    "    \"/Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33_periodicity_only_detected_song_intervals_combined_segments.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a959ff6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Saved USA5207_2025-07-19_detected_song_segment_1.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_2.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_3.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_4.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_5.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_6.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_7.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_8.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_9.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_10.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_11.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_12.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_13.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_14.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_15.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_16.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_17.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_18.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_19.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_20.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_21.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_22.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_23.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_24.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_25.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_26.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_27.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_28.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_29.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_30.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_31.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_32.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_33.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_34.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_35.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_36.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_37.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_38.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_39.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_40.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_41.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_42.wav  (60.00 s)\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_43_partial.wav  (2.67 s)\n",
      "\n",
      "Done!  Segments are in: /Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33/detected_song_segments\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf‑8 -*-\n",
    "\"\"\"\n",
    "Slice detected song intervals out of a folder of .wav files, concatenate them,\n",
    "split into ≤ chunk_duration_sec chunks, and save the chunks with filenames that\n",
    "embed `animal_id` and `recording_date`, e.g.\n",
    "\n",
    "    USA5288_2025-04-08_detected_song_segment_3.wav\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Optional, List\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# USER‑EDITABLE METADATA\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# animal_id      = \"USA5207\"     # shown in the output filenames\n",
    "# recording_date = \"2025-07-19\"  # YYYY‑MM‑DD              ↑\n",
    "\n",
    "# # absolute **or** relative path to the folder that holds the .wav files\n",
    "# folder_path = Path(\n",
    "#     \"/Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33\"\n",
    "# )\n",
    "\n",
    "# # absolute **or** relative path to the JSON file with detected intervals\n",
    "# json_path = Path(\n",
    "#     \"/Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33_periodicity_only_detected_song_intervals_combined_segments.json\"\n",
    "# )\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# RUNTIME SETTINGS\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "chunk_duration_sec       = 60      # target length of each output clip\n",
    "save_partial_final_chunk = True    # keep a trailing < 60‑s chunk?\n",
    "pad_partial_with_zeros   = False   # …and pad it out to full length?\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# QUICK VALIDATION OF THE TWO CRITICAL PATHS\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "if not folder_path.exists():\n",
    "    raise FileNotFoundError(f\"Audio folder not found:\\n  {folder_path.resolve()}\")\n",
    "\n",
    "if not json_path.is_file():\n",
    "    raise FileNotFoundError(f\"JSON file not found:\\n  {json_path.resolve()}\")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# OUTPUT FOLDER\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "output_folder = folder_path / \"detected_song_segments\"\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# STEP 1 – load JSON with [start, end] pairs (seconds)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "with open(json_path, \"r\", encoding=\"utf‑8\") as f:\n",
    "    detected_intervals: dict[str, List[List[float]]] = json.load(f)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# STEP 2 – extract every detected interval from every file\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "detected_segments: List[np.ndarray] = []\n",
    "sample_rate_reference: Optional[int] = None\n",
    "missing_files: list[str] = []\n",
    "\n",
    "for file_name, intervals in detected_intervals.items():\n",
    "    wav_path = folder_path / file_name\n",
    "    if not wav_path.exists():\n",
    "        missing_files.append(file_name)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        samplerate, data = wavfile.read(wav_path)\n",
    "\n",
    "        # use the first file as the reference sample‑rate\n",
    "        if sample_rate_reference is None:\n",
    "            sample_rate_reference = samplerate\n",
    "        elif samplerate != sample_rate_reference:\n",
    "            raise ValueError(f\"Sample‑rate mismatch in {file_name}\")\n",
    "\n",
    "        # stereo → mono\n",
    "        if data.ndim > 1:\n",
    "            data = data.mean(axis=1)\n",
    "\n",
    "        # pull every [start, end] snippet\n",
    "        for start_time, end_time in intervals:\n",
    "            start = int(start_time * samplerate)\n",
    "            end   = int(end_time   * samplerate)\n",
    "            detected_segments.append(data[start:end])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Error reading {file_name}: {e}\")\n",
    "\n",
    "# Report any listed but missing files\n",
    "if missing_files:\n",
    "    print(\"\\n⚠️  The following files were listed in the JSON but not found in\"\n",
    "          f\" {folder_path}:\\n  • \" + \"\\n  • \".join(missing_files))\n",
    "\n",
    "if not detected_segments:\n",
    "    raise RuntimeError(\"No detected song segments were found for the paths \"\n",
    "                       \"you provided. Double‑check the folder/JSON pairing.\")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# STEP 3 – concatenate & split into ≤ chunk_duration_sec chunks\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "concatenated   = np.concatenate(detected_segments)\n",
    "target_samples = chunk_duration_sec * sample_rate_reference\n",
    "song_segments  = []\n",
    "\n",
    "for i in range(0, len(concatenated), target_samples):\n",
    "    chunk = concatenated[i : i + target_samples]\n",
    "\n",
    "    if len(chunk) == target_samples:\n",
    "        # full‑length chunk\n",
    "        song_segments.append(chunk)\n",
    "\n",
    "    elif save_partial_final_chunk and len(chunk) > 0:\n",
    "        # trailing short chunk\n",
    "        if pad_partial_with_zeros:\n",
    "            pad_len = target_samples - len(chunk)\n",
    "            chunk   = np.pad(chunk, (0, pad_len), mode=\"constant\")\n",
    "        song_segments.append(chunk)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# STEP 4 – write each chunk to disk with descriptive filename\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "for idx, segment in enumerate(song_segments, start=1):\n",
    "    duration_sec = len(segment) / sample_rate_reference\n",
    "    suffix       = \"_partial\" if duration_sec < chunk_duration_sec else \"\"\n",
    "    fname = f\"{animal_id}_{recording_date}_detected_song_segment_{idx}{suffix}.wav\"\n",
    "\n",
    "    wavfile.write(output_folder / fname,\n",
    "                  sample_rate_reference,\n",
    "                  segment.astype(np.int16))\n",
    "\n",
    "    print(f\"✅  Saved {fname}  ({duration_sec:.2f} s)\")\n",
    "\n",
    "print(\"\\nDone!  Segments are in:\", output_folder.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6689e7",
   "metadata": {},
   "source": [
    "## Generate the spectrograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fa8039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!/usr/bin/env python\n",
    "# # -*- coding: utf-8 -*-\n",
    "# \"\"\"\n",
    "# Render filtered spectrogram panels for every\n",
    "# <parent>/detected_song_segments/*.wav **and** draw red dashed lines wherever\n",
    "# the concatenated audio switches from one original .wav file to the next.\n",
    "\n",
    "# Required inputs\n",
    "# ---------------\n",
    "# parent_folder : Path to the folder that also contains\n",
    "#                 ├─ detected_song_segments/\n",
    "#                 └─ <something>.json          (# same JSON you fed the exporter)\n",
    "\n",
    "# The JSON must have the form::\n",
    "#     {\n",
    "#         \"original_a.wav\": [[s0,e0], [s1,e1], ...],\n",
    "#         \"original_b.wav\": [[s2,e2], ...],\n",
    "#         ...\n",
    "#     }\n",
    "\n",
    "# The script re‑creates the exporter’s concatenation logic to know where one\n",
    "# file stops and the next one starts inside each 60‑s segment.\n",
    "# \"\"\"\n",
    "\n",
    "# from __future__ import annotations\n",
    "\n",
    "# import re\n",
    "# from pathlib import Path\n",
    "# from typing import Dict, List, Tuple\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.io import wavfile\n",
    "# from scipy.signal import spectrogram, windows, ellip, filtfilt\n",
    "# import json\n",
    "# import tkinter as tk\n",
    "\n",
    "# # ────────────────────────────────────────────────────────────────\n",
    "# # USER CONFIG  (edit these three paths / constants)\n",
    "# # ────────────────────────────────────────────────────────────────\n",
    "# # parent_folder = Path(\n",
    "# #     \"/Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33\"\n",
    "# # )\n",
    "# # json_path = \"/Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33_periodicity_only_detected_song_intervals_combined_segments.json\"\n",
    "\n",
    "# segment_duration    = 10          # seconds per spectrogram panel\n",
    "# panels_per_fig      = 6           # ⇒ 60 s max per detected segment\n",
    "# low_cut, high_cut   = 500, 8000   # Hz filter before spectrogram\n",
    "# cmap_choice         = \"binary\"\n",
    "\n",
    "# # ════════════════════════════════════════════════════════════════\n",
    "# # DERIVED PATHS\n",
    "# # ════════════════════════════════════════════════════════════════\n",
    "# segments_folder = folder_path / \"detected_song_segments\"\n",
    "# png_folder      = segments_folder / \"spectrograms\"\n",
    "# png_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # ════════════════════════════════════════════════════════════════\n",
    "# # UTILS\n",
    "# # ════════════════════════════════════════════════════════════════\n",
    "# def get_screen_inches() -> Tuple[float, float]:\n",
    "#     try:\n",
    "#         root = tk.Tk(); root.withdraw()\n",
    "#         w, h = root.winfo_screenwidth(), root.winfo_screenheight()\n",
    "#         root.destroy()\n",
    "#         return w / 100, h / 100\n",
    "#     except Exception:\n",
    "#         return 12, 8\n",
    "\n",
    "# width_inches, height_inches = get_screen_inches()\n",
    "\n",
    "# segment_idx_re = re.compile(r\"_segment_(\\d+)\")\n",
    "\n",
    "# # ════════════════════════════════════════════════════════════════\n",
    "# # STEP 1 – build boundary map  {segment_number: [times (s), …]}\n",
    "# #         Each time marks EITHER the start OR the end of a slice\n",
    "# # ════════════════════════════════════════════════════════════════\n",
    "# with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#     detected_intervals: Dict[str, List[List[float]]] = json.load(f)\n",
    "\n",
    "# # grab the sample‑rate once from any segment file\n",
    "# any_seg = next(segments_folder.glob(\"*.wav\"), None)\n",
    "# if any_seg is None:\n",
    "#     raise FileNotFoundError(\"No *.wav in detected_song_segments/\")\n",
    "# sr, _ = wavfile.read(any_seg)\n",
    "\n",
    "# SEG_LEN_S   = panels_per_fig * segment_duration          # 60 s\n",
    "# SEG_LEN_SMP = SEG_LEN_S * sr\n",
    "\n",
    "# boundary_map: Dict[int, List[float]] = {}\n",
    "# seg_idx            = 1\n",
    "# pos_in_seg_samples = 0\n",
    "# boundaries: List[float] = []\n",
    "\n",
    "# for src_name, intervals in detected_intervals.items():\n",
    "#     for start_t, end_t in intervals:\n",
    "#         slice_len_smp = int(round((end_t - start_t) * sr))\n",
    "#         remaining = slice_len_smp\n",
    "\n",
    "#         while remaining > 0:\n",
    "#             space_left = SEG_LEN_SMP - pos_in_seg_samples\n",
    "#             take       = min(remaining, space_left)\n",
    "\n",
    "#             # ─── record start & end of the chunk that will be copied ───\n",
    "#             slice_start_time = pos_in_seg_samples              / sr\n",
    "#             slice_end_time   = (pos_in_seg_samples + take)     / sr\n",
    "#             boundaries.extend([slice_start_time, slice_end_time])\n",
    "\n",
    "#             # ─── update counters ──────────────────────────────────────\n",
    "#             pos_in_seg_samples += take\n",
    "#             remaining          -= take\n",
    "\n",
    "#             # ─── segment filled? commit & start a fresh one ───────────\n",
    "#             if pos_in_seg_samples == SEG_LEN_SMP:\n",
    "#                 # drop potential duplicates & keep ascending order\n",
    "#                 boundary_map[seg_idx] = sorted(set(boundaries))\n",
    "#                 seg_idx            += 1\n",
    "#                 pos_in_seg_samples  = 0\n",
    "#                 boundaries          = []\n",
    "\n",
    "# # commit the (possibly shorter) final segment\n",
    "# if boundaries:\n",
    "#     boundary_map[seg_idx] = sorted(set(boundaries))\n",
    "\n",
    "\n",
    "# # ════════════════════════════════════════════════════════════════\n",
    "# # STEP 2 – process ONE .wav\n",
    "# # ════════════════════════════════════════════════════════════════\n",
    "# def process_wav_file(wav_path: Path, boundaries: List[float]):\n",
    "#     base_name = wav_path.stem\n",
    "#     sr, data  = wavfile.read(wav_path)\n",
    "#     if data.ndim > 1:\n",
    "#         data = data.mean(axis=1)\n",
    "#     if np.issubdtype(data.dtype, np.integer):\n",
    "#         data = data.astype(np.float32)\n",
    "\n",
    "#     nyq = sr / 2\n",
    "#     b, a = ellip(5, 0.2, 40, [low_cut / nyq, high_cut / nyq], btype=\"band\")\n",
    "#     data = filtfilt(b, a, data)\n",
    "\n",
    "#     total_secs   = data.size / sr\n",
    "#     samples_per_panel = int(segment_duration * sr)\n",
    "#     n_panels     = min(panels_per_fig, int(np.ceil(total_secs / segment_duration)))\n",
    "\n",
    "#     fig, axs = plt.subplots(n_panels, 1,\n",
    "#                             figsize=(width_inches, height_inches),\n",
    "#                             sharex=True, gridspec_kw={'hspace': 0.0})\n",
    "#     axs = [axs] if n_panels == 1 else axs\n",
    "\n",
    "#     for i in range(n_panels):\n",
    "#         start_samp = i * samples_per_panel\n",
    "#         seg = data[start_samp : start_samp + samples_per_panel]\n",
    "#         if seg.size < samples_per_panel:\n",
    "#             seg = np.pad(seg, (0, samples_per_panel - seg.size))\n",
    "\n",
    "#         f, t, Sxx = spectrogram(\n",
    "#             seg, fs=sr,\n",
    "#             window=windows.gaussian(2048, std=2048/8),\n",
    "#             nperseg=2048, noverlap=2048 - 119\n",
    "#         )\n",
    "#         S_log  = 10 * np.log10(Sxx + np.finfo(float).eps)\n",
    "#         S_log  = np.clip(S_log, a_min=3, a_max=None)\n",
    "#         S_norm = (S_log - S_log.min()) / (S_log.ptp() or 1.0)\n",
    "#         S_norm **= 0.7\n",
    "\n",
    "#         axs[i].imshow(S_norm, aspect='auto', origin='lower',\n",
    "#                       extent=[0, segment_duration, f.min(), f.max()],\n",
    "#                       cmap=cmap_choice)\n",
    "#         axs[i].set_ylim(0, 11000)\n",
    "#         axs[i].set_ylabel(\"Freq [Hz]\")\n",
    "\n",
    "#         # Draw the red dashed boundaries that fall inside this 10‑s panel\n",
    "#         panel_t0 = i * segment_duration\n",
    "#         panel_t1 = panel_t0 + segment_duration\n",
    "#         for b_t in boundaries:\n",
    "#             if panel_t0 < b_t < panel_t1:\n",
    "#                 axs[i].axvline(b_t - panel_t0, color='red',\n",
    "#                                linestyle='--', linewidth=1)\n",
    "\n",
    "#         if i == n_panels - 1:\n",
    "#             axs[i].set_xlabel(\"Time [s]\")\n",
    "#             axs[i].set_xticks(np.linspace(0, segment_duration, 5))\n",
    "\n",
    "#     fig.suptitle(f\"{base_name}  –  Spectrogram ({low_cut}-{high_cut} Hz)\",\n",
    "#                  fontsize=14)\n",
    "#     fig.tight_layout()\n",
    "\n",
    "#     out_png = png_folder / f\"{base_name}_spectrogram.png\"\n",
    "#     fig.savefig(out_png, dpi=300)\n",
    "#     plt.close(fig)\n",
    "#     print(\"✅\", out_png.name)\n",
    "\n",
    "# # ════════════════════════════════════════════════════════════════\n",
    "# # STEP 3 – batch over segments\n",
    "# # ════════════════════════════════════════════════════════════════\n",
    "# wav_files = sorted(segments_folder.glob(\"*.wav\"))\n",
    "# if not wav_files:\n",
    "#     raise FileNotFoundError(\"No .wav files found in detected_song_segments/\")\n",
    "\n",
    "# print(f\"📂 Rendering spectrograms for {len(wav_files)} files …\\n\")\n",
    "\n",
    "# for wav_file in wav_files:\n",
    "#     m = segment_idx_re.search(wav_file.stem)\n",
    "#     if not m:\n",
    "#         print(\"⚠️  Could not parse segment index from\", wav_file.name)\n",
    "#         continue\n",
    "#     seg_idx = int(m.group(1))\n",
    "#     boundaries = boundary_map.get(seg_idx, [])\n",
    "#     process_wav_file(wav_file, boundaries)\n",
    "\n",
    "# print(\"\\nDone!  PNGs are in:\", png_folder.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "735615bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Rendering spectrograms for 43 files …\n",
      "\n",
      "✅ USA5207_2025-07-19_detected_song_segment_1_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_10_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_11_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_12_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_13_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_14_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_15_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_16_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_17_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_18_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_19_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_2_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_20_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_21_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_22_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_23_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_24_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_25_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_26_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_27_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_28_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_29_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_3_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_30_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_31_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_32_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_33_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_34_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_35_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_36_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_37_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_38_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_39_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_4_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_40_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_41_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_42_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_43_partial_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_5_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_6_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_7_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_8_spectrogram.png\n",
      "✅ USA5207_2025-07-19_detected_song_segment_9_spectrogram.png\n",
      "\n",
      "Done!  PNGs are in: /Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33/detected_song_segments/spectrograms\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Render filtered spectrogram panels for every\n",
    "<parent>/detected_song_segments/*.wav and save a PNG for each clip.\n",
    "(NO red dashed boundaries are drawn.)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram, windows, ellip, filtfilt\n",
    "import json\n",
    "import tkinter as tk\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# USER CONFIG –– EDIT these three items\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "folder_path = Path(\n",
    "    \"/Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33\"\n",
    ")\n",
    "json_path = Path(\n",
    "    \"/Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/\"\n",
    "    \"33_periodicity_only_detected_song_intervals_combined_segments.json\"\n",
    ")\n",
    "\n",
    "segment_duration    = 10          # seconds per spectrogram panel\n",
    "panels_per_fig      = 6           # ⇒ 60 s max per detected segment\n",
    "low_cut, high_cut   = 500, 8000   # Hz filter before spectrogram\n",
    "cmap_choice         = \"binary\"\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "# DERIVED PATHS\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "segments_folder = folder_path / \"detected_song_segments\"\n",
    "png_folder      = segments_folder / \"spectrograms\"\n",
    "png_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "# UTILS\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "def get_screen_inches() -> Tuple[float, float]:\n",
    "    try:\n",
    "        root = tk.Tk(); root.withdraw()\n",
    "        w, h = root.winfo_screenwidth(), root.winfo_screenheight()\n",
    "        root.destroy()\n",
    "        return w / 100, h / 100\n",
    "    except Exception:\n",
    "        return 12, 8\n",
    "\n",
    "width_inches, height_inches = get_screen_inches()\n",
    "segment_idx_re = re.compile(r\"_segment_(\\d+)\")\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "# BUILD boundary map  {segment_number: [times (s), …]}\n",
    "#   (We still compute it for completeness, but boundaries are no\n",
    "#   longer drawn.)\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    detected_intervals: Dict[str, List[List[float]]] = json.load(f)\n",
    "\n",
    "any_seg = next(segments_folder.glob(\"*.wav\"), None)\n",
    "if any_seg is None:\n",
    "    raise FileNotFoundError(\"No *.wav in detected_song_segments/\")\n",
    "sr, _ = wavfile.read(any_seg)\n",
    "\n",
    "SEG_LEN_S   = panels_per_fig * segment_duration          # 60 s\n",
    "SEG_LEN_SMP = SEG_LEN_S * sr\n",
    "\n",
    "boundary_map: Dict[int, List[float]] = {}\n",
    "seg_idx            = 1\n",
    "pos_in_seg_samples = 0\n",
    "boundaries: List[float] = []\n",
    "\n",
    "for src_name, intervals in detected_intervals.items():\n",
    "    for start_t, end_t in intervals:\n",
    "        slice_len_smp = int(round((end_t - start_t) * sr))\n",
    "        remaining = slice_len_smp\n",
    "\n",
    "        while remaining > 0:\n",
    "            space_left = SEG_LEN_SMP - pos_in_seg_samples\n",
    "            take       = min(remaining, space_left)\n",
    "\n",
    "            # record start & end of the chunk that will be copied\n",
    "            slice_start_time = pos_in_seg_samples              / sr\n",
    "            slice_end_time   = (pos_in_seg_samples + take)     / sr\n",
    "            boundaries.extend([slice_start_time, slice_end_time])\n",
    "\n",
    "            pos_in_seg_samples += take\n",
    "            remaining          -= take\n",
    "\n",
    "            if pos_in_seg_samples == SEG_LEN_SMP:\n",
    "                boundary_map[seg_idx] = sorted(set(boundaries))\n",
    "                seg_idx            += 1\n",
    "                pos_in_seg_samples  = 0\n",
    "                boundaries          = []\n",
    "\n",
    "if boundaries:\n",
    "    boundary_map[seg_idx] = sorted(set(boundaries))\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "# PROCESS ONE .wav  (no red dashed lines drawn)\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "def process_wav_file(wav_path: Path):\n",
    "    base_name = wav_path.stem\n",
    "    sr, data  = wavfile.read(wav_path)\n",
    "    if data.ndim > 1:\n",
    "        data = data.mean(axis=1)\n",
    "    if np.issubdtype(data.dtype, np.integer):\n",
    "        data = data.astype(np.float32)\n",
    "\n",
    "    nyq = sr / 2\n",
    "    b, a = ellip(5, 0.2, 40, [low_cut / nyq, high_cut / nyq], btype=\"band\")\n",
    "    data = filtfilt(b, a, data)\n",
    "\n",
    "    total_secs        = data.size / sr\n",
    "    samples_per_panel = int(segment_duration * sr)\n",
    "    n_panels          = min(panels_per_fig, int(np.ceil(total_secs / segment_duration)))\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        n_panels, 1, figsize=(width_inches, height_inches),\n",
    "        sharex=True, gridspec_kw={'hspace': 0.0}\n",
    "    )\n",
    "    axs = [axs] if n_panels == 1 else axs\n",
    "\n",
    "    for i in range(n_panels):\n",
    "        start_samp = i * samples_per_panel\n",
    "        seg = data[start_samp : start_samp + samples_per_panel]\n",
    "        if seg.size < samples_per_panel:\n",
    "            seg = np.pad(seg, (0, samples_per_panel - seg.size))\n",
    "\n",
    "        f, t, Sxx = spectrogram(\n",
    "            seg, fs=sr,\n",
    "            window=windows.gaussian(2048, std=2048/8),\n",
    "            nperseg=2048, noverlap=2048 - 119\n",
    "        )\n",
    "        S_log  = 10 * np.log10(Sxx + np.finfo(float).eps)\n",
    "        S_log  = np.clip(S_log, a_min=3, a_max=None)\n",
    "        S_norm = (S_log - S_log.min()) / (S_log.ptp() or 1.0)\n",
    "        S_norm **= 0.7\n",
    "\n",
    "        axs[i].imshow(\n",
    "            S_norm, aspect='auto', origin='lower',\n",
    "            extent=[0, segment_duration, f.min(), f.max()],\n",
    "            cmap=cmap_choice\n",
    "        )\n",
    "        axs[i].set_ylim(0, 11000)\n",
    "        axs[i].set_ylabel(\"Freq [Hz]\")\n",
    "\n",
    "        if i == n_panels - 1:\n",
    "            axs[i].set_xlabel(\"Time [s]\")\n",
    "            axs[i].set_xticks(np.linspace(0, segment_duration, 5))\n",
    "\n",
    "    fig.suptitle(f\"{base_name}  –  Spectrogram ({low_cut}-{high_cut} Hz)\", fontsize=14)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    out_png = png_folder / f\"{base_name}_spectrogram.png\"\n",
    "    fig.savefig(out_png, dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(\"✅\", out_png.name)\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "# BATCH over segments\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "wav_files = sorted(segments_folder.glob(\"*.wav\"))\n",
    "if not wav_files:\n",
    "    raise FileNotFoundError(\"No .wav files found in detected_song_segments/\")\n",
    "\n",
    "print(f\"📂 Rendering spectrograms for {len(wav_files)} files …\\n\")\n",
    "\n",
    "for wav_file in wav_files:\n",
    "    process_wav_file(wav_file)\n",
    "\n",
    "print(\"\\nDone!  PNGs are in:\", png_folder.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970d3783",
   "metadata": {},
   "source": [
    "# Option 2: This portion combines all .wav files containing songs into 1-minute recordings, then  generates spectrograms of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6f401f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0934973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, json\n",
    "# import numpy as np\n",
    "# from scipy.io import wavfile\n",
    "# from pathlib import Path   # (unused but often handy)\n",
    "\n",
    "# # ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# # CONFIG ── update these two paths only\n",
    "# # ╚══════════════════════════════════════════════════════════════════════╝\n",
    "# # folder_path = '/your/recordings/folder'\n",
    "# # json_path   = '/your/detector_output.json'\n",
    "\n",
    "# # ── derived paths ──────────────────────────────────────────────────────\n",
    "# output_folder       = os.path.join(folder_path, 'detected_song_files_full_recordings')\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "# metadata_output_path = os.path.join(output_folder, 'segment_metadata.json')\n",
    "\n",
    "# # ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# # LOAD detector JSON  →  {wav_file : [[start,end], …]}\n",
    "# # ╚══════════════════════════════════════════════════════════════════════╝\n",
    "# with open(json_path) as f:\n",
    "#     detected_intervals = json.load(f)\n",
    "\n",
    "# # process files in deterministic order\n",
    "# file_names = sorted(detected_intervals.keys())\n",
    "\n",
    "# # ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# # READ all wavs into memory (could be streamed if very large files)\n",
    "# # ╚══════════════════════════════════════════════════════════════════════╝\n",
    "# audio_queue            = []            # [(file_name, data)]\n",
    "# sample_rate_reference  = None\n",
    "\n",
    "# for fn in file_names:\n",
    "#     wav_path = os.path.join(folder_path, fn)\n",
    "#     if not os.path.exists(wav_path):\n",
    "#         print(f\"⚠️  Missing file: {fn}\")\n",
    "#         continue\n",
    "#     try:\n",
    "#         sr, data = wavfile.read(wav_path)\n",
    "#         if sample_rate_reference is None:\n",
    "#             sample_rate_reference = sr\n",
    "#         elif sr != sample_rate_reference:\n",
    "#             raise ValueError(f\"Sample‑rate mismatch in {fn} ({sr} vs {sample_rate_reference})\")\n",
    "#         if data.ndim > 1:                       # stereo → mono\n",
    "#             data = data.mean(axis=1)\n",
    "#         audio_queue.append((fn, data.astype(np.float32)))\n",
    "#     except Exception as e:\n",
    "#         print(f\"⚠️  Error reading {fn}: {e}\")\n",
    "\n",
    "# if not audio_queue:\n",
    "#     raise RuntimeError(\"No audio files were loaded successfully.\")\n",
    "\n",
    "# # ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# # CHUNKING variables & helpers\n",
    "# # ╚══════════════════════════════════════════════════════════════════════╝\n",
    "# minute_samples      = 60 * sample_rate_reference\n",
    "# leftover            = np.array([], dtype=np.float32)\n",
    "# leftover_provenance = []      # list of dicts: {\"source_file\", \"range_start\", \"range_end\"}\n",
    "# segment_metadata    = {}\n",
    "# chunk_count         = 0\n",
    "\n",
    "# def get_song_segments_within_range(source_file, range_start, range_end):\n",
    "#     \"\"\"Return detector intervals (sec) that overlap [range_start, range_end) in sample coords,\n",
    "#        expressed relative to the *start of that range*.\"\"\"\n",
    "#     out = []\n",
    "#     for t_start, t_end in detected_intervals.get(source_file, []):\n",
    "#         s_start = int(t_start * sample_rate_reference)\n",
    "#         s_end   = int(t_end   * sample_rate_reference)\n",
    "#         ov_start = max(s_start, range_start)\n",
    "#         ov_end   = min(s_end,   range_end)\n",
    "#         if ov_start < ov_end:\n",
    "#             out.append([\n",
    "#                 round((ov_start - range_start) / sample_rate_reference, 3),\n",
    "#                 round((ov_end   - range_start) / sample_rate_reference, 3)\n",
    "#             ])\n",
    "#     return out\n",
    "\n",
    "# def finalize_chunk(chunk_data, provenance, song_segments, idx):\n",
    "#     fname = f'detected_song_minute_{idx+1}.wav'\n",
    "#     fpath = os.path.join(output_folder, fname)\n",
    "#     wavfile.write(fpath, sample_rate_reference, chunk_data.astype(np.int16))\n",
    "#     segment_metadata[fname] = {\n",
    "#         \"source_files\": provenance,\n",
    "#         \"song_segments_in_chunk\": song_segments\n",
    "#     }\n",
    "#     print(f\"✅  Saved {fname}\")\n",
    "\n",
    "# # ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# # MAIN loop – stitch files, slice 60‑s chunks, preserve provenance\n",
    "# # ╚══════════════════════════════════════════════════════════════════════╝\n",
    "# for file_name, data in audio_queue:\n",
    "\n",
    "#     # 1) build new \"combined\" buffer = leftover + current file\n",
    "#     combined         = np.concatenate([leftover, data])\n",
    "#     combined_ranges  = []          # [{\"source_file\", \"range_start\", \"range_end\"}]\n",
    "#     offset           = 0\n",
    "\n",
    "#     # carry forward *all* leftover provenance\n",
    "#     for prov in leftover_provenance:\n",
    "#         dur = prov[\"range_end\"] - prov[\"range_start\"]\n",
    "#         combined_ranges.append({\n",
    "#             \"source_file\": prov[\"source_file\"],\n",
    "#             \"range_start\": offset,\n",
    "#             \"range_end\":   offset + dur\n",
    "#         })\n",
    "#         offset += dur\n",
    "\n",
    "#     # append current file’s span\n",
    "#     combined_ranges.append({\n",
    "#         \"source_file\": file_name,\n",
    "#         \"range_start\": offset,\n",
    "#         \"range_end\":   offset + len(data)\n",
    "#     })\n",
    "\n",
    "#     # 2) slice full‑minute chunks\n",
    "#     cursor = 0\n",
    "#     while cursor + minute_samples <= len(combined):\n",
    "#         chunk               = combined[cursor:cursor + minute_samples]\n",
    "#         chunk_provenance    = []\n",
    "#         chunk_song_segments = []\n",
    "\n",
    "#         chunk_start = cursor\n",
    "#         chunk_end   = cursor + minute_samples\n",
    "\n",
    "#         for rng in combined_ranges:\n",
    "#             src_start, src_end = rng[\"range_start\"], rng[\"range_end\"]\n",
    "#             ov_start = max(chunk_start, src_start)\n",
    "#             ov_end   = min(chunk_end,   src_end)\n",
    "#             if ov_start < ov_end:   # overlap exists\n",
    "#                 # provenance entry\n",
    "#                 rel_start_sec = (ov_start - chunk_start) / sample_rate_reference\n",
    "#                 rel_end_sec   = (ov_end   - chunk_start) / sample_rate_reference\n",
    "#                 chunk_provenance.append({\n",
    "#                     \"source_file\": rng[\"source_file\"],\n",
    "#                     \"time_range_in_chunk_seconds\": [round(rel_start_sec,3),\n",
    "#                                                    round(rel_end_sec,3)]\n",
    "#                 })\n",
    "#                 # song segments from this slice\n",
    "#                 slice_rel_start = ov_start - src_start\n",
    "#                 slice_rel_end   = ov_end   - src_start\n",
    "#                 for seg in get_song_segments_within_range(\n",
    "#                         rng[\"source_file\"], slice_rel_start, slice_rel_end):\n",
    "#                     chunk_song_segments.append([\n",
    "#                         round(seg[0] + rel_start_sec, 3),\n",
    "#                         round(seg[1] + rel_start_sec, 3)\n",
    "#                     ])\n",
    "\n",
    "#         finalize_chunk(chunk, chunk_provenance, chunk_song_segments, chunk_count)\n",
    "#         chunk_count += 1\n",
    "#         cursor      += minute_samples\n",
    "\n",
    "#     # 3) whatever is left < 60 s → carry to next iteration\n",
    "#     leftover = combined[cursor:]\n",
    "#     leftover_provenance = []\n",
    "#     if len(leftover) > 0:\n",
    "#         for rng in combined_ranges:\n",
    "#             if rng[\"range_end\"] > cursor:                      # part survives\n",
    "#                 leftover_provenance.append({\n",
    "#                     \"source_file\": rng[\"source_file\"],\n",
    "#                     \"range_start\": max(0,   rng[\"range_start\"] - cursor),\n",
    "#                     \"range_end\":   rng[\"range_end\"] - cursor\n",
    "#                 })\n",
    "\n",
    "# # ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# # FINAL (possibly padded) chunk made from leftover audio\n",
    "# # ╚══════════════════════════════════════════════════════════════════════╝\n",
    "# if len(leftover) > 0:\n",
    "#     padded = np.pad(leftover, (0, minute_samples - len(leftover)), mode=\"constant\")\n",
    "#     final_prov  = []\n",
    "#     final_segs  = []\n",
    "#     for rng in leftover_provenance:\n",
    "#         p_start_sec = rng[\"range_start\"] / sample_rate_reference\n",
    "#         p_end_sec   = rng[\"range_end\"]   / sample_rate_reference\n",
    "#         final_prov.append({\n",
    "#             \"source_file\": rng[\"source_file\"],\n",
    "#             \"time_range_in_chunk_seconds\": [round(p_start_sec,3), round(p_end_sec,3)]\n",
    "#         })\n",
    "#         for seg in get_song_segments_within_range(\n",
    "#                 rng[\"source_file\"], 0, rng[\"range_end\"] - rng[\"range_start\"]):\n",
    "#             final_segs.append([\n",
    "#                 round(seg[0] + p_start_sec, 3),\n",
    "#                 round(seg[1] + p_start_sec, 3)\n",
    "#             ])\n",
    "#     finalize_chunk(padded, final_prov, final_segs, chunk_count)\n",
    "\n",
    "# # ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# # WRITE master metadata file\n",
    "# # ╚══════════════════════════════════════════════════════════════════════╝\n",
    "# with open(metadata_output_path, \"w\") as f:\n",
    "#     json.dump(segment_metadata, f, indent=2)\n",
    "\n",
    "# print(f\"📄  Metadata saved to: {metadata_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a3798a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Saved USA5207_2025-07-19_detected_song_segment_1.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_2.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_3.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_4.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_5.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_6.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_7.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_8.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_9.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_10.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_11.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_12.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_13.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_14.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_15.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_16.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_17.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_18.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_19.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_20.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_21.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_22.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_23.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_24.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_25.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_26.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_27.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_28.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_29.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_30.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_31.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_32.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_33.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_34.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_35.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_36.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_37.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_38.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_39.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_40.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_41.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_42.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_43.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_44.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_45.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_46.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_47.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_48.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_49.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_50.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_51.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_52.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_53.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_54.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_55.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_56.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_57.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_58.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_59.wav\n",
      "✅  Saved USA5207_2025-07-19_detected_song_segment_60.wav\n",
      "📄  Metadata saved to: /Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33/detected_song_files_full_recordings/segment_metadata.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf‑8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Split one or more long .wav recordings into consecutive 60‑second clips\n",
    "and keep track of (1) which original file(s) contributed to each clip and\n",
    "(2) where song was detected inside each clip.\n",
    "\n",
    "The output clips are named:\n",
    "    <animal_id>_<recording_date>_detected_song_segment_<N>.wav\n",
    "and a JSON file `segment_metadata.json` is written alongside them.\n",
    "\"\"\"\n",
    "\n",
    "import os, json\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from pathlib import Path   # (unused here, but handy for future tweaks)\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# CONFIG –– update the four values below\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "# folder_path   = \"/Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33\"        # directory with raw .wav files\n",
    "# json_path     = \"/Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33_periodicity_only_detected_song_intervals_combined_segments.json\"      # detector output (song intervals)\n",
    "# animal_id     = 'USA5207'                          # e.g. 'USA5207'\n",
    "# recording_date = '2025-07-19'                      # e.g. 'YYYY‑MM‑DD'\n",
    "\n",
    "# ── derived paths ──────────────────────────────────────────────────────\n",
    "output_folder        = os.path.join(folder_path, 'detected_song_files_full_recordings')\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "metadata_output_path = os.path.join(output_folder, 'segment_metadata.json')\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# LOAD detector JSON  →  {wav_file : [[start,end], …]}\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "with open(json_path, 'r') as f:\n",
    "    detected_intervals = json.load(f)\n",
    "\n",
    "# deterministic processing order\n",
    "file_names = sorted(detected_intervals.keys())\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# READ all wavs into memory (could be streamed if very large files)\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "audio_queue           = []      # list of tuples (file_name, mono_float32_data)\n",
    "sample_rate_reference = None\n",
    "\n",
    "for fn in file_names:\n",
    "    wav_path = os.path.join(folder_path, fn)\n",
    "    if not os.path.exists(wav_path):\n",
    "        print(f\"⚠️  Missing file: {fn}\")\n",
    "        continue\n",
    "    try:\n",
    "        sr, data = wavfile.read(wav_path)\n",
    "        if sample_rate_reference is None:\n",
    "            sample_rate_reference = sr\n",
    "        elif sr != sample_rate_reference:\n",
    "            raise ValueError(f\"Sample‑rate mismatch in {fn} ({sr} vs {sample_rate_reference})\")\n",
    "\n",
    "        # stereo → mono\n",
    "        if data.ndim > 1:\n",
    "            data = data.mean(axis=1)\n",
    "\n",
    "        audio_queue.append((fn, data.astype(np.float32)))\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Error reading {fn}: {e}\")\n",
    "\n",
    "if not audio_queue:\n",
    "    raise RuntimeError(\"No audio files were loaded successfully.\")\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# CHUNKING variables & helpers\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "minute_samples      = 60 * sample_rate_reference\n",
    "leftover            = np.array([], dtype=np.float32)\n",
    "leftover_provenance = []      # list of dicts: {\"source_file\", \"range_start\", \"range_end\"}\n",
    "segment_metadata    = {}\n",
    "chunk_count         = 0\n",
    "\n",
    "def get_song_segments_within_range(source_file, range_start, range_end):\n",
    "    \"\"\"Return detector intervals (sec) that overlap [range_start, range_end) in sample\n",
    "    coordinates, expressed relative to the *start* of that range.\"\"\"\n",
    "    out = []\n",
    "    for t_start, t_end in detected_intervals.get(source_file, []):\n",
    "        s_start = int(t_start * sample_rate_reference)\n",
    "        s_end   = int(t_end   * sample_rate_reference)\n",
    "        ov_start = max(s_start, range_start)\n",
    "        ov_end   = min(s_end,   range_end)\n",
    "        if ov_start < ov_end:\n",
    "            out.append([\n",
    "                round((ov_start - range_start) / sample_rate_reference, 3),\n",
    "                round((ov_end   - range_start) / sample_rate_reference, 3)\n",
    "            ])\n",
    "    return out\n",
    "\n",
    "def finalize_chunk(chunk_data, provenance, song_segments, idx,\n",
    "                   animal_id, recording_date):\n",
    "    \"\"\"Write one 60‑s clip to disk and log its metadata.\"\"\"\n",
    "    fname = (\n",
    "        f\"{animal_id}_{recording_date}_detected_song_segment_{idx+1}.wav\"\n",
    "    )\n",
    "    fpath = os.path.join(output_folder, fname)\n",
    "\n",
    "    # ensure int16 range\n",
    "    chunk_int16 = np.clip(chunk_data, -32768, 32767).astype(np.int16)\n",
    "    wavfile.write(fpath, sample_rate_reference, chunk_int16)\n",
    "\n",
    "    segment_metadata[fname] = {\n",
    "        \"source_files\": provenance,\n",
    "        \"song_segments_in_chunk\": song_segments\n",
    "    }\n",
    "    print(f\"✅  Saved {fname}\")\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# MAIN loop –– stitch files, slice 60‑s chunks, preserve provenance\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "for file_name, data in audio_queue:\n",
    "\n",
    "    # 1) build new \"combined\" buffer = leftover + current file\n",
    "    combined        = np.concatenate([leftover, data])\n",
    "    combined_ranges = []          # [{\"source_file\", \"range_start\", \"range_end\"}]\n",
    "    offset          = 0\n",
    "\n",
    "    # carry forward *all* leftover provenance\n",
    "    for prov in leftover_provenance:\n",
    "        dur = prov[\"range_end\"] - prov[\"range_start\"]\n",
    "        combined_ranges.append({\n",
    "            \"source_file\": prov[\"source_file\"],\n",
    "            \"range_start\": offset,\n",
    "            \"range_end\":   offset + dur\n",
    "        })\n",
    "        offset += dur\n",
    "\n",
    "    # append current file’s span\n",
    "    combined_ranges.append({\n",
    "        \"source_file\": file_name,\n",
    "        \"range_start\": offset,\n",
    "        \"range_end\":   offset + len(data)\n",
    "    })\n",
    "\n",
    "    # 2) slice full‑minute chunks\n",
    "    cursor = 0\n",
    "    while cursor + minute_samples <= len(combined):\n",
    "        chunk               = combined[cursor:cursor + minute_samples]\n",
    "        chunk_provenance    = []\n",
    "        chunk_song_segments = []\n",
    "\n",
    "        chunk_start = cursor\n",
    "        chunk_end   = cursor + minute_samples\n",
    "\n",
    "        for rng in combined_ranges:\n",
    "            src_start, src_end = rng[\"range_start\"], rng[\"range_end\"]\n",
    "            ov_start = max(chunk_start, src_start)\n",
    "            ov_end   = min(chunk_end,   src_end)\n",
    "            if ov_start < ov_end:   # overlap exists\n",
    "                # provenance entry\n",
    "                rel_start_sec = (ov_start - chunk_start) / sample_rate_reference\n",
    "                rel_end_sec   = (ov_end   - chunk_start) / sample_rate_reference\n",
    "                chunk_provenance.append({\n",
    "                    \"source_file\": rng[\"source_file\"],\n",
    "                    \"time_range_in_chunk_seconds\": [\n",
    "                        round(rel_start_sec, 3),\n",
    "                        round(rel_end_sec,   3)\n",
    "                    ]\n",
    "                })\n",
    "\n",
    "                # song segments within this overlap\n",
    "                slice_rel_start = ov_start - src_start\n",
    "                slice_rel_end   = ov_end   - src_start\n",
    "                for seg in get_song_segments_within_range(\n",
    "                        rng[\"source_file\"], slice_rel_start, slice_rel_end):\n",
    "                    chunk_song_segments.append([\n",
    "                        round(seg[0] + rel_start_sec, 3),\n",
    "                        round(seg[1] + rel_start_sec, 3)\n",
    "                    ])\n",
    "\n",
    "        finalize_chunk(chunk, chunk_provenance, chunk_song_segments,\n",
    "                       chunk_count, animal_id, recording_date)\n",
    "        chunk_count += 1\n",
    "        cursor      += minute_samples\n",
    "\n",
    "    # 3) whatever is left (< 60 s) → carry to next iteration\n",
    "    leftover = combined[cursor:]\n",
    "    leftover_provenance = []\n",
    "    if len(leftover) > 0:\n",
    "        for rng in combined_ranges:\n",
    "            if rng[\"range_end\"] > cursor:      # part survives\n",
    "                leftover_provenance.append({\n",
    "                    \"source_file\": rng[\"source_file\"],\n",
    "                    \"range_start\": max(0, rng[\"range_start\"] - cursor),\n",
    "                    \"range_end\":   rng[\"range_end\"] - cursor\n",
    "                })\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# FINAL (possibly padded) chunk made from leftover audio\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "if len(leftover) > 0:\n",
    "    padded = np.pad(\n",
    "        leftover, (0, minute_samples - len(leftover)),\n",
    "        mode=\"constant\"\n",
    "    )\n",
    "\n",
    "    final_prov, final_segs = [], []\n",
    "    for rng in leftover_provenance:\n",
    "        p_start_sec = rng[\"range_start\"] / sample_rate_reference\n",
    "        p_end_sec   = rng[\"range_end\"]   / sample_rate_reference\n",
    "        final_prov.append({\n",
    "            \"source_file\": rng[\"source_file\"],\n",
    "            \"time_range_in_chunk_seconds\": [\n",
    "                round(p_start_sec, 3),\n",
    "                round(p_end_sec,   3)\n",
    "            ]\n",
    "        })\n",
    "        for seg in get_song_segments_within_range(\n",
    "                rng[\"source_file\"], 0, rng[\"range_end\"] - rng[\"range_start\"]):\n",
    "            final_segs.append([\n",
    "                round(seg[0] + p_start_sec, 3),\n",
    "                round(seg[1] + p_start_sec, 3)\n",
    "            ])\n",
    "\n",
    "    finalize_chunk(padded, final_prov, final_segs,\n",
    "                   chunk_count, animal_id, recording_date)\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# WRITE master metadata file\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "with open(metadata_output_path, 'w') as f:\n",
    "    json.dump(segment_metadata, f, indent=2)\n",
    "\n",
    "print(f\"📄  Metadata saved to: {metadata_output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a84cd4",
   "metadata": {},
   "source": [
    "## Generate the spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63a67a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 Found 60 clips – renaming & rendering …\n",
      "\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_1_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_2_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_3_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_4_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_5_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_6_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_7_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_8_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_9_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_10_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_11_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_12_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_13_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_14_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_15_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_16_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_17_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_18_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_19_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_20_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_21_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_22_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_23_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_24_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_25_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_26_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_27_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_28_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_29_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_30_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_31_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_32_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_33_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_34_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_35_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_36_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_37_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_38_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_39_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_40_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_41_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_42_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_43_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_44_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_45_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_46_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_47_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_48_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_49_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_50_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_51_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_52_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_53_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_54_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_55_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_56_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_57_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_58_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_59_spectrogram.png\n",
      "✅ spectrogram → USA5207_2025-07-19_detected_song_file_minute_60_spectrogram.png\n",
      "\n",
      "Done!  Spectrograms in: /Volumes/my_own_SSD/UO_stuff/nerve_transections/USA5207/33/detected_song_files_full_recordings/spectrograms\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Batch‑render spectrograms for detected‑song minute clips and (re)name the\n",
    "clips themselves with a clearer convention:\n",
    "\n",
    "    <animal_id>_<recording_date>_detected_song_file_minute_<n>.wav\n",
    "\"\"\"\n",
    "\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram, windows, ellip, filtfilt\n",
    "import tkinter as tk\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# variables `animal_id`, `recording_date`, `folder_path`, `json_path`\n",
    "# were defined in a previous notebook cell\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# PATHS  –– join with `/` instead of `+`\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "base_folder    = folder_path / \"detected_song_files_full_recordings\"   # ← FIXED\n",
    "spectrogram_out = base_folder / \"spectrograms\"\n",
    "spectrogram_out.mkdir(exist_ok=True)\n",
    "\n",
    "# Optional metadata JSON\n",
    "metadata_json = base_folder / \"segment_metadata.json\"\n",
    "if metadata_json.is_file():\n",
    "    with metadata_json.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        segment_metadata = json.load(f)\n",
    "else:\n",
    "    segment_metadata = {}\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# Figure‑size helper\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def get_screen_inches() -> Tuple[float, float]:\n",
    "    try:\n",
    "        root = tk.Tk(); root.withdraw()\n",
    "        w, h = root.winfo_screenwidth(), root.winfo_screenheight()\n",
    "        root.destroy()\n",
    "        return w / 100, h / 100\n",
    "    except Exception:\n",
    "        return 12, 8\n",
    "\n",
    "width_inches, height_inches = get_screen_inches()\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# Spectrogram rendering for one clip\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def render_clip(\n",
    "    wav_path: Path,\n",
    "    segment_duration: int = 10,\n",
    "    panels_per_fig: int = 6,\n",
    "    low_cut: int = 500,\n",
    "    high_cut: int = 8000,\n",
    ") -> None:\n",
    "\n",
    "    base_name = wav_path.stem\n",
    "    sr, data  = wavfile.read(wav_path)\n",
    "    if data.ndim > 1:\n",
    "        data = data.mean(axis=1)\n",
    "    if np.issubdtype(data.dtype, np.integer):\n",
    "        data = data.astype(np.float32)\n",
    "\n",
    "    # band‑pass\n",
    "    nyq = sr / 2\n",
    "    b, a = ellip(5, 0.2, 40, [low_cut / nyq, high_cut / nyq], btype=\"band\")\n",
    "    data = filtfilt(b, a, data)\n",
    "\n",
    "    total_secs        = data.size / sr\n",
    "    samples_per_panel = int(segment_duration * sr)\n",
    "    n_panels          = min(panels_per_fig, int(np.ceil(total_secs / segment_duration)))\n",
    "\n",
    "    # annotations\n",
    "    meta_key       = wav_path.name\n",
    "    song_intervals = segment_metadata.get(meta_key, {}).get(\"song_segments_in_chunk\", [])\n",
    "    boundary_lines = [\n",
    "        src[\"time_range_in_chunk_seconds\"][1]\n",
    "        for src in segment_metadata.get(meta_key, {}).get(\"source_files\", [])\n",
    "        if \"time_range_in_chunk_seconds\" in src\n",
    "    ]\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        n_panels, 1, figsize=(width_inches, height_inches),\n",
    "        sharex=True, gridspec_kw={\"hspace\": 0.0}\n",
    "    )\n",
    "    axs = [axs] if n_panels == 1 else axs\n",
    "\n",
    "    for idx in range(n_panels):\n",
    "        start_sample = idx * samples_per_panel\n",
    "        panel = data[start_sample : start_sample + samples_per_panel]\n",
    "        if panel.size < samples_per_panel:                 # zero‑pad last panel\n",
    "            panel = np.pad(panel, (0, samples_per_panel - panel.size))\n",
    "\n",
    "        f, t, Sxx = spectrogram(\n",
    "            panel, fs=sr,\n",
    "            window=windows.gaussian(2048, std=2048 / 8),\n",
    "            nperseg=2048, noverlap=2048 - 119,\n",
    "        )\n",
    "        S_log  = 10 * np.log10(Sxx + np.finfo(float).eps)\n",
    "        S_log  = np.clip(S_log, a_min=3, a_max=None)\n",
    "        S_norm = (S_log - S_log.min()) / (S_log.ptp() or 1)\n",
    "        S_norm **= 0.7\n",
    "\n",
    "        axs[idx].imshow(\n",
    "            S_norm, aspect=\"auto\", origin=\"lower\",\n",
    "            extent=[0, segment_duration, f.min(), f.max()],\n",
    "            cmap=\"binary\",\n",
    "        )\n",
    "        axs[idx].set_ylim(0, 11_000)\n",
    "        axs[idx].set_ylabel(\"Freq [Hz]\")\n",
    "\n",
    "        # yellow song spans\n",
    "        p0, p1 = idx * segment_duration, (idx + 1) * segment_duration\n",
    "        for s0, s1 in song_intervals:\n",
    "            if s0 < p1 and s1 > p0:\n",
    "                x0, x1 = max(0, s0 - p0), min(segment_duration, s1 - p0)\n",
    "                axs[idx].axvspan(x0, x1, color=\"yellow\", alpha=0.1)\n",
    "\n",
    "        # (If you removed red boundaries earlier, delete this block.)\n",
    "        for b in boundary_lines:\n",
    "            if p0 < b < p1:\n",
    "                axs[idx].axvline(b - p0, color=\"red\", linestyle=\"--\", linewidth=1.2)\n",
    "\n",
    "        if idx == n_panels - 1:\n",
    "            axs[idx].set_xlabel(\"Time [s]\")\n",
    "            axs[idx].set_xticks(np.linspace(0, segment_duration, 5))\n",
    "\n",
    "    fig.suptitle(f\"{base_name} – Spectrogram ({low_cut}-{high_cut} Hz)\", fontsize=14)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    out_png = spectrogram_out / f\"{base_name}_spectrogram.png\"\n",
    "    fig.savefig(out_png, dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(f\"✅ spectrogram → {out_png.name}\")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# Batch rename clips, update metadata map, and render\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "wav_files: List[Path] = sorted(base_folder.glob(\"*.wav\"))\n",
    "if not wav_files:\n",
    "    raise FileNotFoundError(f\"No .wav clips found in {base_folder}\")\n",
    "\n",
    "print(f\"\\n📂 Found {len(wav_files)} clips – renaming & rendering …\\n\")\n",
    "\n",
    "for idx, old_path in enumerate(wav_files, start=1):\n",
    "    new_name = f\"{animal_id}_{recording_date}_detected_song_file_minute_{idx}.wav\"\n",
    "    new_path = old_path.with_name(new_name)\n",
    "\n",
    "    if old_path.name != new_name:           # rename on disk\n",
    "        old_path.rename(new_path)\n",
    "\n",
    "    # keep metadata mapping in sync\n",
    "    if old_path.name in segment_metadata and new_name not in segment_metadata:\n",
    "        segment_metadata[new_name] = segment_metadata[old_path.name]\n",
    "\n",
    "    render_clip(new_path)\n",
    "\n",
    "print(\"\\nDone!  Spectrograms in:\", spectrogram_out.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1228e1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4149d396",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ffdded0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50401d3c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5c2157b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70bf6745",
   "metadata": {},
   "source": [
    "### Trying out different color scales for better song visibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323fc851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 Processing 2 files in /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5288_testing_pipeline/detected_song_files_full_recordings\n",
      "\n",
      "✅ Saved: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5288_testing_pipeline/detected_song_files_full_recordings/spectrograms/detected_song_minute_2_spectrogram.png\n",
      "✅ Saved: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5288_testing_pipeline/detected_song_files_full_recordings/spectrograms/detected_song_minute_1_spectrogram.png\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "# from scipy.io import wavfile\n",
    "# from scipy.signal import spectrogram, windows, ellip, filtfilt\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tkinter as tk\n",
    "# import json\n",
    "\n",
    "# # ── Utility: approximate screen size in inches (assumes 100 dpi) ─────────────\n",
    "# def get_screen_resolution():\n",
    "#     root = tk.Tk(); root.withdraw()\n",
    "#     w_px, h_px = root.winfo_screenwidth(), root.winfo_screenheight()\n",
    "#     root.destroy()\n",
    "#     return w_px / 100, h_px / 100\n",
    "\n",
    "# width_inches, height_inches = get_screen_resolution()\n",
    "\n",
    "# # ── Load your segment metadata (if you have one) ─────────────────────────────\n",
    "# # For example:\n",
    "# # with open(\"path/to/segment_metadata.json\") as f:\n",
    "# #     segment_metadata = json.load(f)\n",
    "# segment_metadata = {}  # replace with your actual metadata dict\n",
    "\n",
    "# def process_wav_file(file_path, spectrogram_folder,\n",
    "#                      segment_duration=10,\n",
    "#                      low_cut=500, high_cut=8000):\n",
    "#     try:\n",
    "#         base_name = Path(file_path).stem\n",
    "#         sr, data = wavfile.read(file_path)\n",
    "#         if data.ndim > 1:\n",
    "#             data = data.mean(axis=1)\n",
    "\n",
    "#         # === Band‑pass filter ===\n",
    "#         nyq = sr / 2\n",
    "#         b, a = ellip(5, 0.2, 40,\n",
    "#                      [low_cut/nyq, high_cut/nyq],\n",
    "#                      btype='band')\n",
    "#         data = filtfilt(b, a, data)\n",
    "\n",
    "#         # === Setup segments ===\n",
    "#         total_secs = data.size / sr\n",
    "#         seg_samps = int(segment_duration * sr)\n",
    "#         nseg = min(6, int(np.ceil(total_secs / segment_duration)))\n",
    "#         out_path = Path(spectrogram_folder) / f\"{base_name}_spectrogram.png\"\n",
    "\n",
    "#         fig, axs = plt.subplots(nseg, 1,\n",
    "#                                 figsize=(width_inches, height_inches),\n",
    "#                                 sharex=True,\n",
    "#                                 gridspec_kw={'hspace': 0})\n",
    "#         if nseg == 1:\n",
    "#             axs = [axs]\n",
    "\n",
    "#         # retrieve any song intervals / boundaries\n",
    "#         key = f\"{base_name}.wav\"\n",
    "#         song_intervals = segment_metadata.get(key, {}).get(\"song_segments_in_chunk\", [])\n",
    "#         boundaries = [src[\"time_range_in_chunk_seconds\"][1]\n",
    "#                       for src in segment_metadata.get(key, {}).get(\"source_files\", [])\n",
    "#                       if \"time_range_in_chunk_seconds\" in src]\n",
    "\n",
    "#         for i in range(nseg):\n",
    "#             start = i * seg_samps\n",
    "#             end = start + seg_samps\n",
    "#             chunk = np.zeros(seg_samps, dtype=data.dtype)\n",
    "#             if start < data.size:\n",
    "#                 chunk[:max(0, min(seg_samps, data.size - start))] = data[start:end]\n",
    "\n",
    "#             # ── compute spectrogram ──────────────────────────────────────────\n",
    "#             f, t, Sxx = spectrogram(\n",
    "#                 chunk,\n",
    "#                 fs=sr,\n",
    "#                 window=windows.gaussian(2048, std=2048/8),\n",
    "#                 nperseg=2048,\n",
    "#                 noverlap=2048 - 119\n",
    "#             )\n",
    "\n",
    "#             # ── convert to dB and clamp dynamic range ────────────────────────\n",
    "#             Sxx_dB = 10 * np.log10(Sxx + np.finfo(float).eps)\n",
    "#             vmax = Sxx_dB.max()\n",
    "#             vmin = vmax - 60   # adjust dynamic range (e.g. top 60 dB)\n",
    "#             axs[i].imshow(\n",
    "#                 Sxx_dB,\n",
    "#                 aspect='auto',\n",
    "#                 origin='lower',\n",
    "#                 extent=[0, segment_duration, f.min(), f.max()],\n",
    "#                 cmap='gray_r',\n",
    "#                 vmin=vmin,\n",
    "#                 vmax=vmax\n",
    "#             )\n",
    "#             axs[i].set_ylim(0, 11000)\n",
    "\n",
    "#             # ── yellow highlights ───────────────────────────────────────────\n",
    "#             panel_off = i * segment_duration\n",
    "#             for s0, s1 in song_intervals:\n",
    "#                 if s0 < panel_off + segment_duration and s1 > panel_off:\n",
    "#                     x0 = max(0, s0 - panel_off)\n",
    "#                     x1 = min(segment_duration, s1 - panel_off)\n",
    "#                     axs[i].axvspan(x0, x1, color='yellow', alpha=0.1)\n",
    "\n",
    "#             # ── red boundaries ───────────────────────────────────────────────\n",
    "#             for btime in boundaries:\n",
    "#                 if panel_off < btime < panel_off + segment_duration:\n",
    "#                     axs[i].axvline(btime - panel_off,\n",
    "#                                    color='red',\n",
    "#                                    linestyle='--',\n",
    "#                                    linewidth=1.2)\n",
    "\n",
    "#             axs[i].set_ylabel('Freq [Hz]')\n",
    "#             if i == nseg - 1:\n",
    "#                 axs[i].set_xlabel('Time [sec]')\n",
    "#                 axs[i].set_xticks(np.linspace(0, segment_duration, 5))\n",
    "\n",
    "#         fig.suptitle(f'{base_name} – Spectrogram (Filtered {low_cut}-{high_cut} Hz)', fontsize=14)\n",
    "#         fig.tight_layout()\n",
    "#         fig.savefig(out_path, dpi=300)\n",
    "#         plt.close(fig)\n",
    "#         print(f\"✅ Saved: {out_path}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ Error processing {file_path} – {e}\")\n",
    "\n",
    "# def batch_process_folder(folder_path, segment_duration=10):\n",
    "#     spectrogram_folder = Path(folder_path) / \"spectrograms\"\n",
    "#     spectrogram_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     wavs = list(Path(folder_path).glob(\"*.wav\"))\n",
    "#     if not wavs:\n",
    "#         print(\"No .wav files found.\")\n",
    "#         return\n",
    "\n",
    "#     print(f\"\\n📂 Processing {len(wavs)} files in {folder_path}\\n\")\n",
    "#     for wf in wavs:\n",
    "#         process_wav_file(str(wf), str(spectrogram_folder),\n",
    "#                          segment_duration=segment_duration)\n",
    "\n",
    "# # === USER CONFIGURE & RUN ===\n",
    "# if __name__ == \"__main__\":\n",
    "#     # point this to your folder of .wav files\n",
    "#     #folder = \"/path/to/your/wav_folder\"\n",
    "#     batch_process_folder(spectrogram_output_folder, segment_duration=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98f3053",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BYOD_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
