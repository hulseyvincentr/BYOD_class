{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b688551a",
   "metadata": {},
   "source": [
    "# This code uses a .json file with file names and detected song intervals, then assembles either: 1) recording segments that contain song or 2) entire files that contain song.\n",
    "\n",
    "## Both data outputs are saved in the original folder_path.\n",
    "- folder_path is a path to a folder that contains all of the .wav file recordings.\n",
    "- json_path is a path to a .json file output by a song detector code, which contains each .wav file name from folder_path and, if there was detected song, the time segments with detected song in them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64cd353",
   "metadata": {},
   "source": [
    "## Option 1: only generate spectrograms of time setgments with detected song. \n",
    "### This code uses the time segments inside of the .json file to combine songs into 1 minute .wav files containing song, then saves those .wav files and generates .pngs of their spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d5855eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ…  Saved detected_song_minute_1_partial.wav  (32.19â€¯s)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CONFIG â”€â”€ change these two paths only\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "folder_path = (\n",
    "    \"/Users/mirandahulsey-vincent/Documents/allPythonCode/\"\n",
    "    \"BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files\"\n",
    ")\n",
    "json_path = (\n",
    "    \"/Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files_longamp_detected_song_intervals.json\"\n",
    ")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# OPTIONAL RUNTIME SETTINGS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "chunk_duration_sec       = 60      # target length of each output clip\n",
    "save_partial_final_chunk = True    # save the trailing < 60â€‘s chunk?\n",
    "pad_partial_with_zeros   = False   # â€¦and pad it up to 60â€¯s?\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SETâ€‘UP â”€â”€ output folder\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "output_folder = os.path.join(folder_path, \"detected_song_minutes\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# STEPÂ 1 â”€â”€ load JSON with [start,â€¯end] times in seconds\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "with open(json_path, \"r\") as f:\n",
    "    detected_intervals = json.load(f)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# STEPÂ 2 â”€â”€ slice out every detected interval and collect in RAM\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "detected_segments      = []\n",
    "sample_rate_reference  = None\n",
    "\n",
    "for file_name, intervals in detected_intervals.items():\n",
    "    wav_path = os.path.join(folder_path, file_name)\n",
    "    if not os.path.exists(wav_path):\n",
    "        print(f\"âš ï¸  Missing file: {file_name}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        samplerate, data = wavfile.read(wav_path)\n",
    "\n",
    "        # keep the first fileâ€™s sampleâ€‘rate as the reference\n",
    "        if sample_rate_reference is None:\n",
    "            sample_rate_reference = samplerate\n",
    "        elif samplerate != sample_rate_reference:\n",
    "            raise ValueError(f\"Sampleâ€‘rate mismatch in {file_name}\")\n",
    "\n",
    "        # stereo â†’ mono\n",
    "        if data.ndim > 1:\n",
    "            data = data.mean(axis=1)\n",
    "\n",
    "        # extract all (start, end) snippets\n",
    "        for start_time, end_time in intervals:\n",
    "            start = int(start_time * samplerate)\n",
    "            end   = int(end_time   * samplerate)\n",
    "            detected_segments.append(data[start:end])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Error reading {file_name}: {e}\")\n",
    "\n",
    "if not detected_segments:\n",
    "    raise RuntimeError(\"No detected song segments were found in the JSON file.\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# STEPÂ 3 â”€â”€ concatenate and split into â‰¤60â€‘s chunks\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "concatenated   = np.concatenate(detected_segments)\n",
    "target_samples = chunk_duration_sec * sample_rate_reference\n",
    "\n",
    "minute_segments = []\n",
    "\n",
    "for i in range(0, len(concatenated), target_samples):\n",
    "    chunk = concatenated[i : i + target_samples]\n",
    "\n",
    "    if len(chunk) == target_samples:\n",
    "        # fullâ€‘length minute\n",
    "        minute_segments.append(chunk)\n",
    "\n",
    "    elif save_partial_final_chunk and len(chunk) > 0:\n",
    "        # trailing < 60â€‘s chunk\n",
    "        if pad_partial_with_zeros:\n",
    "            pad_len = target_samples - len(chunk)\n",
    "            chunk   = np.pad(chunk, (0, pad_len), mode=\"constant\")\n",
    "        minute_segments.append(chunk)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# STEPÂ 4 â”€â”€ write each chunk to disk\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "for idx, segment in enumerate(minute_segments, start=1):\n",
    "    duration_sec = len(segment) / sample_rate_reference\n",
    "    suffix       = \"_partial\" if duration_sec < chunk_duration_sec else \"\"\n",
    "    fname        = f\"detected_song_minute_{idx}{suffix}.wav\"\n",
    "    fpath        = os.path.join(output_folder, fname)\n",
    "\n",
    "    wavfile.write(fpath, sample_rate_reference, segment.astype(np.int16))\n",
    "    print(f\"âœ…  Saved {fname}  ({duration_sec:.2f}â€¯s)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6689e7",
   "metadata": {},
   "source": [
    "### generate the spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f02c90fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‚ Processing 1 files in: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files/detected_song_minutes\n",
      "\n",
      "âœ… Saved: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files/detected_song_minutes/spectrograms/detected_song_minute_1_partial_spectrogram.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram, windows, ellip, filtfilt\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter as tk\n",
    "import json\n",
    "\n",
    "def get_screen_resolution():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    screen_width = root.winfo_screenwidth()\n",
    "    screen_height = root.winfo_screenheight()\n",
    "    root.destroy()\n",
    "    return screen_width / 100, screen_height / 100  # inches\n",
    "\n",
    "width_inches, height_inches = get_screen_resolution()\n",
    "\n",
    "# === Load JSON file once\n",
    "with open(json_path, 'r') as f:\n",
    "    file_lists = json.load(f)\n",
    "\n",
    "def process_wav_file(file_path, spectrogram_folder, segment_duration=10, low_cut=500, high_cut=8000):\n",
    "    try:\n",
    "        base_name = Path(file_path).stem\n",
    "        samplerate, data = wavfile.read(file_path)\n",
    "        if data.ndim > 1:\n",
    "            data = data.mean(axis=1)\n",
    "\n",
    "        nyquist = samplerate / 2\n",
    "        wp = [low_cut / nyquist, high_cut / nyquist]\n",
    "        b, a = ellip(5, 0.2, 40, wp, btype='band')\n",
    "        data = filtfilt(b, a, data)\n",
    "\n",
    "        duration_seconds = data.shape[0] / samplerate\n",
    "        segment_length_samples = int(segment_duration * samplerate)\n",
    "        num_segments = min(6, int(np.ceil(duration_seconds / segment_duration)))\n",
    "\n",
    "        spectrogram_fig_path = os.path.join(spectrogram_folder, f\"{base_name}_spectrogram.png\")\n",
    "\n",
    "        fig, axs = plt.subplots(num_segments, 1, figsize=(width_inches, height_inches), sharex=True, gridspec_kw={'hspace': 0.0})\n",
    "        if num_segments == 1:\n",
    "            axs = [axs]\n",
    "\n",
    "        red_lines_sec = []\n",
    "        if f\"{base_name}.wav\" in file_lists:\n",
    "            red_lines_sec = [entry[\"start_sample\"] / samplerate for entry in file_lists[f\"{base_name}.wav\"]]\n",
    "\n",
    "        for i in range(num_segments):\n",
    "            start_sample = i * segment_length_samples\n",
    "            end_sample = start_sample + segment_length_samples\n",
    "            segment_data = np.zeros(segment_length_samples, dtype=data.dtype)\n",
    "            if start_sample < data.shape[0]:\n",
    "                segment_data[:max(0, min(segment_length_samples, data.shape[0] - start_sample))] = data[start_sample:end_sample]\n",
    "\n",
    "            f, t, Sxx = spectrogram(\n",
    "                segment_data,\n",
    "                fs=samplerate,\n",
    "                window=windows.gaussian(2048, std=2048/8),\n",
    "                nperseg=2048,\n",
    "                noverlap=(2048 - 119)\n",
    "            )\n",
    "\n",
    "            Sxx_log = 10 * np.log10(Sxx + np.finfo(float).eps)\n",
    "            Sxx_log_clipped = np.clip(Sxx_log, a_min=3, a_max=None)\n",
    "            Sxx_log_normalized = (Sxx_log_clipped - np.min(Sxx_log_clipped)) / (np.max(Sxx_log_clipped) - np.min(Sxx_log_clipped))\n",
    "            Sxx_log_normalized = np.power(Sxx_log_normalized, 0.7)\n",
    "\n",
    "            axs[i].imshow(Sxx_log_normalized, aspect='auto', origin='lower',\n",
    "                          extent=[0, segment_duration, f.min(), f.max()], cmap='binary')\n",
    "\n",
    "            for x in red_lines_sec:\n",
    "                if start_sample / samplerate <= x < end_sample / samplerate:\n",
    "                    axs[i].axvline(x - (start_sample / samplerate), color='red', linestyle='-', linewidth=1)\n",
    "\n",
    "            axs[i].set_ylabel('Freq [Hz]')\n",
    "            if i == num_segments - 1:\n",
    "                axs[i].set_xlabel('Time [sec]')\n",
    "                axs[i].set_xticks(np.linspace(0, segment_duration, 5))\n",
    "\n",
    "        fig.suptitle(f'{base_name} â€“ Spectrogram (Filtered {low_cut}-{high_cut} Hz)', fontsize=14)\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(spectrogram_fig_path, dpi=300)\n",
    "        plt.close(fig)\n",
    "        print(f\"âœ… Saved: {spectrogram_fig_path}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {file_path}: {e}\")\n",
    "\n",
    "def batch_process_folder(folder_path, segment_duration=10):\n",
    "    output_folder = os.path.join(folder_path)\n",
    "    spectrogram_folder = os.path.join(output_folder, \"spectrograms\")\n",
    "    os.makedirs(spectrogram_folder, exist_ok=True)\n",
    "\n",
    "    wav_files = [f for f in Path(folder_path).glob(\"*.wav\")]\n",
    "    if not wav_files:\n",
    "        print(\"No .wav files found in the selected folder.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nğŸ“‚ Processing {len(wav_files)} files in: {folder_path}\\n\")\n",
    "    for wav_file in wav_files:\n",
    "        process_wav_file(wav_file, spectrogram_folder, segment_duration=segment_duration)\n",
    "\n",
    "# === USER INPUT ===\n",
    "#folder_path = '/Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_unsegmented_songs/55/detected_song_minutes'\n",
    "save_minutes_folder_path = folder_path + '/detected_song_minutes'\n",
    "batch_process_folder(\n",
    "    save_minutes_folder_path,\n",
    "    segment_duration=10  # Each panel = 10s; total of 6 panels = 60s\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970d3783",
   "metadata": {},
   "source": [
    "# Option 2: This portion combines all .wav files containing songs into 1-minute recordings, then  generates spectrograms of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0934973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ…  Saved detected_song_minute_1.wav\n",
      "âœ…  Saved detected_song_minute_2.wav\n",
      "âœ…  Saved detected_song_minute_3.wav\n",
      "âœ…  Saved detected_song_minute_4.wav\n",
      "âœ…  Saved detected_song_minute_5.wav\n",
      "ğŸ“„  Metadata saved to: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files/detected_song_files_full_recordings/segment_metadata.json\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from pathlib import Path   # (unused but often handy)\n",
    "\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# CONFIG â”€â”€ update these two paths only\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# folder_path = '/your/recordings/folder'\n",
    "# json_path   = '/your/detector_output.json'\n",
    "\n",
    "# â”€â”€ derived paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "output_folder       = os.path.join(folder_path, 'detected_song_files_full_recordings')\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "metadata_output_path = os.path.join(output_folder, 'segment_metadata.json')\n",
    "\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# LOAD detector JSON  â†’  {wav_file : [[start,end], â€¦]}\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "with open(json_path) as f:\n",
    "    detected_intervals = json.load(f)\n",
    "\n",
    "# process files in deterministic order\n",
    "file_names = sorted(detected_intervals.keys())\n",
    "\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# READ all wavs into memory (could be streamed if very large files)\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "audio_queue            = []            # [(file_name, data)]\n",
    "sample_rate_reference  = None\n",
    "\n",
    "for fn in file_names:\n",
    "    wav_path = os.path.join(folder_path, fn)\n",
    "    if not os.path.exists(wav_path):\n",
    "        print(f\"âš ï¸  Missing file: {fn}\")\n",
    "        continue\n",
    "    try:\n",
    "        sr, data = wavfile.read(wav_path)\n",
    "        if sample_rate_reference is None:\n",
    "            sample_rate_reference = sr\n",
    "        elif sr != sample_rate_reference:\n",
    "            raise ValueError(f\"Sampleâ€‘rate mismatch in {fn} ({sr}Â vsÂ {sample_rate_reference})\")\n",
    "        if data.ndim > 1:                       # stereo â†’ mono\n",
    "            data = data.mean(axis=1)\n",
    "        audio_queue.append((fn, data.astype(np.float32)))\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Error reading {fn}: {e}\")\n",
    "\n",
    "if not audio_queue:\n",
    "    raise RuntimeError(\"No audio files were loaded successfully.\")\n",
    "\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# CHUNKING variables & helpers\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "minute_samples      = 60 * sample_rate_reference\n",
    "leftover            = np.array([], dtype=np.float32)\n",
    "leftover_provenance = []      # list of dicts: {\"source_file\", \"range_start\", \"range_end\"}\n",
    "segment_metadata    = {}\n",
    "chunk_count         = 0\n",
    "\n",
    "def get_song_segments_within_range(source_file, range_start, range_end):\n",
    "    \"\"\"Return detector intervals (sec) that overlap [range_start, range_end) in sample coords,\n",
    "       expressed relative to the *start of that range*.\"\"\"\n",
    "    out = []\n",
    "    for t_start, t_end in detected_intervals.get(source_file, []):\n",
    "        s_start = int(t_start * sample_rate_reference)\n",
    "        s_end   = int(t_end   * sample_rate_reference)\n",
    "        ov_start = max(s_start, range_start)\n",
    "        ov_end   = min(s_end,   range_end)\n",
    "        if ov_start < ov_end:\n",
    "            out.append([\n",
    "                round((ov_start - range_start) / sample_rate_reference, 3),\n",
    "                round((ov_end   - range_start) / sample_rate_reference, 3)\n",
    "            ])\n",
    "    return out\n",
    "\n",
    "def finalize_chunk(chunk_data, provenance, song_segments, idx):\n",
    "    fname = f'detected_song_minute_{idx+1}.wav'\n",
    "    fpath = os.path.join(output_folder, fname)\n",
    "    wavfile.write(fpath, sample_rate_reference, chunk_data.astype(np.int16))\n",
    "    segment_metadata[fname] = {\n",
    "        \"source_files\": provenance,\n",
    "        \"song_segments_in_chunk\": song_segments\n",
    "    }\n",
    "    print(f\"âœ…  Saved {fname}\")\n",
    "\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# MAIN loop â€“ stitch files, slice 60â€‘s chunks, preserve provenance\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "for file_name, data in audio_queue:\n",
    "\n",
    "    # 1) build new \"combined\" buffer = leftover + current file\n",
    "    combined         = np.concatenate([leftover, data])\n",
    "    combined_ranges  = []          # [{\"source_file\", \"range_start\", \"range_end\"}]\n",
    "    offset           = 0\n",
    "\n",
    "    # carry forward *all* leftover provenance\n",
    "    for prov in leftover_provenance:\n",
    "        dur = prov[\"range_end\"] - prov[\"range_start\"]\n",
    "        combined_ranges.append({\n",
    "            \"source_file\": prov[\"source_file\"],\n",
    "            \"range_start\": offset,\n",
    "            \"range_end\":   offset + dur\n",
    "        })\n",
    "        offset += dur\n",
    "\n",
    "    # append current fileâ€™s span\n",
    "    combined_ranges.append({\n",
    "        \"source_file\": file_name,\n",
    "        \"range_start\": offset,\n",
    "        \"range_end\":   offset + len(data)\n",
    "    })\n",
    "\n",
    "    # 2) slice fullâ€‘minute chunks\n",
    "    cursor = 0\n",
    "    while cursor + minute_samples <= len(combined):\n",
    "        chunk               = combined[cursor:cursor + minute_samples]\n",
    "        chunk_provenance    = []\n",
    "        chunk_song_segments = []\n",
    "\n",
    "        chunk_start = cursor\n",
    "        chunk_end   = cursor + minute_samples\n",
    "\n",
    "        for rng in combined_ranges:\n",
    "            src_start, src_end = rng[\"range_start\"], rng[\"range_end\"]\n",
    "            ov_start = max(chunk_start, src_start)\n",
    "            ov_end   = min(chunk_end,   src_end)\n",
    "            if ov_start < ov_end:   # overlap exists\n",
    "                # provenance entry\n",
    "                rel_start_sec = (ov_start - chunk_start) / sample_rate_reference\n",
    "                rel_end_sec   = (ov_end   - chunk_start) / sample_rate_reference\n",
    "                chunk_provenance.append({\n",
    "                    \"source_file\": rng[\"source_file\"],\n",
    "                    \"time_range_in_chunk_seconds\": [round(rel_start_sec,3),\n",
    "                                                   round(rel_end_sec,3)]\n",
    "                })\n",
    "                # song segments from this slice\n",
    "                slice_rel_start = ov_start - src_start\n",
    "                slice_rel_end   = ov_end   - src_start\n",
    "                for seg in get_song_segments_within_range(\n",
    "                        rng[\"source_file\"], slice_rel_start, slice_rel_end):\n",
    "                    chunk_song_segments.append([\n",
    "                        round(seg[0] + rel_start_sec, 3),\n",
    "                        round(seg[1] + rel_start_sec, 3)\n",
    "                    ])\n",
    "\n",
    "        finalize_chunk(chunk, chunk_provenance, chunk_song_segments, chunk_count)\n",
    "        chunk_count += 1\n",
    "        cursor      += minute_samples\n",
    "\n",
    "    # 3) whatever is left < 60â€¯s â†’ carry to next iteration\n",
    "    leftover = combined[cursor:]\n",
    "    leftover_provenance = []\n",
    "    if len(leftover) > 0:\n",
    "        for rng in combined_ranges:\n",
    "            if rng[\"range_end\"] > cursor:                      # part survives\n",
    "                leftover_provenance.append({\n",
    "                    \"source_file\": rng[\"source_file\"],\n",
    "                    \"range_start\": max(0,   rng[\"range_start\"] - cursor),\n",
    "                    \"range_end\":   rng[\"range_end\"] - cursor\n",
    "                })\n",
    "\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# FINAL (possibly padded) chunk made from leftover audio\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "if len(leftover) > 0:\n",
    "    padded = np.pad(leftover, (0, minute_samples - len(leftover)), mode=\"constant\")\n",
    "    final_prov  = []\n",
    "    final_segs  = []\n",
    "    for rng in leftover_provenance:\n",
    "        p_start_sec = rng[\"range_start\"] / sample_rate_reference\n",
    "        p_end_sec   = rng[\"range_end\"]   / sample_rate_reference\n",
    "        final_prov.append({\n",
    "            \"source_file\": rng[\"source_file\"],\n",
    "            \"time_range_in_chunk_seconds\": [round(p_start_sec,3), round(p_end_sec,3)]\n",
    "        })\n",
    "        for seg in get_song_segments_within_range(\n",
    "                rng[\"source_file\"], 0, rng[\"range_end\"] - rng[\"range_start\"]):\n",
    "            final_segs.append([\n",
    "                round(seg[0] + p_start_sec, 3),\n",
    "                round(seg[1] + p_start_sec, 3)\n",
    "            ])\n",
    "    finalize_chunk(padded, final_prov, final_segs, chunk_count)\n",
    "\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# WRITE master metadata file\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "with open(metadata_output_path, \"w\") as f:\n",
    "    json.dump(segment_metadata, f, indent=2)\n",
    "\n",
    "print(f\"ğŸ“„  Metadata saved to: {metadata_output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a131047",
   "metadata": {},
   "source": [
    "### generate the spectrogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63a67a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‚ Processing 5 files in: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files/detected_song_files_full_recordings\n",
      "\n",
      "âœ… Saved: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files/detected_song_files_full_recordings/spectrograms/detected_song_minute_2_spectrogram.png\n",
      "\n",
      "âœ… Saved: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files/detected_song_files_full_recordings/spectrograms/detected_song_minute_3_spectrogram.png\n",
      "\n",
      "âœ… Saved: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files/detected_song_files_full_recordings/spectrograms/detected_song_minute_1_spectrogram.png\n",
      "\n",
      "âœ… Saved: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files/detected_song_files_full_recordings/spectrograms/detected_song_minute_4_spectrogram.png\n",
      "\n",
      "âœ… Saved: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files/detected_song_files_full_recordings/spectrograms/detected_song_minute_5_spectrogram.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram, windows, ellip, filtfilt\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter as tk\n",
    "import json\n",
    "from scipy.signal import spectrogram, windows, filtfilt, ellip\n",
    "\n",
    "def process_wav_file(file_path, spectrogram_folder, segment_duration=10, low_cut=500, high_cut=8000):\n",
    "    try:\n",
    "        base_name = Path(file_path).stem\n",
    "        samplerate, data = wavfile.read(file_path)\n",
    "        if data.ndim > 1:\n",
    "            data = data.mean(axis=1)\n",
    "\n",
    "        # === Apply Bandpass Filter ===\n",
    "        nyquist = samplerate / 2\n",
    "        wp = [low_cut / nyquist, high_cut / nyquist]\n",
    "        b, a = ellip(5, 0.2, 40, wp, btype='band')\n",
    "        data = filtfilt(b, a, data)\n",
    "\n",
    "        duration_seconds = data.shape[0] / samplerate\n",
    "        segment_length_samples = int(segment_duration * samplerate)\n",
    "        num_segments = min(6, int(np.ceil(duration_seconds / segment_duration)))\n",
    "\n",
    "        spectrogram_fig_path = os.path.join(spectrogram_folder, f\"{base_name}_spectrogram.png\")\n",
    "\n",
    "        fig, axs = plt.subplots(num_segments, 1, figsize=(width_inches, height_inches), sharex=True, gridspec_kw={'hspace': 0.0})\n",
    "        if num_segments == 1:\n",
    "            axs = [axs]\n",
    "\n",
    "        metadata_key = f\"{base_name}.wav\"\n",
    "        song_intervals = []\n",
    "        boundary_lines = []\n",
    "\n",
    "        if metadata_key in segment_metadata:\n",
    "            entry = segment_metadata[metadata_key]\n",
    "            song_intervals = entry.get(\"song_segments_in_chunk\", [])\n",
    "            for src in entry.get(\"source_files\", []):\n",
    "                if \"time_range_in_chunk_seconds\" in src:\n",
    "                    end = src[\"time_range_in_chunk_seconds\"][1]\n",
    "                    boundary_lines.append(end)\n",
    "\n",
    "        for i in range(num_segments):\n",
    "            start_sample = i * segment_length_samples\n",
    "            end_sample = start_sample + segment_length_samples\n",
    "            segment_data = np.zeros(segment_length_samples, dtype=data.dtype)\n",
    "            if start_sample < data.shape[0]:\n",
    "                segment_data[:max(0, min(segment_length_samples, data.shape[0] - start_sample))] = data[start_sample:end_sample]\n",
    "\n",
    "            f, t, Sxx = spectrogram(\n",
    "                segment_data,\n",
    "                fs=samplerate,\n",
    "                window=windows.gaussian(2048, std=2048/8),\n",
    "                nperseg=2048,\n",
    "                noverlap=(2048 - 119)\n",
    "            )\n",
    "\n",
    "            Sxx_log = 10 * np.log10(Sxx + np.finfo(float).eps)\n",
    "            Sxx_log_clipped = np.clip(Sxx_log, a_min=3, a_max=None)\n",
    "            Sxx_log_normalized = (Sxx_log_clipped - np.min(Sxx_log_clipped)) / (np.max(Sxx_log_clipped) - np.min(Sxx_log_clipped))\n",
    "            Sxx_log_normalized = np.power(Sxx_log_normalized, 0.7)\n",
    "\n",
    "            axs[i].imshow(Sxx_log_normalized, aspect='auto', origin='lower',\n",
    "                          extent=[0, segment_duration, f.min(), f.max()], cmap='binary')\n",
    "\n",
    "            # === Yellow highlight for song intervals ===\n",
    "            panel_start = i * segment_duration\n",
    "            panel_end = panel_start + segment_duration\n",
    "            for interval_start, interval_end in song_intervals:\n",
    "                if interval_start < panel_end and interval_end > panel_start:\n",
    "                    x0 = max(0, interval_start - panel_start)\n",
    "                    x1 = min(segment_duration, interval_end - panel_start)\n",
    "                    axs[i].axvspan(x0, x1, color='yellow', alpha=0.4)\n",
    "\n",
    "            # === Red dashed lines for source boundaries ===\n",
    "            for boundary_time in boundary_lines:\n",
    "                if panel_start < boundary_time < panel_end:\n",
    "                    axs[i].axvline(boundary_time - panel_start, color='red', linestyle='--', linewidth=1.2)\n",
    "\n",
    "            axs[i].set_ylabel('Freq [Hz]')\n",
    "            if i == num_segments - 1:\n",
    "                axs[i].set_xlabel('Time [sec]')\n",
    "                axs[i].set_xticks(np.linspace(0, segment_duration, 5))\n",
    "\n",
    "        fig.suptitle(f'{base_name} â€“ Spectrogram (Filtered {low_cut}-{high_cut} Hz)', fontsize=14)\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(spectrogram_fig_path, dpi=300)\n",
    "        plt.close(fig)\n",
    "        print(f\"âœ… Saved: {spectrogram_fig_path}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {file_path}: {e}\")\n",
    "\n",
    "\n",
    "def batch_process_folder(folder_path, segment_duration=10):\n",
    "    output_folder = os.path.join(folder_path)\n",
    "    spectrogram_folder = os.path.join(output_folder, \"spectrograms\")\n",
    "    os.makedirs(spectrogram_folder, exist_ok=True)\n",
    "\n",
    "    wav_files = [f for f in Path(folder_path).glob(\"*.wav\")]\n",
    "    if not wav_files:\n",
    "        print(\"No .wav files found in the selected folder.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nğŸ“‚ Processing {len(wav_files)} files in: {folder_path}\\n\")\n",
    "    for wav_file in wav_files:\n",
    "        process_wav_file(wav_file, spectrogram_folder, segment_duration=segment_duration)\n",
    "\n",
    "# === USER INPUT ===\n",
    "spectrogram_output_folder = output_folder\n",
    "batch_process_folder(\n",
    "    spectrogram_output_folder,\n",
    "    segment_duration=10  # Each panel = 10s; total of 6 panels = 60s\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323fc851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BYOD_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
