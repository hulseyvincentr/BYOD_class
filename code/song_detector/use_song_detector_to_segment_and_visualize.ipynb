{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b688551a",
   "metadata": {},
   "source": [
    "# This code uses a .json file with file names and detected song intervals, then assembles either: 1) recording segments that contain song or 2) entire files that contain song.\n",
    "\n",
    "## Both data outputs are saved in the original folder_path.\n",
    "- folder_path is a path to a folder that contains all of the .wav file recordings.\n",
    "- json_path is a path to a .json file output by a song detector code, which contains each .wav file name from folder_path and, if there was detected song, the time segments with detected song in them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64cd353",
   "metadata": {},
   "source": [
    "## Option 1: only generate spectrograms of time setgments with detected song. \n",
    "### This code uses the time segments inside of the .json file to combine songs into 1 minute .wav files containing song, then saves those .wav files and generates .pngs of their spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f1fa98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import json\n",
    "# from scipy.io import wavfile\n",
    "# from pathlib import Path\n",
    "\n",
    "# # === CONFIG ===\n",
    "# folder_path = '/Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files'  # Update this path\n",
    "# json_path = '/Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files_amplitude_only_detected_song_intervals.json'  # Update this path\n",
    "# output_folder = os.path.join(folder_path, 'detected_song_minutes')\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.makedirs(output_folder)\n",
    "\n",
    "# # === Load JSON Detected Intervals ===\n",
    "# with open(json_path, 'r') as f:\n",
    "#     detected_intervals = json.load(f)\n",
    "\n",
    "# # === Step 1: Extract detected segments ===\n",
    "# detected_segments = []\n",
    "# sample_rate_reference = None\n",
    "\n",
    "# for file_name, intervals in detected_intervals.items():\n",
    "#     wav_path = os.path.join(folder_path, file_name)\n",
    "#     if not os.path.exists(wav_path):\n",
    "#         print(f\"Missing file: {file_name}\")\n",
    "#         continue\n",
    "\n",
    "#     try:\n",
    "#         samplerate, data = wavfile.read(wav_path)\n",
    "#         if sample_rate_reference is None:\n",
    "#             sample_rate_reference = samplerate\n",
    "#         elif samplerate != sample_rate_reference:\n",
    "#             raise ValueError(f\"Sample rate mismatch in {file_name}\")\n",
    "\n",
    "#         if data.ndim > 1:\n",
    "#             data = data.mean(axis=1)\n",
    "\n",
    "#         for start_time, end_time in intervals:\n",
    "#             start_sample = int(start_time * samplerate)\n",
    "#             end_sample = int(end_time * samplerate)\n",
    "#             detected_segments.append(data[start_sample:end_sample])\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error reading {file_name}: {e}\")\n",
    "#         continue\n",
    "\n",
    "# # === Step 2: Concatenate into 1-minute chunks ===\n",
    "# target_samples = 60 * sample_rate_reference\n",
    "# concatenated = np.concatenate(detected_segments)\n",
    "\n",
    "# minute_segments = []\n",
    "# for i in range(0, len(concatenated), target_samples):\n",
    "#     chunk = concatenated[i:i + target_samples]\n",
    "#     if len(chunk) == target_samples:\n",
    "#         minute_segments.append(chunk)\n",
    "\n",
    "# # === Step 3: Save 1-minute .wav files ===\n",
    "# for i, segment in enumerate(minute_segments):\n",
    "#     output_path = os.path.join(output_folder, f'detected_song_minute_{i+1}.wav')\n",
    "#     wavfile.write(output_path, sample_rate_reference, segment.astype(np.int16))\n",
    "#     print(f\"Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d5855eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Saved detected_song_minute_1_partial.wav  (36.79 s)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════\n",
    "# CONFIG ── change these two paths only\n",
    "# ════════════════════════════════════════════════════════════════════════\n",
    "folder_path = (\n",
    "    \"/Users/mirandahulsey-vincent/Documents/allPythonCode/\"\n",
    "    \"BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files\"\n",
    ")\n",
    "json_path = (\n",
    "    \"/Users/mirandahulsey-vincent/Documents/allPythonCode/\"\n",
    "    \"BYOD_class/data_inputs/USA5510_debug_segmenter/\"\n",
    "    \"sample_wav_files_amplitude_only_detected_song_intervals.json\"\n",
    ")\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════\n",
    "# OPTIONAL RUNTIME SETTINGS\n",
    "# ════════════════════════════════════════════════════════════════════════\n",
    "chunk_duration_sec       = 60      # target length of each output clip\n",
    "save_partial_final_chunk = True    # save the trailing < 60‑s chunk?\n",
    "pad_partial_with_zeros   = False   # …and pad it up to 60 s?\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════\n",
    "# SET‑UP ── output folder\n",
    "# ════════════════════════════════════════════════════════════════════════\n",
    "output_folder = os.path.join(folder_path, \"detected_song_minutes\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════\n",
    "# STEP 1 ── load JSON with [start, end] times in seconds\n",
    "# ════════════════════════════════════════════════════════════════════════\n",
    "with open(json_path, \"r\") as f:\n",
    "    detected_intervals = json.load(f)\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════\n",
    "# STEP 2 ── slice out every detected interval and collect in RAM\n",
    "# ════════════════════════════════════════════════════════════════════════\n",
    "detected_segments      = []\n",
    "sample_rate_reference  = None\n",
    "\n",
    "for file_name, intervals in detected_intervals.items():\n",
    "    wav_path = os.path.join(folder_path, file_name)\n",
    "    if not os.path.exists(wav_path):\n",
    "        print(f\"⚠️  Missing file: {file_name}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        samplerate, data = wavfile.read(wav_path)\n",
    "\n",
    "        # keep the first file’s sample‑rate as the reference\n",
    "        if sample_rate_reference is None:\n",
    "            sample_rate_reference = samplerate\n",
    "        elif samplerate != sample_rate_reference:\n",
    "            raise ValueError(f\"Sample‑rate mismatch in {file_name}\")\n",
    "\n",
    "        # stereo → mono\n",
    "        if data.ndim > 1:\n",
    "            data = data.mean(axis=1)\n",
    "\n",
    "        # extract all (start, end) snippets\n",
    "        for start_time, end_time in intervals:\n",
    "            start = int(start_time * samplerate)\n",
    "            end   = int(end_time   * samplerate)\n",
    "            detected_segments.append(data[start:end])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Error reading {file_name}: {e}\")\n",
    "\n",
    "if not detected_segments:\n",
    "    raise RuntimeError(\"No detected song segments were found in the JSON file.\")\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════\n",
    "# STEP 3 ── concatenate and split into ≤60‑s chunks\n",
    "# ════════════════════════════════════════════════════════════════════════\n",
    "concatenated   = np.concatenate(detected_segments)\n",
    "target_samples = chunk_duration_sec * sample_rate_reference\n",
    "\n",
    "minute_segments = []\n",
    "\n",
    "for i in range(0, len(concatenated), target_samples):\n",
    "    chunk = concatenated[i : i + target_samples]\n",
    "\n",
    "    if len(chunk) == target_samples:\n",
    "        # full‑length minute\n",
    "        minute_segments.append(chunk)\n",
    "\n",
    "    elif save_partial_final_chunk and len(chunk) > 0:\n",
    "        # trailing < 60‑s chunk\n",
    "        if pad_partial_with_zeros:\n",
    "            pad_len = target_samples - len(chunk)\n",
    "            chunk   = np.pad(chunk, (0, pad_len), mode=\"constant\")\n",
    "        minute_segments.append(chunk)\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════\n",
    "# STEP 4 ── write each chunk to disk\n",
    "# ════════════════════════════════════════════════════════════════════════\n",
    "for idx, segment in enumerate(minute_segments, start=1):\n",
    "    duration_sec = len(segment) / sample_rate_reference\n",
    "    suffix       = \"_partial\" if duration_sec < chunk_duration_sec else \"\"\n",
    "    fname        = f\"detected_song_minute_{idx}{suffix}.wav\"\n",
    "    fpath        = os.path.join(output_folder, fname)\n",
    "\n",
    "    wavfile.write(fpath, sample_rate_reference, segment.astype(np.int16))\n",
    "    print(f\"✅  Saved {fname}  ({duration_sec:.2f} s)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6689e7",
   "metadata": {},
   "source": [
    "### generate the spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f02c90fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 Processing 1 files in: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files/detected_song_minutes\n",
      "\n",
      "✅ Saved: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files/detected_song_minutes/spectrograms/detected_song_minute_1_partial_spectrogram.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram, windows, ellip, filtfilt\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter as tk\n",
    "import json\n",
    "\n",
    "def get_screen_resolution():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    screen_width = root.winfo_screenwidth()\n",
    "    screen_height = root.winfo_screenheight()\n",
    "    root.destroy()\n",
    "    return screen_width / 100, screen_height / 100  # inches\n",
    "\n",
    "width_inches, height_inches = get_screen_resolution()\n",
    "\n",
    "# === Load JSON file once\n",
    "with open(json_path, 'r') as f:\n",
    "    file_lists = json.load(f)\n",
    "\n",
    "def process_wav_file(file_path, spectrogram_folder, segment_duration=10, low_cut=500, high_cut=8000):\n",
    "    try:\n",
    "        base_name = Path(file_path).stem\n",
    "        samplerate, data = wavfile.read(file_path)\n",
    "        if data.ndim > 1:\n",
    "            data = data.mean(axis=1)\n",
    "\n",
    "        nyquist = samplerate / 2\n",
    "        wp = [low_cut / nyquist, high_cut / nyquist]\n",
    "        b, a = ellip(5, 0.2, 40, wp, btype='band')\n",
    "        data = filtfilt(b, a, data)\n",
    "\n",
    "        duration_seconds = data.shape[0] / samplerate\n",
    "        segment_length_samples = int(segment_duration * samplerate)\n",
    "        num_segments = min(6, int(np.ceil(duration_seconds / segment_duration)))\n",
    "\n",
    "        spectrogram_fig_path = os.path.join(spectrogram_folder, f\"{base_name}_spectrogram.png\")\n",
    "\n",
    "        fig, axs = plt.subplots(num_segments, 1, figsize=(width_inches, height_inches), sharex=True, gridspec_kw={'hspace': 0.0})\n",
    "        if num_segments == 1:\n",
    "            axs = [axs]\n",
    "\n",
    "        red_lines_sec = []\n",
    "        if f\"{base_name}.wav\" in file_lists:\n",
    "            red_lines_sec = [entry[\"start_sample\"] / samplerate for entry in file_lists[f\"{base_name}.wav\"]]\n",
    "\n",
    "        for i in range(num_segments):\n",
    "            start_sample = i * segment_length_samples\n",
    "            end_sample = start_sample + segment_length_samples\n",
    "            segment_data = np.zeros(segment_length_samples, dtype=data.dtype)\n",
    "            if start_sample < data.shape[0]:\n",
    "                segment_data[:max(0, min(segment_length_samples, data.shape[0] - start_sample))] = data[start_sample:end_sample]\n",
    "\n",
    "            f, t, Sxx = spectrogram(\n",
    "                segment_data,\n",
    "                fs=samplerate,\n",
    "                window=windows.gaussian(2048, std=2048/8),\n",
    "                nperseg=2048,\n",
    "                noverlap=(2048 - 119)\n",
    "            )\n",
    "\n",
    "            Sxx_log = 10 * np.log10(Sxx + np.finfo(float).eps)\n",
    "            Sxx_log_clipped = np.clip(Sxx_log, a_min=3, a_max=None)\n",
    "            Sxx_log_normalized = (Sxx_log_clipped - np.min(Sxx_log_clipped)) / (np.max(Sxx_log_clipped) - np.min(Sxx_log_clipped))\n",
    "            Sxx_log_normalized = np.power(Sxx_log_normalized, 0.7)\n",
    "\n",
    "            axs[i].imshow(Sxx_log_normalized, aspect='auto', origin='lower',\n",
    "                          extent=[0, segment_duration, f.min(), f.max()], cmap='binary')\n",
    "\n",
    "            for x in red_lines_sec:\n",
    "                if start_sample / samplerate <= x < end_sample / samplerate:\n",
    "                    axs[i].axvline(x - (start_sample / samplerate), color='red', linestyle='-', linewidth=1)\n",
    "\n",
    "            axs[i].set_ylabel('Freq [Hz]')\n",
    "            if i == num_segments - 1:\n",
    "                axs[i].set_xlabel('Time [sec]')\n",
    "                axs[i].set_xticks(np.linspace(0, segment_duration, 5))\n",
    "\n",
    "        fig.suptitle(f'{base_name} – Spectrogram (Filtered {low_cut}-{high_cut} Hz)', fontsize=14)\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(spectrogram_fig_path, dpi=300)\n",
    "        plt.close(fig)\n",
    "        print(f\"✅ Saved: {spectrogram_fig_path}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {file_path}: {e}\")\n",
    "\n",
    "def batch_process_folder(folder_path, segment_duration=10):\n",
    "    output_folder = os.path.join(folder_path)\n",
    "    spectrogram_folder = os.path.join(output_folder, \"spectrograms\")\n",
    "    os.makedirs(spectrogram_folder, exist_ok=True)\n",
    "\n",
    "    wav_files = [f for f in Path(folder_path).glob(\"*.wav\")]\n",
    "    if not wav_files:\n",
    "        print(\"No .wav files found in the selected folder.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n📂 Processing {len(wav_files)} files in: {folder_path}\\n\")\n",
    "    for wav_file in wav_files:\n",
    "        process_wav_file(wav_file, spectrogram_folder, segment_duration=segment_duration)\n",
    "\n",
    "# === USER INPUT ===\n",
    "#folder_path = '/Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_unsegmented_songs/55/detected_song_minutes'\n",
    "save_minutes_folder_path = folder_path + '/detected_song_minutes'\n",
    "batch_process_folder(\n",
    "    save_minutes_folder_path,\n",
    "    segment_duration=10  # Each panel = 10s; total of 6 panels = 60s\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970d3783",
   "metadata": {},
   "source": [
    "# Option 2: This portion combines all .wav files containing songs into 1-minute recordings, then  generates spectrograms of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b6c0e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import json\n",
    "# from scipy.io import wavfile\n",
    "# from pathlib import Path\n",
    "\n",
    "# # === CONFIG ===\n",
    "# #folder_path = '/Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_unsegmented_songs/55'\n",
    "# #json_path = '/Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_unsegmented_songs/55_detected_song_intervals.json'\n",
    "\n",
    "# # Output folder\n",
    "# output_folder = folder_path + '/detected_song_files_full_recordings'\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.makedirs(output_folder)\n",
    "\n",
    "# # === Load Detected Intervals ===\n",
    "# with open(json_path, 'r') as f:\n",
    "#     detected_intervals = json.load(f)\n",
    "\n",
    "# # === Step 1: Sort the files for consistent order ===\n",
    "# file_names = sorted(detected_intervals.keys())\n",
    "\n",
    "# # === Step 2: Load full files with detected song ===\n",
    "# audio_queue = []\n",
    "# sample_rate_reference = None\n",
    "\n",
    "# for file_name in file_names:\n",
    "#     wav_path = os.path.join(folder_path, file_name)\n",
    "#     if not os.path.exists(wav_path):\n",
    "#         print(f\"Missing file: {file_name}\")\n",
    "#         continue\n",
    "\n",
    "#     try:\n",
    "#         samplerate, data = wavfile.read(wav_path)\n",
    "\n",
    "#         if sample_rate_reference is None:\n",
    "#             sample_rate_reference = samplerate\n",
    "#         elif samplerate != sample_rate_reference:\n",
    "#             raise ValueError(f\"Sample rate mismatch in {file_name}\")\n",
    "\n",
    "#         if data.ndim > 1:\n",
    "#             data = data.mean(axis=1)  # Convert to mono\n",
    "\n",
    "#         audio_queue.append(data)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error reading {file_name}: {e}\")\n",
    "#         continue\n",
    "\n",
    "# # === Step 3: Chunk into 1-minute segments ===\n",
    "# minute_samples = 60 * sample_rate_reference\n",
    "# leftover = np.array([], dtype=np.float32)\n",
    "# chunk_count = 0\n",
    "\n",
    "# for segment in audio_queue:\n",
    "#     # Combine leftover from previous file\n",
    "#     combined = np.concatenate([leftover, segment])\n",
    "\n",
    "#     # Chop into full 1-minute chunks\n",
    "#     while len(combined) >= minute_samples:\n",
    "#         chunk = combined[:minute_samples]\n",
    "#         output_filename = f'detected_song_minute_{chunk_count + 1}.wav'\n",
    "#         output_path = os.path.join(output_folder, output_filename)\n",
    "#         wavfile.write(output_path, sample_rate_reference, chunk.astype(np.int16))\n",
    "#         print(f\"Saved: {output_path}\")\n",
    "\n",
    "#         chunk_count += 1\n",
    "#         combined = combined[minute_samples:]  # keep the remainder\n",
    "\n",
    "#     leftover = combined  # update leftover for next file\n",
    "\n",
    "# # === Step 4: Save final leftover if non-empty\n",
    "# if len(leftover) > 0:\n",
    "#     padded = np.pad(leftover, (0, minute_samples - len(leftover)), mode='constant')\n",
    "#     chunk_count += 1\n",
    "#     output_filename = f'detected_song_minute_{chunk_count}.wav'\n",
    "#     output_path = os.path.join(output_folder, output_filename)\n",
    "#     wavfile.write(output_path, sample_rate_reference, padded.astype(np.int16))\n",
    "#     print(f\"Saved final partial chunk: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da8cc3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import json\n",
    "# from scipy.io import wavfile\n",
    "# from pathlib import Path\n",
    "\n",
    "# # === CONFIG ===\n",
    "# #folder_path = '/Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_unsegmented_songs/55'\n",
    "# #json_path = '/Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_unsegmented_songs/55_detected_song_intervals.json'\n",
    "\n",
    "# # Output folder and metadata path\n",
    "# output_folder = folder_path + '/detected_song_files_full_recordings'\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.makedirs(output_folder)\n",
    "\n",
    "# metadata_output_path = os.path.join(output_folder, 'segment_metadata.json')\n",
    "# segment_metadata = {}\n",
    "\n",
    "# # === Load Detected Intervals ===\n",
    "# with open(json_path, 'r') as f:\n",
    "#     detected_intervals = json.load(f)\n",
    "\n",
    "# # === Sort files to ensure consistent processing order ===\n",
    "# file_names = sorted(detected_intervals.keys())\n",
    "\n",
    "# # === Step 1: Load full audio files with detected song ===\n",
    "# audio_queue = []\n",
    "# sample_rate_reference = None\n",
    "\n",
    "# for file_name in file_names:\n",
    "#     wav_path = os.path.join(folder_path, file_name)\n",
    "#     if not os.path.exists(wav_path):\n",
    "#         print(f\"Missing file: {file_name}\")\n",
    "#         continue\n",
    "\n",
    "#     try:\n",
    "#         samplerate, data = wavfile.read(wav_path)\n",
    "\n",
    "#         if sample_rate_reference is None:\n",
    "#             sample_rate_reference = samplerate\n",
    "#         elif samplerate != sample_rate_reference:\n",
    "#             raise ValueError(f\"Sample rate mismatch in {file_name}\")\n",
    "\n",
    "#         if data.ndim > 1:\n",
    "#             data = data.mean(axis=1)  # Convert stereo to mono\n",
    "\n",
    "#         audio_queue.append((file_name, data))\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error reading {file_name}: {e}\")\n",
    "#         continue\n",
    "\n",
    "# # === Step 2: Assemble 1-minute segments with provenance tracking ===\n",
    "# minute_samples = 60 * sample_rate_reference\n",
    "# leftover = np.array([], dtype=np.float32)\n",
    "# leftover_provenance = []\n",
    "\n",
    "# chunk_count = 0\n",
    "# current_chunk = []\n",
    "# current_provenance = []\n",
    "\n",
    "# def finalize_chunk(chunk_data, provenance_list, chunk_index):\n",
    "#     output_filename = f'detected_song_minute_{chunk_index + 1}.wav'\n",
    "#     output_path = os.path.join(output_folder, output_filename)\n",
    "#     wavfile.write(output_path, sample_rate_reference, chunk_data.astype(np.int16))\n",
    "#     segment_metadata[output_filename] = provenance_list\n",
    "#     print(f\"Saved: {output_path}\")\n",
    "\n",
    "# for file_name, data in audio_queue:\n",
    "#     total_samples = len(data)\n",
    "\n",
    "#     # Add leftover from previous file\n",
    "#     combined = np.concatenate([leftover, data])\n",
    "#     combined_provenance = leftover_provenance.copy()\n",
    "\n",
    "#     if leftover.size > 0:\n",
    "#         combined_provenance.append({\n",
    "#             'source_file': leftover_provenance[-1]['source_file'],\n",
    "#             'segment_in_chunk': [0, len(leftover) / sample_rate_reference]\n",
    "#         })\n",
    "\n",
    "#     combined_provenance.append({\n",
    "#         'source_file': file_name,\n",
    "#         'segment_in_chunk': [\n",
    "#             len(leftover) / sample_rate_reference,\n",
    "#             (len(leftover) + total_samples) / sample_rate_reference\n",
    "#         ]\n",
    "#     })\n",
    "\n",
    "#     # Slice into full 1-minute chunks\n",
    "#     cursor = 0\n",
    "#     while len(combined) - cursor >= minute_samples:\n",
    "#         chunk = combined[cursor:cursor + minute_samples]\n",
    "\n",
    "#         # Calculate provenance within this chunk\n",
    "#         chunk_provenance = []\n",
    "#         chunk_start = cursor\n",
    "#         chunk_end = cursor + minute_samples\n",
    "#         for entry in combined_provenance:\n",
    "#             source_file = entry['source_file']\n",
    "#             seg_start_sec, seg_end_sec = entry['segment_in_chunk']\n",
    "#             seg_start = int(seg_start_sec * sample_rate_reference)\n",
    "#             seg_end = int(seg_end_sec * sample_rate_reference)\n",
    "\n",
    "#             # Determine overlap with current chunk\n",
    "#             overlap_start = max(chunk_start, seg_start)\n",
    "#             overlap_end = min(chunk_end, seg_end)\n",
    "\n",
    "#             if overlap_start < overlap_end:\n",
    "#                 chunk_start_in_sec = (overlap_start - chunk_start) / sample_rate_reference\n",
    "#                 chunk_end_in_sec = (overlap_end - chunk_start) / sample_rate_reference\n",
    "#                 chunk_provenance.append({\n",
    "#                     'source_file': source_file,\n",
    "#                     'time_range_in_chunk_seconds': [round(chunk_start_in_sec, 3), round(chunk_end_in_sec, 3)]\n",
    "#                 })\n",
    "\n",
    "#         finalize_chunk(chunk, chunk_provenance, chunk_count)\n",
    "#         chunk_count += 1\n",
    "#         cursor += minute_samples\n",
    "\n",
    "#     # Save the remainder for the next chunk\n",
    "#     leftover = combined[cursor:]\n",
    "#     leftover_provenance = [{\n",
    "#         'source_file': file_name,\n",
    "#         'segment_in_chunk': [\n",
    "#             (cursor - len(combined) + total_samples) / sample_rate_reference,\n",
    "#             total_samples / sample_rate_reference\n",
    "#         ]\n",
    "#     }]\n",
    "\n",
    "# # === Step 3: Final leftover segment (pad if needed) ===\n",
    "# if len(leftover) > 0:\n",
    "#     padded = np.pad(leftover, (0, minute_samples - len(leftover)), mode='constant')\n",
    "\n",
    "#     # Adjust final provenance times\n",
    "#     final_provenance = []\n",
    "#     total_sec = len(leftover) / sample_rate_reference\n",
    "#     for entry in leftover_provenance:\n",
    "#         seg_start = entry['segment_in_chunk'][0]\n",
    "#         seg_end = entry['segment_in_chunk'][1]\n",
    "#         seg_end = min(seg_end, seg_start + total_sec)\n",
    "#         final_provenance.append({\n",
    "#             'source_file': entry['source_file'],\n",
    "#             'time_range_in_chunk_seconds': [\n",
    "#                 round(seg_start, 3),\n",
    "#                 round(seg_end, 3)\n",
    "#             ]\n",
    "#         })\n",
    "\n",
    "#     finalize_chunk(padded, final_provenance, chunk_count)\n",
    "\n",
    "# # === Step 4: Save metadata JSON ===\n",
    "# with open(metadata_output_path, 'w') as f:\n",
    "#     json.dump(segment_metadata, f, indent=2)\n",
    "\n",
    "# print(f\"Metadata saved to: {metadata_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796e027e",
   "metadata": {},
   "source": [
    "### this code doesn't work, but it's the last bit that was semi-functional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5441d979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import json\n",
    "# from scipy.io import wavfile\n",
    "# from pathlib import Path\n",
    "\n",
    "# # === CONFIG ===\n",
    "# #folder_path = '/Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_unsegmented_songs/55'\n",
    "# #json_path = '/Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_unsegmented_songs/55_detected_song_intervals.json'\n",
    "\n",
    "# output_folder = folder_path + '/detected_song_files_full_recordings'\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.makedirs(output_folder)\n",
    "\n",
    "# metadata_output_path = os.path.join(output_folder, 'segment_metadata.json')\n",
    "\n",
    "# # === Load Detected Intervals ===\n",
    "# with open(json_path, 'r') as f:\n",
    "#     detected_intervals = json.load(f)\n",
    "\n",
    "# # === Sort files for reproducibility ===\n",
    "# file_names = sorted(detected_intervals.keys())\n",
    "\n",
    "# audio_queue = []\n",
    "# sample_rate_reference = None\n",
    "\n",
    "# for file_name in file_names:\n",
    "#     wav_path = os.path.join(folder_path, file_name)\n",
    "#     if not os.path.exists(wav_path):\n",
    "#         print(f\"Missing file: {file_name}\")\n",
    "#         continue\n",
    "\n",
    "#     try:\n",
    "#         samplerate, data = wavfile.read(wav_path)\n",
    "\n",
    "#         if sample_rate_reference is None:\n",
    "#             sample_rate_reference = samplerate\n",
    "#         elif samplerate != sample_rate_reference:\n",
    "#             raise ValueError(f\"Sample rate mismatch in {file_name}\")\n",
    "\n",
    "#         if data.ndim > 1:\n",
    "#             data = data.mean(axis=1)  # mono\n",
    "\n",
    "#         audio_queue.append((file_name, data))\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error reading {file_name}: {e}\")\n",
    "#         continue\n",
    "\n",
    "# # === Chunks ===\n",
    "# minute_samples = 60 * sample_rate_reference\n",
    "# leftover = np.array([], dtype=np.float32)\n",
    "# leftover_provenance = []\n",
    "# segment_metadata = {}\n",
    "# chunk_count = 0\n",
    "\n",
    "# def get_song_segments_within_range(file_name, range_start, range_end):\n",
    "#     \"\"\"Get adjusted song intervals from a file that fall within a sample range.\"\"\"\n",
    "#     song_segments = []\n",
    "#     for start_time, end_time in detected_intervals.get(file_name, []):\n",
    "#         start_sample = int(start_time * sample_rate_reference)\n",
    "#         end_sample = int(end_time * sample_rate_reference)\n",
    "#         overlap_start = max(start_sample, range_start)\n",
    "#         overlap_end = min(end_sample, range_end)\n",
    "#         if overlap_start < overlap_end:\n",
    "#             relative_start = (overlap_start - range_start) / sample_rate_reference\n",
    "#             relative_end = (overlap_end - range_start) / sample_rate_reference\n",
    "#             song_segments.append([round(relative_start, 3), round(relative_end, 3)])\n",
    "#     return song_segments\n",
    "\n",
    "# def finalize_chunk(chunk_data, provenance_list, song_segments, chunk_index):\n",
    "#     output_filename = f'detected_song_minute_{chunk_index + 1}.wav'\n",
    "#     output_path = os.path.join(output_folder, output_filename)\n",
    "#     wavfile.write(output_path, sample_rate_reference, chunk_data.astype(np.int16))\n",
    "#     segment_metadata[output_filename] = {\n",
    "#         \"source_files\": provenance_list,\n",
    "#         \"song_segments_in_chunk\": song_segments\n",
    "#     }\n",
    "#     print(f\"Saved: {output_path}\")\n",
    "\n",
    "# for file_name, data in audio_queue:\n",
    "#     total_samples = len(data)\n",
    "\n",
    "#     # Combine with leftover\n",
    "#     combined = np.concatenate([leftover, data])\n",
    "#     combined_provenance = []\n",
    "#     combined_song_segments = []\n",
    "\n",
    "#     combined_ranges = []\n",
    "#     current_offset = 0\n",
    "\n",
    "#     if len(leftover) > 0:\n",
    "#         combined_ranges.append({\n",
    "#             \"source_file\": leftover_provenance[-1][\"source_file\"],\n",
    "#             \"range_start\": 0,\n",
    "#             \"range_end\": len(leftover)\n",
    "#         })\n",
    "#         current_offset = len(leftover)\n",
    "\n",
    "#     combined_ranges.append({\n",
    "#         \"source_file\": file_name,\n",
    "#         \"range_start\": current_offset,\n",
    "#         \"range_end\": current_offset + len(data)\n",
    "#     })\n",
    "\n",
    "#     # Chunk slicing loop\n",
    "#     cursor = 0\n",
    "#     while cursor + minute_samples <= len(combined):\n",
    "#         chunk = combined[cursor:cursor + minute_samples]\n",
    "#         chunk_provenance = []\n",
    "#         chunk_song_segments = []\n",
    "\n",
    "#         chunk_start = cursor\n",
    "#         chunk_end = cursor + minute_samples\n",
    "\n",
    "#         for entry in combined_ranges:\n",
    "#             source_file = entry[\"source_file\"]\n",
    "#             source_start = entry[\"range_start\"]\n",
    "#             source_end = entry[\"range_end\"]\n",
    "\n",
    "#             # Determine overlap with chunk\n",
    "#             overlap_start = max(chunk_start, source_start)\n",
    "#             overlap_end = min(chunk_end, source_end)\n",
    "\n",
    "#             if overlap_start < overlap_end:\n",
    "#                 # Provenance info\n",
    "#                 prov_start_sec = (overlap_start - chunk_start) / sample_rate_reference\n",
    "#                 prov_end_sec = (overlap_end - chunk_start) / sample_rate_reference\n",
    "#                 chunk_provenance.append({\n",
    "#                     \"source_file\": source_file,\n",
    "#                     \"time_range_in_chunk_seconds\": [round(prov_start_sec, 3), round(prov_end_sec, 3)]\n",
    "#                 })\n",
    "\n",
    "#                 # Song segment info\n",
    "#                 rel_range_start = overlap_start - source_start\n",
    "#                 rel_range_end = overlap_end - source_start\n",
    "#                 song_segs = get_song_segments_within_range(source_file, rel_range_start, rel_range_end)\n",
    "#                 for s in song_segs:\n",
    "#                     adjusted = [\n",
    "#                         round(s[0] + prov_start_sec, 3),\n",
    "#                         round(s[1] + prov_start_sec, 3)\n",
    "#                     ]\n",
    "#                     chunk_song_segments.append(adjusted)\n",
    "\n",
    "#         finalize_chunk(chunk, chunk_provenance, chunk_song_segments, chunk_count)\n",
    "#         chunk_count += 1\n",
    "#         cursor += minute_samples\n",
    "\n",
    "#     # Keep remainder for next round\n",
    "#     leftover = combined[cursor:]\n",
    "#     leftover_provenance = [{\"source_file\": file_name}]\n",
    "\n",
    "# # Final chunk\n",
    "# if len(leftover) > 0:\n",
    "#     padded = np.pad(leftover, (0, minute_samples - len(leftover)), mode='constant')\n",
    "#     final_song_segments = []\n",
    "#     if leftover_provenance:\n",
    "#         source_file = leftover_provenance[0][\"source_file\"]\n",
    "#         song_segs = get_song_segments_within_range(source_file, 0, len(leftover))\n",
    "#         final_song_segments = song_segs\n",
    "\n",
    "#     finalize_chunk(padded, [{\"source_file\": leftover_provenance[0][\"source_file\"], \"time_range_in_chunk_seconds\": [0.0, len(leftover) / sample_rate_reference]}], final_song_segments, chunk_count)\n",
    "\n",
    "# # Save metadata\n",
    "# with open(metadata_output_path, 'w') as f:\n",
    "#     json.dump(segment_metadata, f, indent=2)\n",
    "\n",
    "# print(f\"Metadata saved to: {metadata_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2c4012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = (\n",
    "    \"/Users/mirandahulsey-vincent/Documents/allPythonCode/\"\n",
    "    \"BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files\"\n",
    ")\n",
    "json_path = (\n",
    "    \"/Users/mirandahulsey-vincent/Documents/allPythonCode/\"\n",
    "    \"BYOD_class/data_inputs/USA5510_debug_segmenter/\"\n",
    "    \"sample_wav_files_amplitude_only_detected_song_intervals.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0934973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Saved detected_song_minute_1.wav\n",
      "✅  Saved detected_song_minute_2.wav\n",
      "✅  Saved detected_song_minute_3.wav\n",
      "✅  Saved detected_song_minute_4.wav\n",
      "✅  Saved detected_song_minute_5.wav\n",
      "📄  Metadata saved to: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files/detected_song_files_full_recordings/segment_metadata.json\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from pathlib import Path   # (unused but often handy)\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# CONFIG ── update these two paths only\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "# folder_path = '/your/recordings/folder'\n",
    "# json_path   = '/your/detector_output.json'\n",
    "\n",
    "# ── derived paths ──────────────────────────────────────────────────────\n",
    "output_folder       = os.path.join(folder_path, 'detected_song_files_full_recordings')\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "metadata_output_path = os.path.join(output_folder, 'segment_metadata.json')\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# LOAD detector JSON  →  {wav_file : [[start,end], …]}\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "with open(json_path) as f:\n",
    "    detected_intervals = json.load(f)\n",
    "\n",
    "# process files in deterministic order\n",
    "file_names = sorted(detected_intervals.keys())\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# READ all wavs into memory (could be streamed if very large files)\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "audio_queue            = []            # [(file_name, data)]\n",
    "sample_rate_reference  = None\n",
    "\n",
    "for fn in file_names:\n",
    "    wav_path = os.path.join(folder_path, fn)\n",
    "    if not os.path.exists(wav_path):\n",
    "        print(f\"⚠️  Missing file: {fn}\")\n",
    "        continue\n",
    "    try:\n",
    "        sr, data = wavfile.read(wav_path)\n",
    "        if sample_rate_reference is None:\n",
    "            sample_rate_reference = sr\n",
    "        elif sr != sample_rate_reference:\n",
    "            raise ValueError(f\"Sample‑rate mismatch in {fn} ({sr} vs {sample_rate_reference})\")\n",
    "        if data.ndim > 1:                       # stereo → mono\n",
    "            data = data.mean(axis=1)\n",
    "        audio_queue.append((fn, data.astype(np.float32)))\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Error reading {fn}: {e}\")\n",
    "\n",
    "if not audio_queue:\n",
    "    raise RuntimeError(\"No audio files were loaded successfully.\")\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# CHUNKING variables & helpers\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "minute_samples      = 60 * sample_rate_reference\n",
    "leftover            = np.array([], dtype=np.float32)\n",
    "leftover_provenance = []      # list of dicts: {\"source_file\", \"range_start\", \"range_end\"}\n",
    "segment_metadata    = {}\n",
    "chunk_count         = 0\n",
    "\n",
    "def get_song_segments_within_range(source_file, range_start, range_end):\n",
    "    \"\"\"Return detector intervals (sec) that overlap [range_start, range_end) in sample coords,\n",
    "       expressed relative to the *start of that range*.\"\"\"\n",
    "    out = []\n",
    "    for t_start, t_end in detected_intervals.get(source_file, []):\n",
    "        s_start = int(t_start * sample_rate_reference)\n",
    "        s_end   = int(t_end   * sample_rate_reference)\n",
    "        ov_start = max(s_start, range_start)\n",
    "        ov_end   = min(s_end,   range_end)\n",
    "        if ov_start < ov_end:\n",
    "            out.append([\n",
    "                round((ov_start - range_start) / sample_rate_reference, 3),\n",
    "                round((ov_end   - range_start) / sample_rate_reference, 3)\n",
    "            ])\n",
    "    return out\n",
    "\n",
    "def finalize_chunk(chunk_data, provenance, song_segments, idx):\n",
    "    fname = f'detected_song_minute_{idx+1}.wav'\n",
    "    fpath = os.path.join(output_folder, fname)\n",
    "    wavfile.write(fpath, sample_rate_reference, chunk_data.astype(np.int16))\n",
    "    segment_metadata[fname] = {\n",
    "        \"source_files\": provenance,\n",
    "        \"song_segments_in_chunk\": song_segments\n",
    "    }\n",
    "    print(f\"✅  Saved {fname}\")\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# MAIN loop – stitch files, slice 60‑s chunks, preserve provenance\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "for file_name, data in audio_queue:\n",
    "\n",
    "    # 1) build new \"combined\" buffer = leftover + current file\n",
    "    combined         = np.concatenate([leftover, data])\n",
    "    combined_ranges  = []          # [{\"source_file\", \"range_start\", \"range_end\"}]\n",
    "    offset           = 0\n",
    "\n",
    "    # carry forward *all* leftover provenance\n",
    "    for prov in leftover_provenance:\n",
    "        dur = prov[\"range_end\"] - prov[\"range_start\"]\n",
    "        combined_ranges.append({\n",
    "            \"source_file\": prov[\"source_file\"],\n",
    "            \"range_start\": offset,\n",
    "            \"range_end\":   offset + dur\n",
    "        })\n",
    "        offset += dur\n",
    "\n",
    "    # append current file’s span\n",
    "    combined_ranges.append({\n",
    "        \"source_file\": file_name,\n",
    "        \"range_start\": offset,\n",
    "        \"range_end\":   offset + len(data)\n",
    "    })\n",
    "\n",
    "    # 2) slice full‑minute chunks\n",
    "    cursor = 0\n",
    "    while cursor + minute_samples <= len(combined):\n",
    "        chunk               = combined[cursor:cursor + minute_samples]\n",
    "        chunk_provenance    = []\n",
    "        chunk_song_segments = []\n",
    "\n",
    "        chunk_start = cursor\n",
    "        chunk_end   = cursor + minute_samples\n",
    "\n",
    "        for rng in combined_ranges:\n",
    "            src_start, src_end = rng[\"range_start\"], rng[\"range_end\"]\n",
    "            ov_start = max(chunk_start, src_start)\n",
    "            ov_end   = min(chunk_end,   src_end)\n",
    "            if ov_start < ov_end:   # overlap exists\n",
    "                # provenance entry\n",
    "                rel_start_sec = (ov_start - chunk_start) / sample_rate_reference\n",
    "                rel_end_sec   = (ov_end   - chunk_start) / sample_rate_reference\n",
    "                chunk_provenance.append({\n",
    "                    \"source_file\": rng[\"source_file\"],\n",
    "                    \"time_range_in_chunk_seconds\": [round(rel_start_sec,3),\n",
    "                                                   round(rel_end_sec,3)]\n",
    "                })\n",
    "                # song segments from this slice\n",
    "                slice_rel_start = ov_start - src_start\n",
    "                slice_rel_end   = ov_end   - src_start\n",
    "                for seg in get_song_segments_within_range(\n",
    "                        rng[\"source_file\"], slice_rel_start, slice_rel_end):\n",
    "                    chunk_song_segments.append([\n",
    "                        round(seg[0] + rel_start_sec, 3),\n",
    "                        round(seg[1] + rel_start_sec, 3)\n",
    "                    ])\n",
    "\n",
    "        finalize_chunk(chunk, chunk_provenance, chunk_song_segments, chunk_count)\n",
    "        chunk_count += 1\n",
    "        cursor      += minute_samples\n",
    "\n",
    "    # 3) whatever is left < 60 s → carry to next iteration\n",
    "    leftover = combined[cursor:]\n",
    "    leftover_provenance = []\n",
    "    if len(leftover) > 0:\n",
    "        for rng in combined_ranges:\n",
    "            if rng[\"range_end\"] > cursor:                      # part survives\n",
    "                leftover_provenance.append({\n",
    "                    \"source_file\": rng[\"source_file\"],\n",
    "                    \"range_start\": max(0,   rng[\"range_start\"] - cursor),\n",
    "                    \"range_end\":   rng[\"range_end\"] - cursor\n",
    "                })\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# FINAL (possibly padded) chunk made from leftover audio\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "if len(leftover) > 0:\n",
    "    padded = np.pad(leftover, (0, minute_samples - len(leftover)), mode=\"constant\")\n",
    "    final_prov  = []\n",
    "    final_segs  = []\n",
    "    for rng in leftover_provenance:\n",
    "        p_start_sec = rng[\"range_start\"] / sample_rate_reference\n",
    "        p_end_sec   = rng[\"range_end\"]   / sample_rate_reference\n",
    "        final_prov.append({\n",
    "            \"source_file\": rng[\"source_file\"],\n",
    "            \"time_range_in_chunk_seconds\": [round(p_start_sec,3), round(p_end_sec,3)]\n",
    "        })\n",
    "        for seg in get_song_segments_within_range(\n",
    "                rng[\"source_file\"], 0, rng[\"range_end\"] - rng[\"range_start\"]):\n",
    "            final_segs.append([\n",
    "                round(seg[0] + p_start_sec, 3),\n",
    "                round(seg[1] + p_start_sec, 3)\n",
    "            ])\n",
    "    finalize_chunk(padded, final_prov, final_segs, chunk_count)\n",
    "\n",
    "# ╔══════════════════════════════════════════════════════════════════════╗\n",
    "# WRITE master metadata file\n",
    "# ╚══════════════════════════════════════════════════════════════════════╝\n",
    "with open(metadata_output_path, \"w\") as f:\n",
    "    json.dump(segment_metadata, f, indent=2)\n",
    "\n",
    "print(f\"📄  Metadata saved to: {metadata_output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a131047",
   "metadata": {},
   "source": [
    "### generate the spectrogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63a67a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 Processing 5 files in: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files/detected_song_files_full_recordings\n",
      "\n",
      "✅ Saved: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files/detected_song_files_full_recordings/spectrograms/detected_song_minute_2_spectrogram.png\n",
      "\n",
      "✅ Saved: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files/detected_song_files_full_recordings/spectrograms/detected_song_minute_3_spectrogram.png\n",
      "\n",
      "✅ Saved: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files/detected_song_files_full_recordings/spectrograms/detected_song_minute_1_spectrogram.png\n",
      "\n",
      "✅ Saved: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files/detected_song_files_full_recordings/spectrograms/detected_song_minute_4_spectrogram.png\n",
      "\n",
      "✅ Saved: /Users/mirandahulsey-vincent/Documents/allPythonCode/BYOD_class/data_inputs/USA5510_debug_segmenter/sample_wav_files/detected_song_files_full_recordings/spectrograms/detected_song_minute_5_spectrogram.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram, windows, ellip, filtfilt\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter as tk\n",
    "import json\n",
    "from scipy.signal import spectrogram, windows, filtfilt, ellip\n",
    "\n",
    "def process_wav_file(file_path, spectrogram_folder, segment_duration=10, low_cut=500, high_cut=8000):\n",
    "    try:\n",
    "        base_name = Path(file_path).stem\n",
    "        samplerate, data = wavfile.read(file_path)\n",
    "        if data.ndim > 1:\n",
    "            data = data.mean(axis=1)\n",
    "\n",
    "        # === Apply Bandpass Filter ===\n",
    "        nyquist = samplerate / 2\n",
    "        wp = [low_cut / nyquist, high_cut / nyquist]\n",
    "        b, a = ellip(5, 0.2, 40, wp, btype='band')\n",
    "        data = filtfilt(b, a, data)\n",
    "\n",
    "        duration_seconds = data.shape[0] / samplerate\n",
    "        segment_length_samples = int(segment_duration * samplerate)\n",
    "        num_segments = min(6, int(np.ceil(duration_seconds / segment_duration)))\n",
    "\n",
    "        spectrogram_fig_path = os.path.join(spectrogram_folder, f\"{base_name}_spectrogram.png\")\n",
    "\n",
    "        fig, axs = plt.subplots(num_segments, 1, figsize=(width_inches, height_inches), sharex=True, gridspec_kw={'hspace': 0.0})\n",
    "        if num_segments == 1:\n",
    "            axs = [axs]\n",
    "\n",
    "        metadata_key = f\"{base_name}.wav\"\n",
    "        song_intervals = []\n",
    "        boundary_lines = []\n",
    "\n",
    "        if metadata_key in segment_metadata:\n",
    "            entry = segment_metadata[metadata_key]\n",
    "            song_intervals = entry.get(\"song_segments_in_chunk\", [])\n",
    "            for src in entry.get(\"source_files\", []):\n",
    "                if \"time_range_in_chunk_seconds\" in src:\n",
    "                    end = src[\"time_range_in_chunk_seconds\"][1]\n",
    "                    boundary_lines.append(end)\n",
    "\n",
    "        for i in range(num_segments):\n",
    "            start_sample = i * segment_length_samples\n",
    "            end_sample = start_sample + segment_length_samples\n",
    "            segment_data = np.zeros(segment_length_samples, dtype=data.dtype)\n",
    "            if start_sample < data.shape[0]:\n",
    "                segment_data[:max(0, min(segment_length_samples, data.shape[0] - start_sample))] = data[start_sample:end_sample]\n",
    "\n",
    "            f, t, Sxx = spectrogram(\n",
    "                segment_data,\n",
    "                fs=samplerate,\n",
    "                window=windows.gaussian(2048, std=2048/8),\n",
    "                nperseg=2048,\n",
    "                noverlap=(2048 - 119)\n",
    "            )\n",
    "\n",
    "            Sxx_log = 10 * np.log10(Sxx + np.finfo(float).eps)\n",
    "            Sxx_log_clipped = np.clip(Sxx_log, a_min=3, a_max=None)\n",
    "            Sxx_log_normalized = (Sxx_log_clipped - np.min(Sxx_log_clipped)) / (np.max(Sxx_log_clipped) - np.min(Sxx_log_clipped))\n",
    "            Sxx_log_normalized = np.power(Sxx_log_normalized, 0.7)\n",
    "\n",
    "            axs[i].imshow(Sxx_log_normalized, aspect='auto', origin='lower',\n",
    "                          extent=[0, segment_duration, f.min(), f.max()], cmap='binary')\n",
    "\n",
    "            # === Yellow highlight for song intervals ===\n",
    "            panel_start = i * segment_duration\n",
    "            panel_end = panel_start + segment_duration\n",
    "            for interval_start, interval_end in song_intervals:\n",
    "                if interval_start < panel_end and interval_end > panel_start:\n",
    "                    x0 = max(0, interval_start - panel_start)\n",
    "                    x1 = min(segment_duration, interval_end - panel_start)\n",
    "                    axs[i].axvspan(x0, x1, color='yellow', alpha=0.4)\n",
    "\n",
    "            # === Red dashed lines for source boundaries ===\n",
    "            for boundary_time in boundary_lines:\n",
    "                if panel_start < boundary_time < panel_end:\n",
    "                    axs[i].axvline(boundary_time - panel_start, color='red', linestyle='--', linewidth=1.2)\n",
    "\n",
    "            axs[i].set_ylabel('Freq [Hz]')\n",
    "            if i == num_segments - 1:\n",
    "                axs[i].set_xlabel('Time [sec]')\n",
    "                axs[i].set_xticks(np.linspace(0, segment_duration, 5))\n",
    "\n",
    "        fig.suptitle(f'{base_name} – Spectrogram (Filtered {low_cut}-{high_cut} Hz)', fontsize=14)\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(spectrogram_fig_path, dpi=300)\n",
    "        plt.close(fig)\n",
    "        print(f\"✅ Saved: {spectrogram_fig_path}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {file_path}: {e}\")\n",
    "\n",
    "\n",
    "def batch_process_folder(folder_path, segment_duration=10):\n",
    "    output_folder = os.path.join(folder_path)\n",
    "    spectrogram_folder = os.path.join(output_folder, \"spectrograms\")\n",
    "    os.makedirs(spectrogram_folder, exist_ok=True)\n",
    "\n",
    "    wav_files = [f for f in Path(folder_path).glob(\"*.wav\")]\n",
    "    if not wav_files:\n",
    "        print(\"No .wav files found in the selected folder.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n📂 Processing {len(wav_files)} files in: {folder_path}\\n\")\n",
    "    for wav_file in wav_files:\n",
    "        process_wav_file(wav_file, spectrogram_folder, segment_duration=segment_duration)\n",
    "\n",
    "# === USER INPUT ===\n",
    "spectrogram_output_folder = output_folder\n",
    "batch_process_folder(\n",
    "    spectrogram_output_folder,\n",
    "    segment_duration=10  # Each panel = 10s; total of 6 panels = 60s\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323fc851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BYOD_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
